{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualización en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:90% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import animation, patches\n",
    "from IPython.display import display, Audio, HTML\n",
    "import soundfile as sf\n",
    "from style import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Universidad Austral de Chile \n",
    "\n",
    "## INFO183: Análisis de sistemas lineales\n",
    "\n",
    "# Unidad 4: Sistemas y filtros adaptivos\n",
    "\n",
    "### Dr. Pablo Huijse, phuijse at inf dot uach dot cl \n",
    "\n",
    "### <a href=\"https://github.com/phuijse/UACH-INFO183\"> github.com/phuijse/UACH-INFO183 </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "<a id=\"index\"></a>\n",
    "\n",
    "# Contenidos de la unidad\n",
    "\n",
    "***\n",
    "\n",
    "1. [Estimador lineal óptimo](#section1)\n",
    "1. [Gradiente descendente](#section2)\n",
    "1. [Algoritmo de mínimos cuadrados (LMS)](#section3)\n",
    "1. [Algoritmo de mínimos cuadrados recursivo (RLS)](#section4)\n",
    "1. [Algoritmo perceptrón](#section5)\n",
    "\n",
    "### Bibliografía\n",
    "\n",
    "1. Simon Haykin, \"Adaptive filter theory\" 5ed, Pearson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducción\n",
    "***\n",
    "\n",
    "- **Estimador:** Sistema diseñado para **extraer información** a partir de una **señal**\n",
    "- La señal contiene **información y ruido** \n",
    "- La señal es representada como una secuencia de **datos**\n",
    "\n",
    "Tipos de estimador\n",
    "- **Filtro:** Estimo el valor actual de mi señal acentuando o eliminando una o más características\n",
    "- **Predictor:** Estimo el valor futuro de mi señal\n",
    "\n",
    "Estimador lineal óptimo\n",
    "- Lineal: La cantidad estimada es una función lineal de la entrada\n",
    "- Óptimo: El estimador es la mejor solución posible de acuerdo a un criterio (*e.g.* Error cuadrático medio)\n",
    "\n",
    "Estimador lineal adaptivo\n",
    "- Es lineal pero no LTI\n",
    "- Sus parámetros cambian en función del tiempo\n",
    "- Diseñamos una regla para actualizar sus parámetros\n",
    "- Usualmente las reglas están basadas en criterios de optimización\n",
    "\n",
    "\n",
    "<img src=\"img/adaptive-systems1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Proceso aleatorio/estocástico\n",
    "***\n",
    "\n",
    "- Colección de variables aleatorias indexadas en el tiempo\n",
    "- Evolución de un fenomeno estadístico en el tiempo\n",
    "- El fenomeno se rige por leyes probabilísticas\n",
    "\n",
    "\n",
    "Un proceso aleatorio $U_n = (u_n, u_{n-1}, u_{n-2}, \\ldots, u_{n-L})$ se describe a través de sus momentos\n",
    "\n",
    "Si consideramos una caracterízación de segundo orden necesitamos definir\n",
    "- Momento central o media \n",
    "$$\n",
    "\\mu(n) = \\mathbb{E}[U_n]\n",
    "$$\n",
    "- Segundo momento o correlación\n",
    "$$\n",
    "r_{uu}(n, n-k) = \\mathbb{E}[U_n U_{n-k}]\n",
    "$$\n",
    "- Segundo momento centrado o covarianza\n",
    "$$\n",
    "\\begin{align}\n",
    "c_{uu}(n, n-k) &= \\mathbb{E}[(U_n-\\mu_n) (U_{n-k}- \\mu_{n-k})] \\nonumber \\\\\n",
    "&= r(n,n-k) - \\mu_n \\mu_{n-k} \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "- correlación cruzada entre dos procesos \n",
    "$$\n",
    "r_{ud}(n, n-k) = \\mathbb{E}[U_n D_{n-k}]\n",
    "$$\n",
    "\n",
    "***\n",
    "En general consideraremos el caso simplificado donde el proceso es estacionario\n",
    "\n",
    "$$\n",
    "\\mu(n)  = \\mu, \\forall n\n",
    "$$\n",
    "y\n",
    "$$\n",
    "r_{uu}(n, n-k)  = r_{uu}(k), \\forall n\n",
    "$$\n",
    "es decir los estadísticos se mantienen constantes en el tiempo (no depende de $n$)\n",
    "\n",
    "Otra simplificación es que el proceso sea ergódico\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[U_n] = \\frac{1}{N} \\sum_{n=1}^N u_n\n",
    "$$\n",
    "\n",
    "es decir podemos reemplazar el valor esperado por la media en el tiempo\n",
    "***\n",
    "\n",
    "### Densidad espectral de potencia\n",
    "\n",
    "Otra cantidad de interés es la PSD (*power spectral density*) que mide la distribución de la potencia en frecuencia\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S_{uu}(f) &= \\sum_{k=-\\infty}^{\\infty} r_{uu}(k) e^{-j 2\\pi f k} \\nonumber \\\\\n",
    "&= \\lim_{N\\to\\infty} \\frac{1}{2N+1} \\mathbb{E} \\left [\\left|\\sum_{n=-N}^{N} u_n e^{-j 2\\pi f n} \\right|^2 \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "que corresponde a la transformada de Fourier de la correlación (caso estacionario)\n",
    "\n",
    "La PSD y la correlación forman un par de Fourier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[&larr; Volver al índice](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "<a id=\"section1\"></a>\n",
    "\n",
    "# Estimadores óptimos\n",
    "***\n",
    "[Óptimo](http://dle.rae.es/?id=R7bbor7): adj. Sumamente bueno, que no puede ser mejor.\n",
    "\n",
    "Para diseñar un estimador óptimo necesitamos un **criterio**\n",
    "\n",
    "Luego el estimador será **óptimo según dicho criterio**\n",
    "\n",
    "Usualmente también consideramos supuestos. Podríamos asumir que\n",
    "- el ruido es aditivo y blanco o que tiene una cierta covarianza conocida\n",
    "- conocemos la media y covarianza de la señal\n",
    "- el proceso es estacionario\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "wiener.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoEAAAE0CAIAAADc3n60AAAOSHpUWHRSYXcgcHJvZmlsZSB0eXBlIGV4aWYAAHjarZlpduM4skb/YxW9BERgXg7Gc94Oevl9A6KdssuVdbJfW5miTIoYYvgG2u1//99x/+In1FBdTKXmlrPnJ7bYtPOh+tfP6yg+3vfXKfH6nP1y3oX4fFSOgWN4Xcj7dZTO+fTrhhKf8+PreVfm64PWZ6DnwseAwWa2NTzfq89AQV/n5fndtee+Ht+28/wf6zmXXofvv8dCMFZivKBOd5Dgec82S2AFhK7zLrxrSPo620MIifcU2s+xc58fvwWvjGf2b7Hz/flG+BoK5/PzhfwtRs95ST/H7kbofUXiP7P25cKu/iMif4ndOaues1+76zETqeyeTflniPuJL7KxGO5tmVfhf+Jzua/Gq7LFScYW2Ry8ppMmSrSPRFnS5ci+xymTJUbdWjiqTg33XA1Fm86blGgvOVpCC8uRIw2TrAVO6+da5M7b7nxTbJtL+KYKgwl3/OXlfjr537w+BzrHSlfEglnGjRXrUqtplmGZs3e+RULkPDFNN7735T7T+uvHEhvIYLphrmyw+/EaYiT5VVvh5jnwveSj86/WkLKeAQgRcycWQ3VH8VlCkiy+qBYR4ljJT2flGqIOMiAp6RJ3yE0ImeRUtbm5p8j9riZ9nQZaSEQKORRS00InWTEm6qfESg31FFJ0KaWcSqqppZ5DjjnlnEs2jOollFhSyaWUWlrp4FesqeZaaq2t9qYtAGGp5VZcq6213pm0M3Tn7s43eh86wogjjTzKqKONPimfGWeaeZZZZ5t96QqL9l95Fbfqaqtv2ZTSjjvtvMuuu+1+qLUTTjzp5FNOPe30z6w9Wf2aNfmWud9nTZ6sWcbi/V75lTVOl/IxhBicJMsZGdMoZLxYBihotZwB2zGqZc5y5psaVClZk2TJWWIZI4Nxi6Yjn7n7lbnf5s2l+Ed507/LnLPU/S8y5yx1T+b+mrcfsrb6ZZRwE2RdaDH14QBsfKlr5R94rERw1NTLYG9LTh6ifpcbVTBtVajiVIhDekm7NmJS9150kAMwU4px1jSFEQnfnOO0YtST+5LU9mD3Y7Q51vLKqZbWWMVPordbSpPK7tXJSmGvToLnmTOcWvg8IS7eGCWOHHolEa2uUzYAqmTnxJj9nLFRXMHAxVhEeiSQjKcpUizp1Aq0tzYi6Z8ZWB5rsLezYWvpK6YcNdXd9WiPc5U0UpXifIpElDoZdRc5mxtGCmRq7RFZcit5jJXaKW0fAGIvWWHkaGuutuYi5OpkF0n8pshWnb2uaVgi9ezW5hnM7omCQdWcpVjDWNcUkuRPBOb3YZEjsFl1QmozgFWIk66dJVPKh0XURCEuvrvj9C0faDsnKm+35Xc8q4QbSctHPZIdVVbZ9hy+sgJWJWy5b3KtpbGM3dl4b95SExh+pL2jEGopwRh0zFxkd3HjBEpsRavrgbpQ3utS9nPo8ZrzAf80mX5JEp9jYrStVBEtiR6BLY8bbcUhaW0AIUMnhIka4AbWpUM3/UH9DX80byX1Ph6UXWhCKgswdvZK0lNzJEasSCivEwKwkaHO3ptYj8CjkKsH0muftSlFwrJCo/oN88MGLrbPZbTtGj03RtaeR61swshVtW1Lxao57liVquuNNpXle83WI5Z7q/oU6FHOleJy1Z0D+aNQM5/apCYbOLPnAgIQBqQgivYxwd5G2VequrBMdlFklE5Tr9Bdeg1OsyHUJtNH9YOvUeRrkv3byrelVVpfTUtOupcxcA6+b9qBUpPjTi5T9gjlLJrAukb6SJYeWoo6r2GRuTPOtGvsuPx8h/vzW36+w/35LfeOGuIcFLJSwrPvdVxpDZj2aWwAmo4NKe9KiXYa0dv9yW69I9iMi2Y8dOrZh17nCijXLIJOx08X5dcon6uAE77P8BYG9z6KYe/5mOLbDM81+WGddwZiRMbpU/IYY8nIzLhhFc6WPWqgAsIZgWXYzG1YEPlEGL8EcQ/HqZ6fixxmrvf8Dfi98Nw6AQzaAzotPw7sGPljyo/zX7MWDYd68BBaXqr3NpQ1DRqR2nHra2aX9wQkgJY4dzjMOm6Aut2QwWM7rnBTv9/qyy7c0xYpLmxHqPpNxjiwJFe4FNe9OD4y+LoAAz4X7GZLSn/NeQd230dGKiDHlYW1hF6PEhqUMmElELCpzXlb7zl2aGN3XzPSr252nGzPo641DUa83Q5CXQZCqICEgAzSFKKnenUj9iHCFIEpqENarE77xAzCu2Yh88dcKKsOncWhSJUxwPW8FlOCEuMqrDOyaY1uXTUBlkX612xEOZksxkCcbg3nE+OzX03hVRHrLGHvVeF54iPaLAqo3ToBtqDTYXGgAWBGpuHeTX3mDsoAsgCrrYY8qb4lQaWUAxoflpxqsfwT67pyNeOHCoNB7QXD6h2ORPzhYM5GW1axbf3NxtqEi3MLGpEIk7ikFhADvhMhtCoMVrr5/pAgQVNpdz78GeTf46tFxCIP29EbeGZpAeUKq0X6hbZsyS/Nc80u6OwCgLcCyyt0QO2fhrBTBFQnkwHTeBoaC3HKog2pMoYjglyRBdJSKtNCshBaxP/OY9Pe+RCmnhtA+pXwoXwVBmVTaFoEXRXjo4rnJ2sgRmCHOMzuJgrMVOE2j4uE5ECNhPbw+NAF+xqBgaQBObCR2RtRkK0vUT6X5NG5TlEfNDX3IcAYblmrvdH8PSakRkNdUTZ9We83YVSCJeaoAPAz3WKNKfWU/FzAGryYOrtPDeFGSY9NsxyxRzEVaQqgIFwCygHtOKuwR6jOnpM4jX6Pi7xiIxYKNeQrhxAVugfvO1Vk3nUe6Iuj1r7DZ9Oy6HhOTL+3ExSvmpKgkChAIQzFfHXwtM6sGfkDuZTpD8TjWdlaUS2je6MjgPBAMikH5xv2D1tZAbbImi0grbNDMNXU/92qeQwCCeyw4k1mapT5qnfkAVI0oiENPxEjE7in5S9HQF97t6thaX6aAS5YFzMHZXwiXTpPGyy7J6Yv9E5ytd2REwodEhnMKTgYpPYplpnVzbS/IjokLIO5eGsDfDTVmMlmFz1O8Ti4J7zSANDRVMOavwHA1jcKDOUVG7oOhij+jGY1cmQRMEVQdo8eBg0XCNlYQJhi4RxhmeLCidTtaUwducsGEpHXFWeBxDY5FE3RxdSRNxk5iPUKw8W9Cx6wmbJf4eAtME0AlYKytFbsKC8fsUDcTozqKSB6sC0lM0ZjIBtMbbkVKgKbRqH0cqQKG0RLi/UeD+lqC6k+aFCTbxjQisYu9ogBgG09Qetqli0XYIQ+aJ6iwxcQztmMN9WeArLyRLu82Gze48J6vogp4GA3yhKV1+m9bVALSFEYWl9Soe7XGGKibpHGy3Tk7Q54xoOTfm0qFvzWe2m7e0WMIYuyGQxwoYxpdzrSvF4v2C8P8mKU8YOJcGOZDChERBUjhm7PYTolaBLg7MElHHaIgDKWJOjl1YKlNnpDuCOuY1oUD5qZ3Y9tRELVFoXCgqM7ROgVSfb0FBXMpGAMoaBWIsSGQB/EfFEJPphrkom5ZXAWQNsxHU0xsBBwd0IGUsYBn4/ixVVBVrnT87rInFr1gmBpq8enxjC7PTSAitHOQvNhdei13YDPHaPpcvzANl9JK+AncA/4xbyHzjxUgycW5DeC8uQhDqowqmDOo+Y4HT0b0ODpeBxrP1g7Ik6gy6LhcHCsIC/QjF9hfoCWCck7ZW8JaRUjTGFJM79WjK8zYZimESK7BGR8Mvs7PaHAHWNPuYeEJiCisLNF4hCIzZ6geKggu5U3BZ4xaEdtM4WBWz8qZn3J9Ubb4AGzWYwwWeeCBSlpFMzE1ymGspgqcMaV3Eu0q2ENNjKZpTUWy9Z0ey00wu5sJwDboxZ8MnaX2ynDbvU9sfvZwbq0a5qN67J9S/QooDwB8IrHZggskz17yNChmCP0c1zhAFIY3tKQCe/rNs6eAhvAJQWMJL4l9qbJfnvsfV5Vq+LwwuhYuuMBs48Lb+dtm1xhHyhC8LviaElijNRbnfT5ybs57m437Jw1RZMWAlA7xlwImz3cAR6rqTDFRwN+pUPVbeC4ySQ9AnKiTnDZlFUzyuImU6oVGAMYEsXKQFjsei7sV6vkBjwDrKAHoiMVEkcXlmBCCAvBWksKg0Jq3M2KTAQAWUAr/OCLjdChFQgjXHLMAzQa2/4QYQ/KqEJKw6FwDz4EqAGIO8gyixELYGXprRDV+i28PWpH3XsSKAlqy0QSbUD5IQgy2gO5FVmwSijBWK7A7PsA+cxQp1F4L+KMsSFKG2fWYaHrp1VqYQhkhrEc1hirS6wb9EbQdHt+RJW0nPOa9uSmhtGA2ikk2fKMckbLHXKLG6UX4o0OkTQFb4+5iU/6u8Jy/1Rx0qAApWpKzhiEFpDAUAoglI1AH4NYi8MEIhrNXs1rWdG7b2fe7CdtDEZJkZc/82Ym386518k39/l1pH8c2yyqjeSOjRMI3wEnOYv3HApDWs9b+IwQQRTTyF8f/bwf0cnuh+DmRGGcgBRB0IBXy++r2FoLbSHvAO4AmyT99bjDd/f5KPP/efyngQCdgTdI7I0SY4GoDzQawswes9JJHrZBsBdXhdKI1XcarNJ39AA4UVHhkkYyP+BzAEUOtNTPfXQUkeq0P5vHvM3ZF1x3XCu1C8w2cFvT5zztrxN01T6mMYNQ5jQIIm2C7Ikm2/Yo1dQ02iwZW+p9euFyYuVh0wm3DcMEz3Ega8qyvxDaMwXzXAXGRuMqqgI+yPQEwoZW3iYy4RNxEaSmTXMfbQ+WhZSGNfI3g/LPRyd/eMP7sQL22K95RsquUIwJkJqp0bwzC64XbWxPMuxJQLLiNVH2ejgGugroiXhF0SM9MXjb/gLrDzbLihwiXr+dnfFWc/8B/YjWwutPXhgAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAAHdElNRQfiCxkXIzvbUhKdAAAgAElEQVR42uzdd1gTSR8H8AFCEYTQi0cHFWygUgSx9947KqCiondnF+8U2+mdFRsWmr2cYBesWOhdAVHBAiiEjvQSUt4/9i5vjhIjRSnfz+Pjk2xmZyaTDb/Z3cmMCJfLJQAAAPDdiaIJAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAMRgAAAAQgwEAABCDAQAAADEYAAAAMRgAAAAQgwEAABCDv4ecnJy3b99WVFQQQqqqqrhcLrX9w4cPnz99aqZCmzXzH6WoqOjNmzc/pOiKioq4uLh6Xy0vf/PmTUlJSUuoqgDvkpMLCwsFVLv9HEsA0MZjMIvFOn7s2IJ5tn9fvvLh/fuzp0/bzZ8/b/acwi///BH8849dhw66NlPpzZr5DxERHj5y6LBTx0/8kNA1ZeKkzZt+q/PVk8eP+1z1SUtJ7d+v333/ez+2qgJs3eKSnJw8sH//vLy8Oqvdfo6lNiwnJ+fN69elpaVUH6tpe5+Ce2Mttq+GTmQTorWWilZXV8+eMVNZRdnD20tSUpLaONfWds7MmaWlJQqKCoSQQ0ePiIk2V6+imTJnMpneXl7Lli///k1q2a/foMGDmUzm9y+6c5cuk6dO8btzt/ZLT5888ffzv+13lxDSUbajsopK7ar+wEbjiYqMfJ2YuH3nDgNDQ0VFxTqr3RzHUkt47+0Bi8VyP3kyPCzc3MJCV0/X767fi9hYFov1t69PI3ufP69YKS4ufsffj+qN0en0A4dc6+urCXj1B2qxFUMMbkZHDh1+8/r1s+AgXgAmhMjJyf2+ZUt5eQX1tGPHjs1XgebInMPh7Nqxs6io6Ee1qoiIyA8rmtRd9JPHAXp6etRjmwEDalf1hzcaJTkpSUxMlBBiZGQkoNpNeyy1kPfe5tXu8U+YSFJTUhfa2jZt77NGb6xGB6tZTyq+qXv3YyuGGNwiXDx/vr+Njaqqao3t1v37Uw+CAgNv37pFp9M3u7icO3PW5+rVPn37/rp6lYyMzLEjR7Ozsv7cs6e8otz36lVJKanoyKgZs2ZaWVvzdlRSUlJTU/P18SGEHDl2zMDQkL8U/szrS/8uOfnK5cvq6hrFxcX+fncVFBQ3OG+0sLQMCw3dtsWln7X19p074l6+3Obi8pOm5rHjxwkhTwICgoODZGQ6nvE+PWrMaA0NDd7VqhNux1VVVd4lv1NSVv5l1a+EkOfPnsVExygpKUWEh69eu6Zzly7Uxtu3bmlodKLT6devXZOTkzt89Oizp08vnDtXXV3teuRwt+7d66tYjZYsKSmp3Th11oSnzioJaM+qqqpTJ07IysmVFJfE13Uz+NHDh3FxceI02hnv0ywW687t29o62kfd3P4TpGs1Wp01DwsNvX3zFofDMe3T28vD44Crq4mpKS+TvLw8b09PUVGx14mJEydNmjx1ClU9T3cPOl2OwWDk5eatXb9OTV29zpYJePQ44HFAVlb2Ge/T3Xt0LywsrK/atQviP5bqzFxAA9Z47/Ly8gI+HWjaHr+unq7tggVVVVX8GxvZ++TvjdXuYDXrSYXw3bsfW7G2j9safEpLM9DR3bl9O//G+Lj4q1euUP+io6IqKirmzJz168qfuVwum80ePWLk2tWrqZSnTpx88+YNl8tdaGv75csXLpcbHRVl0r1Hfn4+l8stLy+fNnnKxHHj01JTC/ILhg4atOW332tUgD/z+tK/iI3tZ2Y+ddLk9+/fFxcXr1+ztoeRcXZWFpfLXbFs+Ya166istm5xsV+wkJfzhrXrqGz5XTh3znn9Bi6XW1Zadtj1ELXRok/fiPBwLpd72NV1sb0DtbG8rGziuPFTJ03+/PlzXl7eACvryRMmUAOFJowdt+bXVYIrxl96nY1TZ0146q5S/e3puHjxs6dPqcerfv5l/JixtT/rX1f+zGsrl98389qKv6o1Gq3Omn/58mX+3HlWFpbhYWEP7t8vKiripa+qqho5bPjnz5+5XO4Z79OWfc2o7Q4L7e7fu0c93r9339BBg6gRf3Xmf9j10Kzp0wVXu86C+I+lOjMXfEDyv3fBnw40WO+evXjHM7/q6moOh8PlcisrK48dOXr+7Nk9f/65fs3arMxMLpcb+Pz5ujVr/ty1y9vTc+yoUWNHjXr/7h21Y2Vl5WFXV28vr8OuhxbZ2VNHPpWe92ft0cOHQwcNmjB23GkvbwaDUePVbyqxvLz8wL7958+edfl9c50HxrOnTw/s23/G+/Ryx6XJSUm1S+dPLKBiz54+XbNq1b49e91Pnho9YuTMadMzGZmXL14aN2r0yKHDEl+9onIoLi729vS8eOHC6l9+DQ0JqVGZ0tLSC+fPb9q4MTsrqyC/4K/du7ducWk/B1vruJ5QVVVFCKmsrOTf2LNXTz19g00bnaOjovuamUlJSWlpaVEviYqKOixyuO9/j+q7paamGBkZvYiNZWQwbl6/ccb7dGxMrJa29of37wkhHTp00NTUNDIy0tbRUVBUsBkwkMFg1KgAf+b1pTft3VtXT89mgI2BgYGsrOzWHdu5XG5AQAAhhEb7//UGcdrXrz0oq6hcv37t2JGjYjSx5SucqI3uXp59+vZlsViVlZUpKR//qYy0dKdOnbp3766pqamkpNTfxkZdXcOwc2c6nT5o8OCvVoynvsapsyY8dVepnvZ5lZAQEx0zcNAgKlmXrl2+2g4SEhJfTVNfzeXl5Y2Mjbt27WrZr9/IUaPk5OR4u9zz95eRkdbU1CSELLBbeOeePyEkNiYmOCho+PARVBrb+bZpqWlPHgfUl78w1a6zIP5jqc7MhTkgBRwn0EifP30qLi7W0dWp47IhjUbdE3Fausyws6HtggUbnJ3V1NXnzp7NZDLNzM1TPqaEhYYNGz78wqXLlZWVZ0+foXb8ZeVKE1NTeweHX1b9KisrS200t7DISM/Iy82jng4fMcLMzFxfX9/OwV5DQ6PGq99U4nVf39ycHNsFCzZu2lTne9ywdp3NAJuF9nZGxkZ7/9pTu3T+xAIqZmFh8f7d+7DQ0DHjxl64fCmTwVi+1NHM3Ozi31ckpaS8PDypHH52cpoybdrcefPmzbdd7ri0oKCAP38ZGRk6nf7wwcOS0tK7d+507Wp068YNXItuWfT09Tt06PApreZIPF09XUKIvoFB7V0mTp6856891319e/Yyoa5XJ71N0tLWtnOwpxIsWepY9x9QcXEOhyN83fjTi/LdI5GRkdHT1y8tKW3A+x01evT6DRtdDxy4cf3a/oMHe/fpQwjR0dU97HpIWVlZSkqKVc2qc0dxcXH+x1yusBWrr3HqrAmPMFXitU/iq0Q5OTnebV1RUbEmOTYEfKyioiJ13vBOS01V+femhoiIiIqKCiEkKSlJVFRUjPZPrdTU1el0empaamFhoTCHTZ3qLEjIygtzQAr+dKAJe/z8qO6au6cnr7t2ws3tyeOA0WPHaGpqSkpKauvoEEJsBgzMSE/n9T5Purvzep/v37/n9cao4mrjf/VbS6Q6Zz9pai5Z6lhn58zdy7N7jx41es9C4q8YdQ6goqJCdTT729gUFhYadu5MCBk0eHB0VBR/R5O60U51NBUtLPjzjI+LNzU1jYyImL9wwRnv03369m0/x1vrOA8WExMbPmJEVGRkenq6kLtISkrOnjPn4oULjx89HDV6NCFEWkY6IT6efxhwclJy836ZKyuNuxnzrvkLv2NOdvZixyX3Hj7Q0tJebO/AYrFYLNbkCROHDR+20N5OpdZN8cZUjFJf49SuCS/Bt1ZJQVEhk8H46m9nv1UDPlaNTp1exr7g7VJRXl5cXKyurl5dXZ2WmkZtZLPZLBZLS0urMYdNnQU1svKCjxNE0Obr8f+/51RPd635ep/fWiLVOTvh5jZ21KhXCQm1M6R6zxfPXxDQe26AOs8BeB1NOwf7JUsd7/j7mf83ABNCngYElJWVzpg5kxASER5ee7QKYvCPt/2PnWrq6ttdtvL3T2ucH7A5bDaHzXs6f8H8z58/S0pKUkeGlbV1VVWVy++bCwsLKyoqvDw8eIn5d2Rz2By+TOrMXEB6Xq/2w4cPklJS/W1sqJ5jYuIrNpvNZDITExP5/xDLysnm5OQQQsrL/v/TwycBT1JTUrV1dNy9PJlMJovFinv5kpGRoaevTwjJzcnhf+P1VYzDYbPZHMEV46Wvr3Fq14SXofBVotrH1NRURERk3197qO3l5WVlZWVfbWdOXW+Nv9EEfKxVVVV1ns2Ym1sUFxdv3bylsLDwU1qa+6lT0tLSVtbWOro6ly9d/LdjHqegqDh06ND68mcymdV8f7zqrHadBQnT7AIOMP73LuDTgebo8bNYrJKSkvq6a83X+/zWEgV3zpq2Q9/4XnJaalpKSor9okU0Go3NZoeHhQ0cNBAxuMWRk5O7dfeOnr7+vNlzTh4/fs/P/+zpM5s3bVq3ccOChQsIIeFhYRFh4TFR0aEhIbze4rhx42fOnk09VVFROXrcLSgoyLx3nwHW/TU0OhkbG1M7xkRFR4ZHhIeFxcbEBD0PTIhPCAoM5C+dP3PB6e/fu3/y+HGfq1c93T28TntTnd+p06dlpGcMsrHZsHadgYFBQUGB391/fpxgYWkZExO9crkTg5HBf9Ruc9lyzdf34P79TitXSElJ9TIx6WpkNGfmzAP79nfoIJ2bm+vl4UEICQ0JeRn7IjQkNCoyMioyMjQk9GXsi+Cg4IT4hIBHj9++eRPw6HF9FeN/U/U1Tu2a8CpZX5Xqax9VNbUDrq737vlbW/ZbbO+Ql5fHZrH87/rxt3NoSEiNfePj4p89fVrjw+VvtPpqHhQYGBwY9DoxkRpaXOMWxs7du/z9/Mx791ls7zB5ylQajSYlJeV5+nTcy7hdO3Ze8/X19fE5fe5sB2npOvOPCA9/9PDh2zdvPE65f/z4sb5q11nQV5td8AHG/94FfDrQ5D3+8rLyo4cPi4mK1ddda0Dvs8ZpQ40eOX9f7ZtKFNw5q6/3XOf5gOCKCXMOIKCX/M9J8JMnioqKQ4cNI4QkxMeL0WgKCopvXr9uL0dbqxtFxuFw0tPTX79+XVFR8dXElZWVtTfm5eWx2ezmqNvcWbMP7t9fXFxcXFxcuybU8Nfy8vIaLxUWFlKDLWsoKSmpkU9hYSHvpaaqmDCNU7smDa5SdXV1dlYWh8Op86MRXu1G+9aPtaqqKicnp/b20tLS0tLSJjxs6iuowZnXeO8CPh1ozAG2a+cfUydNPuHm5n/X7+zpM+4nT/Ha+ePHj7NnzPxj+w5fH5/fnJ0/fvzI5XLDQkOtzC0GWFmHhYbGREcPHzykTy+TwOfPuVyu/10/s969rSwsF9nZ/+bsPNC6v9+du2GhoTb9rKzMLUKCg6lsH9y/38XAYMWy5e+Sk2u8+k0l3rp5c6Gtra+Pz5+7dh0/dqzGW2MymePHjB0zcuT+vfvcT54yMuzs6e5eo/Qau9RXsZDgYPPefQYPGBgZEREZETF4wEDz3n2CAoPi4+LHjx7Tw8j48cNHXC73+bNn1pb9DHX1+pr29rtzt0bmC21td/+xi3p8/949I8POF86daz9Hmsg33acEwebNnmNmbrZ67VpUDKBtnKIwGIzysjJ9AwMxsZr3canTWRkZGWGyYrFYBfn5KqqqTCZTwC+Mi4qK+G8eN6ZEqivJG4ZduyA6nU4l4/3eV0DpgismjPz8fAUFBdGvTe5RUlJSX53bJBq+Zk2IwWBkMjJRMYC2QURE5KeffqrvVSFj4T9/amk0VTU1QojgKT6ouNgkJQqeSYNXEH8yAaULrpgwlJSUhEnWrgIwIQTnwU0mJDiEkZFOCDEwNGxRY+tbbMUAANp7Pw8xGAAA4IfAvNsAAACIwQAAAIjBAPWJjIj4prk8AeA727Xzj9o/iwfEYGj14uPi586affvmLTQFQMuUkZFx7syZY0eOsjFvGmIwtDEn3NwIIZ7u7vh6A7RAbBZr6+YtKqoqOdnZbsfc0CCIwdBGcDgc1wMHHj96tNnFJTU1dcP69fWt9wIAP8TLFy8c7OzCw8IOHTnq/NtvRw8f3rp5y6e0NLRMS/b13yZxudzsrOyioqLi4mL+ebehTRITE2Oz/zOba2VFRXJy0s3rN1LTUl22bZtna/v0yZNVP/8iKyc7Zeq0Hj17dOz4n9/U02g0LB7QhklLd5CTk9PU0hI81wQhhMlk3rp5M/5l3JfCLyX/XTAKGqmDjEwF35InFRWVGRkZ2VlZXY26/rF7N7WK5Y1r1/ft2ZObm6ujo6OiqiohIf6f0y9RsToXp2nPKioqGxPjOnbsSKfTVVRVh48YYTPApmlisK+Pz8F9+6nZuqE96NK1a3JSUo2NioqKY8aOnWM7z8jIiNqSkZFx6cKFO7du115evpdJr/i4eLRk2yYpKTl/4YINzs71TT3IYrFmTZv+9u3bnr16Kikpy8nJ8ZbegyZpf/4LURISEqqqqlbW1iampvzJ2CzW8+eBrxIS8vPyaqyUICoiyuFicGUTKyoq+vzp86uEhHUb1i9zcmpsDI6Li5s+eYrtgvmjx4yRl1eQlu6AJm7zREVFawx7VlZR6dCh3o++qqoqLy+Pw3fqLNfoOe2gJSspKSkuKoqIiNj7518u27fNmTu3zmRPHgcsc3T0f3CfWtEdoP04eviIp7v7y1cJwkyvLWi+6OjISFU1ta3bt6NNQUB/XMCEutD20Ol0oqnZrXv30OCQ6Kio+mJwWlqqsrIyAjC0Q1bW1me8vQsKCoSZIlvQefDTJ08+f/q8wG4h2hQAanj+7FlJScn4CRPQFAANhvmiAQAAfgz8NgkAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAABCDAQAAADEYAAAAMRgAAAAQgwEAABCDAQAAADEYAAAAMRgAAAAQgwEAABCDAQAAADEYAAAAMRgAAAAxGAAAABCDAQAAEIMBAAAAMRgAAAAxGAAAABCDAQAAEIMBAAAAMRgAAAAxGAAAABCDAQAAEIMBAAAAMRgAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAABCDAQAAADEYAACgraOhCaDB7vvfi4+PQzu0K9OmTzcwNEQ7ACAGww/2/NkzP7+72lraaIr2gMPlJCclm5mZIwYDIAZDi2BiYnr+0kW0Q3tQVlZm0r0H2gGgCeF+MAAAAGIwAAC0bx8+fPj86VODd6+oqIiLa02DVHAtGgAAGigqMvL8uXP+d/109XSHDR/xpaAgLy+PxWLNmDVzzNixNNo3h5g//9hFp9MPHHJtQGXeJSf/vGKluLj4HX8/xGAAAGjjzC0s1NTU/O/6jRs/fvXatdRGv7t3XX7f7HHK/fyli3Q6/ZsyPHT0iJhoAy/Qdu7SZfLUKX537raiBsS1aAAAaDhJSUlCiKysHG/LuPHjd+z643Vi4l+7//zW3Dp27NhBWrrBlREhIq2r9XAeDAAAjSXy39g3bvx41wMH7t65s33nDgkJCUJISUmJ79WrklJS0ZFRM2bNtLK2rqioOOF2XFVV5V3yOyVl5V9W/RoUGHj71i06nb7ZxSUsNPT2zVscDse0T28vD48Drq4mpqa1MyGEVFVVnTpxQlZOrqS4JD6ulc1YgPNgAABoet26d68oL8/OyqKe/uzkNGXatLnz5s2bb7vccWlBQcF1X9/cnBzbBQs2btpEpTG3sMhIz8jLzSOEGHfrlpGRERQUpK+vv8HZWU9fv85MCCG/rFxpYmpq7+Dwy6pfZWVlcR4MAADtHZvFJoSIiIoSQl7ExjIyGDev3yCEVFdXa2lrf3j/XllF5fr1az9pai5Z6rh8hRMhREpKSktLq6qqihAiLy9vZGwsJiZm2a8flWGdmTA6dIiJjjnp7k6l6dK1y/v37xGDAQCgXUtKeisnJ6ehrkEISXqbpKWtbedgT720ZKkj9WD9ho2uBw7cuH5t/8GDvfv0qZGDqKiICN817joz+fvyFTk5OV4yUVGx1tVKuBYNAABN7NHDh6kpqfPmzxejiRFCpGWkE+LjmUwmL0FyUnJOdvZixyX3Hj7Q0tJebO/AYrEE51lnJgqKCpkMRklJSSttKMRgAABoOOrSMfU/5cH9+5s2Oo8eO+bX1auoLVbW1lVVVS6/by4sLKyoqPDy8GBz2E8CnqSmpGrr6Lh7eTKZTCoGszlsNofNy7myspKXbZ2ZmJqaioiI7PtrD5WmvLysrKysFbUerkUDAEADRYSHXzh/nhDy9+UrOTm5JSXFRYVFcnJyx0+esLC05CVTUVE5etxt00bna7370OXld+zcaWxs/C45eZvLlgmTJr1LTnZauUJKSio8LCwiLJzNZoeGhLDZ7ODAoNzcXF8fn+kzZtSXCSHkgKury5bNjx8/7tatm5q6GpvF8r/rN3b8uFbRgCJcLheHETTMpg0b09PTsWZDO0Gt2eDu6Tl0+LCWUB8ul5uRnl7NYuno6IiK4pJe65Cfn6+goMD/eZWWlnK53G8az1w7ExaLVZCfr6KqymQyqd8r4zwYAKBZlJeVH9i/Lzsr28LSkiZOO3rosISExKbNv3/rlEzw/SkpKdXY0rFjx8ZnQqPRVNXUyL8ThrQi6DwCQCsLwJPGj+dwOMdOHF9gt3DuvHkHDx/q9FOnsaNGfyn4InhfJpN58sSJxpTe+BwA2mwMTk5K3rl9u6GunkWfvufOnG1dd+YBQBh79+zJzc1dv2Ej/0anlSu5XO72rVsF7MjhcHbt2Pn29ZsGF934HADacgzu0rXLZhcXGo02cPCgBXYLZWRkmjBz9H8BfjgOh3PN19dmwABpmf9MKUyj0YYMHeLv51dRXh4WGjpq2PCtW1wIIXEvX06ZOHGlkxMh5ElAQHBw0MePH894n87MzHyXnLxz+3aPU+4H9u0fNnjw9ClTIyMiqNyEzAEfByAG1yQiIiIhKUFNT9q033z0f1ujRq5FCi3Np7RPFeXlGp061X7pp59+4nA4SUlJVtbWnbt0qayoIISYmJqamPYuLysnhAwfMcLMzFxfX9/OwV5DQ6OsrMz/rt/9e/cmT51y884dfX39RXb2OdnZhBAhc8DHAYjBXxEUGLh+7dq/du8+7eU1bvTocaNHf3j/nhBSXxcY/d/WJSE+wXHxYkNdvVHDhl+98nftQf5//rHr0EFXNFSbUV3NJISw2XVM5kD9urS6upo6LeZtF69nCVvT3r119fRsBtgYGBjIyspu3bGdy+UGBATwTqy/mgMAYvBXmJmbp3xMCQsNGzZ8+IVLlysrK8+ePkMIqa8LjP5v69KzV8+169YTQiZPnTJz9iwRkZrLlh06euSP3bvQUG2GvoGBlJRUJqOOfjAjgyEiItKte/dv+PPH9+MWGRkZPX390pJSNDIgBjeZDh06aGpqGhkZaevoKCgq2AwYyGAwBHeB0f9tXeTl6YSQ+u4+NHItUmhpxMTEJkycGBwcTHWOedgs9tMnT4aPGMEbBdKAmQ+qKiuNuxnznmLuBPgO2leMkRAX53A46AK3E/xrkVKPlZSU1NTUfH18CCFHjh0zMDQkdS1rSgh5/uxZTHSMkpJSRHj46rVrOnfpUudqpmjk7+93ly0RERF79+zZtmM7b+Oxo0fExMR2/nvNQ0pKKiEhns1ms9nsxMRE3gzDsnKynxM/E0LKy8qpUV28GRY/fPggKSXV38bmW3MAQAxuAvxdYPR/2wZzC4sTbsermdWEEDNz88Ouh5KTko+6HZs8Zer0qVPOnj6zY9cfhJCfnZwOHT0qLy/ftWvXRXb2TwKfKyoqbli77uhxNwtLy6Kiwr1/7fHw9jLu1u2E2/H3799PnT6Nt5opfH8dO3a84++3f+/elU5OFhaWNHFadGSUuLi4/4P78goKVJqp06fdv3dvkI2NmZm5gYFBSEiI392748aPt7C0PH/u3MrlTqvWrDbs3JkQcv/efXl5eSVl5diYWK/T3rzbGcLn0M7V2Tets19bUVFxwu24qqrKu+R3SsrKY8aOuXL5srq6RnFxsb/fXQUFxQ3OG3nTW1ZVVXm6e9DpcgwGIy83b+36dWrq6vX1pGvk/MuqX+vrWyMGNzsul8usYvIvrME/Azibw+b8+7i+LjD6v20G/1qk1F0JSUlJbR0dQojNgIEZ6emknhVJFS0s3L08u/fowWKxKisrU1I+krpWM4UfRUZGZuv27Vwu9/OnTyw2e/acOTXmqrSwtIyIia6oqJCXl6+oqOjQoQO1feSoUZExMfxL3U2aPGne/PmEkBkzZzYsh3auzr5pnf3a676+uTk5a9atLS8r9/TwoAbldPrpp70H9jsuW7pz2/ZFdvYBz55S0105LV02c/asUaNHE0IO7Ns/d/bsew8f1teTrpEzVbE664AY3Lzevn379+XLLBbr+bNnZ7xPz5g1MyE+PiYqmkajhYeFSUhIBD0PLCgoCAoMHDBwYH1dYPR/2wPeXYn6ljXV0dU97HpIWVlZSkqKVf3PKNwaq5nCjyUiIkL1qOokKSlJTVvIC5+U2vNZ1jdTsfA5tGe1+6b19WuVVVSuX7/2k6bmkqWOy1c4iYuL6+rpWVhaGBgYEEK27tju7+cXEBAwZ+7c2JiY4KAgd09PKkPb+bYn3NyePA4YPXZMnT3pGjkLqANicPMyMjLaun371u3/v0vUz8oqNDKC9/TR0yf86evsAqP/2zaEh4X1s7L6ajLeiqS8UV3JScn6BvqTJ0w8dOSwae/ely9dQmO2VQwGo84h1vBNavRN6+vXjho9ev2Gja4HDty4fm3/wYO9+/Spb1BOUlKSqKgotfAwIURNXZ1Op6empdbXk66dc311aOGL1coAACAASURBVImt186PHllZ2dq9YElJSXl5+Tr7vwjALc2XwkJCSGnpf8bTnfE+XXst0jrvStS5Imncy5eMjAzqqlpuTg5vHF+N1UyhVQsJDnFa4WRuYR4bE4PWaEK8fi1vS3JSMiEkJzt7seOSew8faGlpL7Z3oL6h/HiDctTV1aurq9NS0/75trLZLBZLS0urvhJr51xfHXAejC4wNKW4uDi3o0cJIX9fvpLJyBQVE62urn7/7l16enp4ZBT/WqSioqL13ZWovSJpdXV1VyOjOTNnDhs+Qk5OLjc318vDo0vXrjVWM4VWrb9NfzRCk6jRN+X1a51//01SUvLShQvWNjaEkCcBT/pZWenq6bp7efY1MaVicJ2DcqysrXV0dS5fuuj822+EkPi4OAVFxaFDh9bXk66dc311aIHa6frBIcEhjIx0QoiBoWGfvn3xLWqYtrR+cO0VSYuKiqg7f6WlpQ1YXq3taWnrB7dhHA4n6e3bFy9epHxMSUtNKS0tKy8vJ/9et9PT19M3MOjb10xXT/eHVzUoMHDH1m25ubmbt7rw+qaBz59v2uick51N9WvHjh9HCLl969Z1X98Jkya9S06m0+nLV6yYN3tORkbG7DmzqUE5q9espgZkEUJSUlJ+2+jco0cPo27GsTExix0d9fT0wsPC1vy6ikaj7T2wX0JCYuO69QUFBYeOHvny5UuNnOurA2IwIAYDYnBzYbPZf1+5Mmfu3PruGX348CErM6vFngGz2eyw0NAb168/f/a88MuXDtLSenp6enp6snKycnJybDanrKy0IL/g48ePaamp1dXVGhoaI0aNnDJ1Ws9ePVtFv5bq0XK5XOoO4LzZc8zMzRY7OpJ6RsZRa98JufoOf86C69Ci4PfBANBGzh23bXFZ6rRcwKANAwODF7Gx/nf9WtpZEZPJ9PXxcT95Kv3z5x49ezouXWplbd2tezcxMbH60r+IjQ0JDrl75865M2d79OzptHLF8BEjWlSwUVJSqr2x9iWl+salCx9968u5vjq0KO1rTBabzb508SLv1J/D4WRlZlGTvFN95JDgkKYtgurKlZSUNF8RbDY7KzOLzWY3YREArc6Bfft6mZpoamoKTjZ9xoxrvr6vExNbTs0fP3o0YsjQndu2W1lb33v44Oad247Llvbs1bO+AEwIkZCQsOzXb826tQHPnl6+elVVTXXFsuXTJk9OiE9oRR8ZBuW0rxhMdZMHDhpEdZM/paWtX7P23bvkvX/tCXj0mOojZ2Yy/O/6NVURhJDbt26NGDL044cPvG540xZx2tvbzLS3jZWVRZ++jx89apIiAFodBoNx4/qNyVOmCJN43vz5B/btbwnVLi4uXrncadkSR5PepgHPn/2556/OXbp8Uw4iIiLmFubunp4379wWF5eYNnnyX7t31x5y3AJhXPo/uO3G3r/+uvr339RjFos1dtSohPh4LpdbUVExyGbA50+fqJccFtolvnrV+CKqqqrOeJ++dfOmgY7uyxcv+JM1VRGPHz464ebGZDJzc3MX2s7v08uExWI1vgjhOa/fYDtnLhfah9LSUgMd3YBHj39gHb58+XLY1fXQwYPU02u+vvf8/blc7r6/9jgtXcZf1Qvnz2/auDE7K6sgv+Cv3bu3bnHhf7WLvsH7d+9+bHsmvno1yGaAZV+zZ0+fNkmGHA7n4oUL3bsaTZ8yNTs7G0dsqyDaPrvJ0VFRjAxGj549CSFSUlJdjbrevHGzkX3kGkVISEgstLebOGlS7SV9mqqIisqKZU5O4uLiysrKq9euKSoqys3JbWk9/e+poqIiLi6Od03+86dPLbCSLbZirYK8vHyPnr1OnThZXFxMCJGWlo6JiiaEhIeHG3frxksmIyNDp9MfPnhYUlp6986drl2Nbt24wf+qlrZWdFT0D3wj4WFhc2fN1tDQuHPPf9DgwU2Sp4iIyNx583xv3sjPz585bXpqSioOGFyL/q7KysouXrjwm7NzTnY2ddl25/bt1GKFl85f6N27t7i4OJUyLDRUUen/c4cqKiqFhvxzD9Wyn2VwUNCH9+8bWQT/F6PGlqYqYvyECby9OnSQlldQUFFVEaaINuldcvKUiZM2b/qNevrnH7sOHXRtgfVssRVrLQYNGiQlJRUdGUV1oEeMGkkIYWRkKCgq8CeLj4s3NTWNjIiYv3BBYWFhjZ8gyssrfP78+QcG4EV29tb9+585f05FRaVpMzcyMrp6zVdeXn7OzJmf0tK+/4XVjIyM4KAg/o21R8nU7pi221EsbSoGU53fB/fuKykrE0JiY2Kv/n2VOsRrdJNzcnIUFPhjsEJOTrYwfWThixBczyYv4smTgBU/r+QN4mgJPf3vrHOXLpOn/v924KGjR/74dyW7JsRkMk+eONGYXZqpYu2HGE2sl0mvxMRE6tthZm7O5XLz8vJqzGr3NCCgrKyUmoY2IjyctyAPRVpaOjOT8UPq/zoxcdkSx0GDBx897kbNR93klJWVz1+6qKyiYrdgYV5e3vd8d1++fDm4b/+Ordt4W2qPkqmtPY9iaWvXol8nJlpZW1Oh6NaNG/369aPOGmt0k8VExdjs/w9bYLHYYmI0IfvIQhYhWNMWkZqS+vnTJ3sHh5bT0/8hRMj/v+QdO3bsIN3Ey1txOJxdO3a+ff2mMbs0R8Xamx49er5OTIyOih42fJioqKiIiIiSklJFRQUvQVpqWkpKiv2iRTQajc1mh4eFDRw0kD+H8vJyVVXV71/zoqIip6XLjLt1cz1yWMCw58aTlZX1PnuGw2av/uVX3o8mvgNFRUUZGRn+tcVa73j176Ot/T446HngHNt5hJCMjIzbt26tWbeOujxSo5usqKT45Ush72nhly/8PyMT3EcWsgjBmrCI0tLSo4cP//Hn7m8qos2oqqo6deKErJxcSXFJ/L83g6l1Rul0+mYXlzrXFs3Ly/P29BQVFXudmDhx0iQ1dTVh1kB9EhAQHBwkI9PxjPfpUWNGa2hofHWN0hq7vH/3jlex58+e3b51S0OjE51Ov37tmpyc3OGjR589fXrh3Lnq6mrXI4e7de9OWs8yqN9T9x49bt688SohgTcpv76BQT7fCd/TJ08UFRWHDhtGCEmIjxej0RQUFN+8fs27jJSfn69vYPD9a/7bRufKysojbsea6QyYn4qKyhE3t1nTpx8/5vbzr798t/cYFxfHWyOBGsLyPDhImB2pUSxeZ07jPLi1ys3NffPmjY2NDSEkOipKRETEZuAAQkjtbrK5hWVRIV8MLio0tzAXpo8sfBGCNVURbDb74P79Gzc5U7GZf47yH9XT/85+WbnSxNTU3sHhl1W/8n7sb25hkZGekZebRwih1ha1XbBg46ZN1KtMJnPe7DlzbW3XbVg/aPDgv3bvNu7WLSMjIygoSF9fn38N1CnTps2dN2/efNvljksLCgqGjxhhZmaur69v52CvoaFRZ5oa1auxC3/FLCws3r97HxYaOmbc2AuXL2UyGMuXOpqZm138+4qklJSXxz8Lt321iPZ4HtyzB4fNmTJtKm/LlGlT+X/i8uzpkynTptFoNEJIdnZ2WWlpwONHvACcm5ubn583esyY71ztx48ePbh/f++B/U1+D7g+vUx6rVqz5vixYx8/fmzWgrhc7oP79+/cvn3a2/vt2zcW/64SyD+EhX+ky5eCL3v+/HOby1b+TNrhKJa2FoNjoqJV1dS0dXTu3L4tIyMjLSOjrq5O/Wi9RjfZsp+lopLimzdvqL/ISW/eTpg4kfcqfx/54YMH6enpDSiCd2iy2KzS0rIa25uqCLejR+3s7alJVrMys06dOClMEZTzZ89lZGRQjysrKz3dPaiZ4QghOdnZp729W/48pq8SEmKiYwYOGkQ97dL1n99WSklJ8VZZodYWPXbkqBhNjFpb9J6/v4yMNHVxbIHdwjv3/Kk1ULt27WrZr9/IUaPk5OR464+e8T4dGxNLrT9ao3Rh0tTAX7EO0tKdOnXq3r27pqamkpJSfxsbdXUNw86d6XT6oMGDqVF4DSiiPcjPzz94+BD/Or4TJ01iZDB49z7PnD+/6fd/RueNGj06MjaGWqWUct//3tx58wRMz9RMF2x2bts+dvw43uH6fSxaslhPX4//Bm2TY7PYG9etJ4RMmDiRWcXU1tLmTfvMP4RF8GB10i5HsbS1GNxBukNRYeHWzVvMzS3Ky8tLSkquXLrUo2eP2t1kcXHx4ydPeZw8FRwUfGDf/jXr1xl27ly7j8xisdavWbvIzr4BRRBCnj19+ueu3WwW2+PUyVs3bvKWFmmqIk6dOHn08JERw4Z1NTTsamBoY2XFmzZWcBFU0D3s6koNLiWEZKSnH3Z1/fjhn87yy5cvDx905U3v1WIlvkrkX9FZVLSOG2zU2qIn3NzGjhr1KiGBEJKWmqry7xUCERER6qSkvjVQ7Rzslyx1vOPvZ15rAfA60zx88MC8Tx/q34d/52YRBv+IenFxcS6XI2Q12psvBV9SU1JrLA4tISGx7+CBE25ude7CH27Ly8oDnz+n7u98T9d8fXNycjb9/vt3LpdGo/22eXNwUFBMdHPFNrdjx0REREaNHk0I+fQpzaLf/4e/1RjCIniwOmmXo1ja1P3gQYMHR8bGUFOMTpw0afCQIXJycrxusvuJk3l5ecrKytSWrkZd97sezMvNtexnyf/nj7+PTKPRwiIj/9q9u2FFDB4yZPCQIb9trvmta6oili5ftnT5sjqbQnAR1AlZREw0b1SIgaHhy1cJvKcjR40aNnx4s44ZaRIKigqZDEZJSYmAcxpqbdGRo0a6bN6y2N4hIiZao1Oni+cvMJlM6qfbFeXl1bXmFeKtP8r7eXdyUjLvPFtAmiFDhz4KCPjnT/+/H1yDCVON9iMuLu73jc5W1tabNtcRyUxMTXNycu75+Y8ZN7a+HFgs1onjx3f9ubv2r/abFZvNdj95asq0qdQtjO/MZsAAE1PTk8dPeHh7NXnmOTk5HqdOXb1+jRBSXV396MHDzVtdeFcBawxheRoQoKyiXN9gddJuRrG02fNg8t85vuX4/gLW2U0WFRVVVVPjD8C1+8iZmYzhI0c0uIjaWkgRhJAaIVbw05bJ1NRURERk3197/nnj5WW8y+m8dUafBDxJTUnV1tFx9/JkMpksFsvc3KK4uHjr5i2FhYWf0tLcT52Slpaubw3UwsLCiooKLw8PKjdZOdmcnByqketMIy4uLq+gQP2j2pB/F1JrAdQ6H3M4bDabI6Aa7VP37t33uR78bcvm+lYmGDFypGFnQwH3ULIyM51WOPGulH43YaGh6Z8/OyxaJEziF7Gxjx89Eubfi9hYISvgsHhR4PPn2VlZTf7WQoND5OXljY2NqSt/hYWFlv9G1hpDWL46WJ20m1EsbTkGC2BiatrPyuqen/839ZE7SEsLf/+mbRTRiqiqqR1wdb13z9/ast9ie4e8vDw2i+V/1y88LCwiLDwmKjo0JERaRnqby5Zrvr4H9+93WrlCSkpKV0935+5d/n5+5r37LLZ3mDxlalhoaHBg0OvERF8fHypnFRWVo8fdgoKCzHv3GWDdX0OjE/VXxsLSMiYmeuVyJwYjo740NfDvwl+x0JCQl7EvQkNCoyIjoyIjQ0NCX8a+CA4KTohPCHj0+O2bNwGPHgtZRHu5akejGRsbC/iZKSGkc5cuAhJoamn9kB+G3bh+vWevnrwbXoLJycn97rxp2RLHFcuXv3n9Jiszk/cvk5H5OjHxnp//xnXrly1xdPl9s5AVGDZ8uLS09O1bt5v8rX369ImaGignJyfx1SuqhXmjFviHsNQ3WJ0/tx81Xv1Ham+TcyYnJXE4nDpf+vzpU3lZGYpodfNFV1dXZ2dlcTicysrK+tKUlJQUFxfzb6mqqsrJyflq5nl5eWw2m39LYWFhjcavnaaG2rt8q68W0U7mi26N2Gx2XxNT95OnvukLbt67j4GO7oSx4758+VI7QX5+vu2cuT27dRM+zzW/rpo9Y2aTv7u4l3Hduxpt37o14NHj27duWfTpS02JRfG5enWhrS31eKGt7e4/dlGP79+7Z2TY+cK5c/xZ5eTk9OzWrcb3tM0j+IYA1mwAxODm8yohwUBHl1ohRnhv37w1693bQEd34rjxhYWFtRNkZWb27NYtNzdXyAyv/v23kWHn5uigFxcXV1VV8bqbNXq6I4YMrbOStWPtuTNn/9y1C2s2AABAk3n58qW0jLSQE9nydDXqeu7iRXl5+cRXr+zmz6fWqOCnpq4+ZszYtNRUITO0sLCsrq5OTHzd5G9QVlaWd+eL/wdjgoew1BhH+aPGq+N+MABAW5by8aOenn4DBjkaGxufu3iBTqcnxCfYzZ9f+7eCy1Y4qQk9vkxLW0tSUjIl5eN3fvtfHcJCftx4dcRgaOleJyampKSgHQDqk/jqleBVAj99+qSrq9uwzLt17372wnk5Obn4uHi7+QtKS0v5X9XT09P8d8qXr/+tFxXV0tZOS613JaWCgoLgoODmaKIWO14dMRhauojw8JFDh82bPcfn6tWioiI0CEANoSGhI4YOnT93nq+PT+0rxoSQ4qIieXn5Buffo2fPM+fPy8rKxr18ab9gIe/Xdw0gL0+vfTJdVVX14P79n1essOlndenChWZqpZY5Xr0loOErJKRrvr4tf+7GJhcXF8flciPCwyPCw11+32zdv/+AgQP72/Tv3KULDon2KSE+vuAL5qz+T4Nwudyw0NCw0FD+7wjvl0hlZeXSMo0KML1Mep05f26h7fwXsbH2CxaeOXeuYRl27Chb+m8MZjAYIcHBIUHBz54+5Z1eZ2Rk8H6e106MGzfux4Z/kXYYVxrYj9PTR1vxaOvoTJs+PSkp6UtBwflLF394fSrKy1PT0jQ1NXkDPYqKihgMRnv+NW2TKysrM+neQ9/A4OO3zMHZbunq6k6dPm3KtGnLljhaWVs5//ZbIzOMjYmxW7CgvKx88JAhnqe9G5CD/YKFdHm6lZW1r4+P8PN7tG2BoSGdOnXCeXAr4LJtWzuMweFhYQ8fPKAei4qK9u7Th+rj9zIxERMT27Rh45cWsIzPyePHpaVlVFVVZ02fvnff/tFjx0SEh/+yYqWVtfWho0dw6DatESNHqrXL+3b1CQ0JffzoIe870qdvnwEDB/W36d+zVy9qHJa0tHRZaVnjC+rTt+/W7dsP7N23dsP6BveidPV0Z82ZPWvO7NSU1JDgoOCg4OCgIN5UVkZGRjNnz25XH588Xf7HVgAxWFjzFy5oh++azWY9fPCgl0mvCRMnjhk7Tl1DvaXV8OmTJ/5+/rf97hJCOsp2VFZRIYRY9us3aPBg3kqOTCbT28tr2fLlOIwbr2/fvkOHD0M78FRVVT1+9NDExGT8pIljx45VU6/5HVFQUMjPz298QVGRUVev/O1780aDz9sK8vN5d6Z19XR19XTnzZ9fUV4eEBBw+9at50+faevoLLBbiM8UMRhaij59+972u0stJt8yPXkcoKenRz22GTCAt503AITD4ezasRMDyqCZmFuY3/H3E/DzX1093adPnjaylDu3b/teveru5VnjB7jCq66u/pz+WfffLwtPB2np8RMmjJ8wITsr6/Xr1/hAEYOhBTExNW3J1Xv08GFcXJw4jXbG+zSLxbpz+7a2jvbR/04I8CQgIDg4SEam4xnv06PGjNbQ0CgpKfG9elVSSio6MmrGrJlW1tZhoaG3b97icDimfXp7eXgccHXtZWIya/qMcePHL7S3w2EAApj27i04gb6BwRnv0/yLX32rk8ePv3r1yt3LS1JSssZLOdnZHTvKCjNE6+OHj2wWW1+/3tmY1dTVa5/EQ3PDb5OgFRsxcqS+vr5h5852DvaLHZeYmprWvvE2fMQIMzNzfX19Owd7auW4n52cpkybNnfevHnzbZc7Li0oKDDu1i0jIyMoKEhfX3+Ds7Oevr6IiEjPXj21tLXRyNBIfc3MmExm3MuXDdiXzWL/5uyck5Nz5Nix2gGYEPKb86aycqFuNkeEh0vLSBt3wyhFnAcDNA9hzjNexMYyMhg3r98ghFRXV2tpa394/97cwsLI2FhMTMyyXz9eyi1bt6JJofH09PTUNdRDgoPNLSy+aceysrJfVqzsZ2W1ZKljnQnevH5Nrd8lTG4hIcEWFpY0Gv7mIwYD/DhJb5O0tLXtHOypp7y/bqKiIoIXxQNosOEjRt65ffvX1auFP8ays7KWOTouWGg3cfIkNvu/i0ZzScGXgpjo6F07dg4eMkSY3IqKioKeB27dvh2fBWIwwI8kLSOdEB/Pf3MuOSm5S1dMOQLNaMq0qRfOnYuJjjEzNxMm/du3bxfZ2WdnZa1fu3b92rUCUlr0sxQmw7t37oiIiIwZN/arKblcblRkpIWlJT617wP3g6F1Y3PYbA6b95jD95i3XVZONicnhxBSXlZuZW1dVVXl8vvmwsLCiooKLw8PKllVVVVlZSV/zhfPn0+IT0ALQ+OZmJh079HDw/2UMImDAgNnTZuenZUlTGJLIYIlm8Xy9vQcN368nJzcVxNzOJyTx0/gI8N5MMDXhYaExERF02i08LAwCQmJoOeB+fn5z54+lZKSiggLZ7PZoSEh1v37W1hanj93buVyp1VrVht27nz0uNumjc7Xevehy8vv2LnT2Ng4KDAwODAoNzfX18dn+owZ1NmA2zG3qdOm9ezVE+0Mjbd8hdPPTivevH791UUMf9LU9L1xXZg8RUREhFnn4Pat2+mf0z28vfEptECYqxIabtOGjenp6S1hrsqvKioqkpOT478bl5+fr6CgICpa76WgxvyYpE2i5qp09/TEHB0NwOFwpk2eLCEhecXn6vcceVBaWjpy6LABAwfu2b9PcPVYLBZ10rx86VJ3Ly9qO74COA8GaAK1ZzZQUlISvAv++oBgDgvtam/cuGlTV6OutbeLiopu27lzxpSpVy5fnjN37ner5L49e6uqqjZschacLCEh4aTbcUIIh8t58/rNryt/pra7nTwhoJ8KiMEAAD+G99kz35TexMTEzsFh984/+vY1+z7DAB/cv3/x/Pl9Bw58tcdpYmJywv0UIYTNZi9xWHRCuFvX0Hjo4AAAfCcbnDd26drVaenSguZf7OTt27fO6zdMmz59yrSpaHnEYACA9o5Go504dZLFYi22t+et2tsc0j9/dlho19Wo6/Y/dqLZEYMBAIAQQlTV1LzPnWVkMObNnpOXl9dMZ8Azp89QUJA/5ekpJSX1TfuKiYl96zV2QAwGAGg19PX1r/j4FBUVTZ8ytcl/g/7wwYM5M2Zqa2td+vvvBi+yBIjBAABtlq6ers/1a506dZo1fbrHKXc2i9X4PEtLS7e5bF2xbPmIkSPPnD+PAIwYDAAAdVNRUTl/6eIyp+UH9++fNH5CSHBIg7Nis9k3r98YOWz47Zs39+zft/fA/m+9BA2IwQAA7YuYmNgvq1bdvX9PWUV5oa3t9ClT/e7eraqqEj6HoqKiSxcvjhw2bMO6dQMGDHj09MnUadPQsIjBAN/Dp7S0P3ftvn7tGvX00cOHWZlZhJC4uLjjx44RQqqrq0NDQkKCQ6qrqxuTDyUnJycyIqIxmeTl5V3z9b175w6TycTHBxQDA4Mz589f8fGh0+mrf/m1n5n52tWrr/n6fkpL43A4tdOzWKzkpOTzZ88tW+JoZW6xa8fOvn3N7j9+tGf/vq/+DhgQgwGajLaOTmlpycvYF4SQsrKyrVtcPn/+TAhRVFAIDgrmcDirf/lVW1vbwMBg1c+/1FwATuh8qL9613x9F9rODwkObnAmyUnJ69esTfmYcvTwkTqnWIL2zMzczOvM6cCQkOUrVjAyMjZv+m3ooME9jIzHjho1Z+asJQ6LHBbazZo+Y8SQod2NjMaOGrVv757q6uqt27eHRUXuPbBfX18fbdgaYZ4saN00NTXfv3tPCDl/9qyYqGhWViYhpJrFGjN27PNnz0RERTS1tAghHTt2fPzo0ajRoxuQDyGkqqpq3PjxmYzM6mpmwypDCImKjPA+e0ZERMR2/nwbK6uCggJFRUV8gsBPXUPdcdlSx2VLK8rLX71KTPn4MT09vaAgv7ysnFnNLCgoMOpmvOLnn/UNDLp170aj4Q84YjDAD9Whg3RpWemb168NO3c2MDSkLv/e9/d3XLZs9x9/qP27qoyqmlpQYKCAGCwgH0KIjIwMIURcXFxwDBacybz58/+tjKq8vLysrCw+Pqj3WJKWNrcwN7cw521Jeps0bvTozl06T546Be3TZuBaNLRu0tLSJcUlIcEhw0eM0OjUKSsr8+qVv8dPmECj0bKzsuXlFahkCgry2VnZDcunSSrDnyw0JMRh8SJxcXF8fACIwQCtmFQHqffv3lFnBhoaGs+fPVNUUtTW0SGESEhI8IaYVlZWSkpK8vZ6+OBBenq6kPnUp2GZFBYWBj4PXL5iRX2ZEELOnz2XkZHBq7mnu0dZWRn1NCc7+7S3N5YcBUAMBmgR58Gbfv9dWVmZEKLRSWP6jBnDR4ygXtLW0S788uXfyFekraNNPWaxWOvXrF1kZy9kPnVqWCZsNvvUiROrVq+mVpCtM5PKysrDrq7RkVHU04z09MOurh8/fKSevnz58vBB15KSEnz0AG0A7gdD62YzYABvOoLx48d3kJbmvTRi5Mi9f+2hHqempix3cvrnoKfRwiIj/9q9W8h8+OMum8VuTCbnzpxZsnSptIw0IeTpkydDhg6tnYmUlFRETLSYmBj11MDQ8OWrBN7TkaNGDRs+nPcUABCDAX4Y/vmAasS8Hj179rex8fXxoYnRevfu3btPH95LmZmM4SNHCJkPdf76/Nnzx48eMpnM3n36DBoymEajfWsmx48du3jhos/Vq4SQvNy8g4cP1VkTQkiNECv4KQAgBgO0REuXL6uuruZyuRISEvzbO0hLDxw0SPh8xMTEhg4bOnTY0MZk1C5OHgAADJ5JREFU4rRypdPKlTU2fmsmAIAYDNBq1Dn8uFOnTo3PueVkAgCtFMZkAQAAIAYDAAAgBgMAAABiMAAAAGIwAAAAIAYDAAAgBgMAAABiMAAAAGIwAAAAIAYDAAAgBgMAAABiMAAAAGIwAAAAYjAAAAAgBgMAACAGAwAAAGIwAAAAYjAAAAAgBgMAALQ+NDQBNEZ5WdmbN2/QDu1BZUUFGgEAMRhakLi4uAljxqIdAAAQg+G7Wr12jcPiRWiHduWnnzTRCACIwfDjqaqpqaqpoR0AABoGY7IAAAAQgwEAABCDAQAAADEYAAAAMRgAAAAQgwEAABCDAQAAADEYAAAAMRgAAAAQgwEAABCDAQAAADEYAAAAMRgAAAAxGAAAABCDAQAAEIMBAAAAMRgAAAAxGAAAABCDAQAAEIMBAAAAMRgAAAAxGAAAABCDAQAAWgYRLpeLVgAAaLHS09N/d3YuLyt/8eKFqqpK5y5dBg4atGjJErQMzoMBAKB5aWpqfvlS+OLFC0JITk5uSHCIkXE3NAtiMAAAfA9Tp03jPdbS1rbub402QQwGAIDvYdyE8WJiYtTj8RMmiIiIoE0QgwEA4HtQUVExt7DgxWM0CGIwAAB8PyNGjiSEaGppGRkZoTUQgwEA4Pvpb9OfEGIzwAZNgRgMAADflWHnzuoa6jY2A9AUiMEAAPC9mZmZ9zU3QzsgBgMAwPc2eMgQFRUVtENbgnmyAABah4ry8g7S0mgHxGAAAABoLFyLBgAAQAwGAABADAYAAADEYAAAAMRgAAAAQAwGAABADAYAAADEYAAAAMRgAABoKh8+fPj86VPLzxO+FebJAgBoRlGRkefPnfO/66eppWVlbS0iQrhckvLxw8sXL+NfJ0pISAiTyWJ7BzqdfuCQaxNWrDnyBMRgAICW5VNa2tBBg9dt3LBs+XLexr8vXxk2YriysnKduzCZTG8vL1760tJSMVHRxk8WzZ9tU+UJjUFDEwAANCtJSUlCiDjtP39vJ0+dIipa991ADoeza8fOoqIi3paOHTs2vho1sm2SPAExGACglYmOipaW7tCte3dCSEVFxQm346qqKu+S3ykpK/+y6tcnAQHBwUEyMh3PeJ8eNWb0+3fvbt+6RafTN7u4PH/27PatWxoaneh0+vVr1+Tk5A4fPfrs6dML585VV1e7HjlM5fn82bOY6BglJaWI8PDVa9d07tKFEMKfrbS0dFRUJJUnVaWqqipPdw86XY7BYOTl5q1dv05NXT0oMPD2rVtKSkpqamq+Pj6EkCPHjhkYGuITbCoYkwUA8D08fPBw+9at27du3bRh4y8rV3I4HGr7dV/f3Jwc2wULNm7aRG0ZPmKEmZm5vr6+nYO9hoaGuYVFRnpGXm4eIcTCwuL9u/dhoaFjxo29cPlSJoOxfKmjmbnZxb+vSEpJeXl4UjlsWLvOZoDNQns7I2OjvX/tqZ3txMmTeHlSnJYuM+xsaLtgwQZnZzV19bmzZzOZTDNz85SPKWGhYcOGD79w6XJlZeXZ02fwUeI8GACglRkybKjDokXUia+SkhJvu7KKyvXr137S1Fyy1HH5CqfaO0pJSWlpaVVVVRFCOkhLd+rUSUVFRVNTkxDS38amsLDQsHNnQsigwYOjo6KoXdy9PLv36MFisSorK1NSPgrOkxASGxMTHBTk7vlPCLedb3vCze3J44DRY8doampKSkpq6+gQQmwGDMxIT8dHifNgAIBWRpxGk5CQkJCQoNPpS52Wd/rpJ2r7qNGj12/YeMLNbeyoUa8SEr4tT3Fx/sdc7j/n1jq6uoddD108f0FKSopVzfpqPklJSaKiomI0Meqpmro6nU5PTUutkUxCXJx3+g6IwQAArZKsrKyiomLiq1eEkJzs7MWOS+49fKClpb3Y3oHFYjUycxaLNXnCxGHDhy20t1NRVRVmF3V19erq6rTUNOopm81msVhaWlr4pBCDAQBaN+qSb3l5Bf/G4uJin6s+hJAnAU9SU1K1dXTcvTyZTCYVg2XlZHNycggh5WXlhBA2h83msP8JkPU85nDYbDaHEBL38iUjI0NPX58QkpuTw3/myp8t/75W1tY6ujqXL12knsbHxSkoKg4dOrR2cZx/H0OTwP1gAIBmFBEefuH8eULIpQsXGBkZIqIiVAgMCw3dsMmZECItI73NZcuESZPeJSc7rVwhJSVFCLGwtDx/7tzK5U6r1qzOy8uLCAtns9mhISGEkJexL2Q6doyKjCSEhIaElpWWBgcF0+n0gEePU1NTAx49Hjh4UFcjozkzZw4bPkJOTi43N9fLw2PRkiX82faz6sfL07p/fykpKc/Tp3/b6Lxrx06jbsaxMTGnz53tIC0dHhYWExVNo9HCw8IkJCSCngcWFBQEBQYOGDgQn2yTwBwdAAA/XmlpKZfLlZWV5W0pKiqSk5MTERFpWIZFRUV0Op3Kmf+nwIKzLSsrI4TIyMjgE0EMBgAAaMtwPxgAAAAxGAAAADEYAAAAEIMBAAAQgwEAAAAxGAAAADEYAAAAEIMBAAAQgwEAAEAwzBcNANC8SkpKfK9elZSSio6MmjFrppW1NSEkLDT09s1bHA7HtE9vLw+PA66u5eXlNbYYGRt7unvQ6XIMBiMvN2/t+nVq6uq1dzQxNUUj4zwYAADq8LOT05Rp0+bOmzdvvu1yx6UFBQWEEONu3TIyMoKCgvT19Tc4O+vp69fe4rR0mWFnQ9sFCzY4O6upq8+dPZvJZNZOhhbGeTAAANThRWwsI4Nx8/oNQkh1dbWWtvaH9+8VLSzk5eWNjI3FxMQs+/XjJebfEhsTExwU5O7pSb1kO9/2hJvbk8cBo8eOqb0jIAYDAEBNSW+TtLS17RzsqadLljryXhIVFamxfhH/lqSkJFFRUTGaGPVUTV2dTqenpqXWuSO0UrgWDQDQjKRlpBPi45lMJm9LclKyMDuqq6tXV1enpaZRT9lsNovF0tLSQpMiBgMAgFCsrK2rqqpcft9cWFhYUVHh5eHB5rCpl6qqqiorK/kT82+xsrbW0dW5fOki9TQ+Lk5BUXHo0KF17giIwQAAUJOKisrR425BQUHmvfsMsO6vodHJ2NiYEBIUGBgcGPQ6MdHXx4dKWWOLlJSU5+nTcS/jdu3Yec3X19fH5/S5sx2kpWvvCK2XCJfLRSsAADS3/Px8BQUFUdFvPvMpKysjhMjIyKANEYMBAACgaeBaNAAAAGIwAAAAYjAAAAAgBgMAACAGAwBAk2Kz2ZcuXhQwNvbDhw8hwSFoKMRgAABoShwOZ9sWl4GDBgmYeNLAwCAzk+F/1w/NhRgMAABN5sC+fb1MTTQ1NQUnmz5jxjVf39eJiWgxxGAAAGgCDAbjxvUbk6dMESbxvPnzD+zbj0Zre7BuEgBAs6uqqrrn519cXJybm7t2/TpCyKXzF3r37i0uLk4lKCsru3njRuKrV6tWrxYXl3A/dbKionLbju3Uq5b9LJc7On54/97A0BCNifNgAAAQVlZm1nLHpeaWFtb9rc94e1NrKIWHhxt368ZLIyMjQ6fTHz54WFJaevfOna5djW7duMH/qpa2VnRUNBoTMRgAAITF5XLXrVkzaPBgdTX1I4cPr/h5pYSEBCGEkZGhoKjAnzI+Lt7U1DQyImL+wgWFhYV9+vblf1VeXuHz589oT8RgAAAQVnhYWGREBJ1Ov3LlssOiRcucnKjAnJeX16FDB/6UTwMCyspKZ8ycSQiJCA+3sLTkf1VaWjozk4H2bGNwPxgAoBm9iI3t0bPH5Kn/GXslIiKipKRUUVHB25KWmpaSkrLeeSONRmOz2eFhYb+s+pV/l/LyclVVVbQnzoMBAEBYYmK0/Lx86nFWZtaH9++px/oGBvl5ef8/Cf5fe3ezkkAUhnH8oIeBBBceh9xn3khunGqj09ZuQNqEi/AWoi9KWlcQ1CVoTdleSQMDW6oLsYEBPxY2DO0GqYQCWxT/326G92yexTwc5sCxLKXUSjIphHhqNIJSRiLqudn0B2zbXorHyZMOBgB8V2bDDEq5lcsVj0/q9Uf/YHPazNSqVX/s/s5Km6aUUgjR6/VGw+HtTdk/tNXv9237NWUY5PnPcH8wAPwuz/Mcx1FKTb+cTCbrKePy+krX9c9LBoNBOBz2Hy/Ozrvdzk6hQJjsgwEAP/nOBgIfClgIoWna7v7eabH45ZLpAh6Pxg+VynY+T5LsgwEAc1Muldw311hbnTXguu7RwWF2M7sYixEXHQwAmKeXVms5kZh1bUOn3Y5GowuhEEHRwQAAYG74HwwAAB0MAAAdDAAA6GAAAOhgAABABwMA8Ne9A4bbyYy825hnAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filtro de Wiener\n",
    "\n",
    "- Filtro LTI de tiempo discreto\n",
    "- Estructura FIR con $L+1$ coeficientes: $h_0, h_1, h_2, \\ldots, h_{L}$\n",
    "- La entrada es una señal $u_0, u_1, u_2, \\ldots$\n",
    "- Para cada tiempo el filtro produce una salida $y_0, y_1, y_2, \\ldots$\n",
    "\n",
    "Adaptamos los coeficientes del filtro con dos ingredientes\n",
    "- Una respuesta \"deseada\" $d_0, d_1, d_2, \\ldots$\n",
    "- Un criterio de optimalidad que opera sobre el error entre la respuesta deseada y la salida\n",
    "$$\n",
    "e_n = d_n - y_n = d_n - \\sum_{k=0}^{L} h_k u_{n-k} \n",
    "$$\n",
    "\n",
    "Diagrama del filtro de Wiener\n",
    "\n",
    "![wiener.png](attachment:wiener.png)\n",
    "\n",
    "(Este filtro fue publicado por Norbert Wiener en 1949)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ajuste del filtro de Wiener\n",
    "\n",
    "El criterio más común para adaptar el filtro de Wiener es **el error medio cuadrático** entre la respuesta deseada y la salida del filtro. Asumiendo que la $u$ e $d$ son secuencias reales\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{MSE} &= \\mathbb{E}\\left [e_n^2 \\right] \\nonumber \\\\\n",
    "&= \\mathbb{E}\\left [(d_n - y_n)^2 \\right] \\nonumber \\\\\n",
    "&= \\mathbb{E}\\left [d_n^2 \\right]  - 2\\mathbb{E}\\left [ d_n y_n \\right] + \\mathbb{E}\\left [ y_n^2 \\right] \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "donde $\\sigma_d^2 = \\mathbb{E}\\left [d_n^2 \\right]$ es la varianza de la señal deseada y $\\sigma_y^2 = \\mathbb{E}\\left [ y_n^2 \\right]$ es la varianza de nuestro estimador\n",
    " \n",
    "***\n",
    "Minimizar el MSE implica acercar la salida del filtro a la respuesta deseada\n",
    "***\n",
    "En este caso igualando la derivada del MSE a cero tenemos \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{d h_j} \\text{MSE} &= -2\\mathbb{E}\\left[ d_n \\frac{d y_n}{d h_j}  \\right]  + 2 \\mathbb{E}\\left[ y_n \\frac{d y_n}{d h_j}    \\right]  \\nonumber \\\\\n",
    "&= -2\\mathbb{E}\\left[ d_n u_{n-j} \\right]  + 2 \\mathbb{E}\\left[ y_n u_{n-j}    \\right]  \\nonumber \\\\\n",
    "&= -2\\mathbb{E}\\left[ d_n u_{n-j} \\right]  + 2 \\mathbb{E}\\left[ \\sum_{k=0}^{L} h_k u_{n-k}  u_{n-j} \\right] \\nonumber \\\\\n",
    "&= -2\\mathbb{E}\\left[ d_n u_{n-j} \\right]  + 2 \\sum_{k=0}^{L} h_k \\mathbb{E}\\left[ u_{n-k}  u_{n-j} \\right] = 0 \\nonumber \\end{align}\n",
    "$$\n",
    "\n",
    "Si despejamos y repetimos para $j=0, \\ldots, L$ obtenemos el siguiente sistema de ecuaciones\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{pmatrix}\n",
    "r_{uu}(0) & r_{uu}(1) & r_{uu}(2) & \\ldots & r_{uu}(L) \\\\\n",
    "r_{uu}(1) & r_{uu}(0) & r_{uu}(1) & \\ldots & r_{uu}(L-1) \\\\\n",
    "r_{uu}(2) & r_{uu}(1) & r_{uu}(0) & \\ldots & r_{uu}(L-2) \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots &\\vdots \\\\\n",
    "r_{uu}(L) & r_{uu}(L-1) & r_{uu}(L-2) & \\ldots & r_{uu}(0) \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "h_0  \\\\\n",
    "h_1  \\\\\n",
    "h_2  \\\\\n",
    "\\vdots  \\\\\n",
    "h_L \\\\\n",
    "\\end{pmatrix} &= \n",
    "\\begin{pmatrix}\n",
    "r_{ud}(0)  \\\\\n",
    "r_{ud}(1)  \\\\\n",
    "r_{ud}(2) \\\\\n",
    "\\vdots  \\\\\n",
    "r_{ud}(L) \\\\\n",
    "\\end{pmatrix} \\nonumber \\\\\n",
    "R_{uu} \\textbf{h} &= R_{ud},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "que se conoce como las ecuaciones de Wiener-Hopf. \n",
    "\n",
    "Además $R_{uu}$ se conoce como matriz de auto-correlación. Asumiendo que $R_{uu}$ es no-singular, la **solución óptima en el sentido de mínimo MSE** es \n",
    "\n",
    "$$\n",
    "\\textbf{h}^{*} = R_{uu} ^{-1} R_{ud}\n",
    "$$\n",
    "\n",
    "En general $R_{uu}$ es una matriz definida-positiva (su inversa existe) y el sistema puede resolverse en $\\mathcal{O}(L^2)$ usando la [recursión de Levison-Durbin](https://en.wikipedia.org/wiki/Levinson_recursion)\n",
    "\n",
    "Requisitos/supuestos de este filtro\n",
    "- la salida deseada y la entrada tienen media cero, *i.e.* $\\mathbb{E}[d_n] = \\mathbb{E}[u_n] = 0$ (si existe podemos restarla)\n",
    "- la salida deseada y la entrada son estacionarias en el sentido amplio, *i.e.* la correlación solo depende de $m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Error mínimo del filtro de Wiener\n",
    "\n",
    "Dado que $y_n = \\textbf{h}^T U_n = U_n^T \\textbf{h} $, podemos expresar el MSE como\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{MSE} &= \\mathbb{E}\\left [d_n^2 \\right]  - 2\\mathbb{E}\\left [ d_n y_n \\right] + \\mathbb{E}\\left [ y_n^2 \\right] \\nonumber \\\\\n",
    "&= \\mathbb{E}\\left [d_n^2 \\right] - 2 \\textbf{h}^T \\mathbb{E}\\left [ d_n U_n \\right]  + \\textbf{h}^T \\mathbb{E}\\left [U_n U_n^T \\right]  \\textbf{h}  \\nonumber \\\\\n",
    "&= \\sigma_d^2 - 2 \\textbf{h}^T R_{ud} + \\textbf{h}^T R_{uu} \\textbf{h} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Luego el mínimo error que se puede obtener es\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{MSE}_{\\text{min}} &= \\sigma_d^2 - (R_{uu}^{-1} R_{ud})^T R_{ud} \\nonumber \\\\\n",
    "&= \\sigma_d^2 - R_{ud}^T R_{uu}^{-1} R_{ud} < \\sigma_d^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filtro de wiener: Regresión (identificación de sistema)\n",
    "\n",
    "En regresión buscamos encontrar los coeficientes $h$ a partir de $(X, Y)$ tal que\n",
    "$$\n",
    "Y = h^T X + \\epsilon,\n",
    "$$\n",
    "donde $X \\in \\mathbb{R}^{N\\times D}$ son las variables dependientes (entrada), $Y \\in \\mathbb{R}^N$ es la  variable dependiente (salida) y $\\epsilon$ es ruido.\n",
    "\n",
    "\n",
    "### Entrenamiento del predictor\n",
    "\n",
    "- Asumimos que hemos observado N muestras de $X$ e $Y$ \n",
    "- A partir de $u=X$ construimos $R_{uu}$\n",
    "- A partir de $d=Y$ construimos $R_{ud}$\n",
    "- Finalmente recuperamos $\\textbf{h}$ usando $R_{uu} ^{-1} R_{ud}$\n",
    "- Con esto podemos interpolar $Y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(9, 4))\n",
    "N = 100; t = np.linspace(0, 10, num=N)\n",
    "U = np.ones(shape=(N, 5))\n",
    "for i in range(1, 5):\n",
    "    U[:, i] = t**i\n",
    "h_real = [-1, 1, -0.1, 0.01, -0.001]\n",
    "def update(rseed, order):\n",
    "    np.random.seed(rseed)\n",
    "    Y = np.dot(U, h_real) + np.random.randn(N)\n",
    "    Ruu = np.dot(U[:, :order+1].T, U[:, :order+1])\n",
    "    Rud = np.dot(U[:, :order+1].T, Y[:, np.newaxis])\n",
    "    h = np.linalg.solve(Ruu, Rud)[:, 0]\n",
    "    ax.cla();\n",
    "    ax.plot(t, np.dot(U, h_real), lw=4, alpha=0.7, label='true')\n",
    "    ax.plot(t, Y, '.', label='observed', markersize=10)\n",
    "    ax.plot(t, np.dot(U[:, :order+1], h), lw=4, alpha=0.7, label='estimated'); plt.legend();\n",
    "interact(update, rseed=IntSlider_nice(), order=SelectionSlider_nice(options=[0, 1, 2, 3, 4]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filtro de wiener: Predicción \n",
    "\n",
    "En este caso asumimos que la señal deseada es la entrada en el futuro\n",
    "$$\n",
    "d_n = \\{u_{n+1}, u_{n+2}, \\ldots, u_{n+m}\\}\n",
    "$$ \n",
    "\n",
    "- Donde $m$ es el horizonte de predicción\n",
    "- Llamamos *predicción a un paso* al caso $m=1$\n",
    "- El largo del filtro $L$ define la cantidad de muestras pasadas que usamos para predecir\n",
    "- Por ejemplo un sistema de predicción a un paso con $L+1 = 3$ coeficientes:\n",
    "$$\n",
    "h_0 u_n +  h_1 u_{n-1} + h_2 u_{n-2}= y_n = \\hat u_{n+1} \\approx u_{n+1}\n",
    "$$\n",
    "\n",
    "### Entrenamiento del predictor\n",
    "\n",
    "- Asumimos que la señal ha sido observada y que se cuenta con $N$ muestras\n",
    "- Podemos formar una matriz cuyas filas son $[u_n, u_{n-1}, \\ldots, u_{n-L}]$ para $n=L,L+1,\\ldots, N-1$\n",
    "- Podemos formar un vector $[u_N, u_{N-1}, \\ldots, u_{L+1}]^T$ (caso $m=1$)\n",
    "- Con esto podemos formar las matrices de correlación y obtener $\\textbf{h}$\n",
    "- Finalmente usamos $\\textbf{h}$ para predecir el futuro no observado de $u$\n",
    "\n",
    "¿Cómo afectan $L$ y $N$ en la calidad del predictor lineal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "fig, ax = plt.subplots(1, figsize=(9, 4))\n",
    "t = np.linspace(0, 10, num=200)\n",
    "u = np.sin(2.0*np.pi*0.5*t) + 0.25*np.random.randn(len(t))\n",
    "#u += 0.5*t\n",
    "def update(L, N_train):    \n",
    "    ax.cla();\n",
    "    U = as_strided(u, [len(u)-L+1 , L+1], strides=[u.strides[0], u.strides[0]])\n",
    "    Ruu = np.dot(U[:N_train, :L].T, U[:N_train, :L])\n",
    "    Rud = np.dot(U[:N_train, :L].T, U[:N_train, L][:, np.newaxis])\n",
    "    h = np.linalg.solve(Ruu, Rud)[:, 0]\n",
    "    ax.plot(t[:N_train], u[:N_train], label='Train'); \n",
    "    ax.plot(t[N_train:], u[N_train:], label='Test'); \n",
    "    u_pred = np.zeros(shape=(len(u), ))\n",
    "    u_pred[:N_train] = u[:N_train]\n",
    "    for k in range(N_train, len(u)):\n",
    "        u_pred[k] = np.sum(h*u_pred[k-L:k])    \n",
    "    ax.plot(t[N_train:], u_pred[N_train:], linewidth=4, alpha=0.7,\n",
    "            label='Predicted'); ax.legend(loc=3);\n",
    "\n",
    "interact(update, L=SelectionSlider_nice(options=[1, 5, 10, 20, 30, 50], value=5), \n",
    "         N_train=SelectionSlider_nice(options=[len(u)//3, len(u)//2, len(u)*2//3], value=len(u)//2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Filtro de Wiener: Eliminar ruido blanco aditivo\n",
    "\n",
    "En este caso asumimos que la señal de entrada corresponde a una señal deseada (información) que ha sido contaminada con ruido aditivo\n",
    "\n",
    "$$\n",
    "u_n = d_n + \\nu_n,\n",
    "$$\n",
    "\n",
    "adicionalmente asumimos que\n",
    "- el ruido es estacionario en el sentido amplio y de media cero $\\mathbb{E}[\\nu_n] = 0$\n",
    "- el ruido es blanco, es decir no tiene correlación consigo mismo o con la señal deseada\n",
    "$$\n",
    "r_{\\nu d}(k) = 0, \\forall k\n",
    "$$\n",
    "- el ruido tiene una cierta varianza $\\mathbb{E}[\\nu_n^2] = \\sigma_\\nu^2, \\forall n$\n",
    "\n",
    "Notemos que en este caso $R_{uu} = R_{dd} + R_{\\nu\\nu}$ y $R_{ud} = R_{dd}$, luego\n",
    "\n",
    "la señal recuperada es $\\hat d_n = h^{*} u_n$ y el filtro es\n",
    "\n",
    "$$\n",
    "\\vec h^{*} = \\frac{R_{dd}}{R_{dd} + R_{\\nu\\nu}}\n",
    "$$\n",
    "\n",
    "y su respuesta en frecuencia\n",
    "\n",
    "$$\n",
    "H(f) = \\frac{S_{dd}(f)}{S_{dd}(f) + S_{\\nu\\nu}(f)}\n",
    "$$\n",
    "\n",
    "es decir que \n",
    "- en frecuencias donde la $S_{dd}(f) > S_{\\nu\\nu}(f)$, entonces $H(f) = 1$\n",
    "- en frecuencias donde la $S_{dd}(f) < S_{\\nu\\nu}(f)$, entonces $H(f) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sistemas adaptivos\n",
    "\n",
    "Hasta ahora hemos estudiando sistemas LTI: \n",
    "- sus coeficientes quedan fijos luego del diseño y son constantes en el tiempo\n",
    "- hacen supuestos sobre los estadísticos de la señal/ruido\n",
    "\n",
    "Qué hacer si\n",
    "- no podemos hacer supuestos sobre los estadísticos\n",
    "- los estadísticos de la señal/ruido cambian en el tiempo (no estacionaridad)\n",
    "- estamos en un escenario donde los datos llegan continuamente (streaming)\n",
    "\n",
    "Estimador **adaptivo**: \n",
    "- Sistemas cuyos coeficientes se pueden adaptar a medida que llegan nuevos datos\n",
    "- Se diseñan de acuerdo a un método de optimización *online*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[&larr; Volver al índice](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "<a id=\"section2\"></a>\n",
    "\n",
    "# Gradiente descendente\n",
    "***\n",
    "\n",
    "- Sea un vector de pesos $w$ de largo $L+1$ que guarda los coeficientes de un filtro\n",
    "- Sea ahora una función de costo que mapea el vector de pesos a un número real: $J(w): \\mathbb{R}^{L+1} \\to \\mathbb{R}$\n",
    "    - A menor $J$ mejor es nuestro filtro (menor error)\n",
    "\n",
    "Para entrenar un filtro adaptivo \n",
    "1. Partimos de una solución inicial $w_0$\n",
    "1. Modificamos iterativamente $w$ tal que $J(w_{t+1}) < J(w_t)$\n",
    "1. Nos detenemos al cumplir un cierto criterio \n",
    "\n",
    "***\n",
    "Una alternativa de bajo costo para lograr esto es la regla del **gradiente descendente** (GD)\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\mu \\frac{dJ(w)}{dw},\n",
    "$$\n",
    "\n",
    "donde $\\mu$ se conoce como tasa de aprendizaje o \"paso\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all'); fig, ax = plt.subplots(1, figsize=(7, 3))\n",
    "x = np.linspace(-4, 6, num=100)\n",
    "L = lambda x : (x-1)**2 + 3*np.sin(np.pi*x)\n",
    "p = 10*np.random.rand(10) - 4.\n",
    "ax.plot(x, L(x))\n",
    "sc = ax.scatter(p, L(p), s=100)\n",
    "mu = 0.01\n",
    "\n",
    "def update(n):\n",
    "    p = sc.get_offsets()[:, 0]\n",
    "    p = p - mu*2*(p-1) - mu*3*np.pi*np.cos(np.pi*p)\n",
    "    sc.set_offsets(np.c_[p, L(p)])\n",
    "    \n",
    "anim = animation.FuncAnimation(fig, update, frames=100, interval=200, repeat=False, blit=True)\n",
    "#plt.close(); HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "***\n",
    "\n",
    "- Imaginemos $J$ como una superficie de $L+1$ dimensiones\n",
    "- En cada punto el gradiente negativo de $J$ nos indica hacia donde está el descenso más abrupto\n",
    "- La tasa $\\mu$ nos da el largo del salto entre $w_t$ y $w_{t+1}$\n",
    "\n",
    "Notemos de la **expansión de Taylor de primer orden** de $J$ en $w_{t}$ que\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J(w_{t+1}) &= J(w_t) + \\frac{dJ(w_t)}{dw} (w_{t+1} - w_{t})  \\nonumber \\\\\n",
    "&= J(w_t) -\\mu \\left \\| \\frac{dJ(w_t)}{dw} \\right \\|^2 \\leq J(w_t) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "es decir que dado usando la regla GD con $\\mu>0$ se cumple que $J$ decrece monotonicamente\n",
    "\n",
    "- Relación con método de Newton!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradiente descendente en el filtro de Wiener\n",
    "\n",
    "Para el filtro de Wiener teniamos\n",
    "$$\n",
    "J(h) = \\sigma_d^2 - 2 \\textbf{h}^T R_{ud} + \\textbf{h}^T R_{uu} \\textbf{h},\n",
    "$$\n",
    "por ende\n",
    "$$\n",
    "\\frac{dJ(h)}{dh} = -2 R_{ud} + 2 R_{uu} \\textbf{h}\n",
    "$$\n",
    "y finalmente\n",
    "$$\n",
    "\\textbf{h}_{t+1} = \\textbf{h}_{t} (I - 2 \\mu R_{uu}) + 2\\mu R_{ud}\n",
    "$$\n",
    "En este caso la condición de convergencia estable es \n",
    "$$\n",
    "0 < \\mu < \\frac{1}{\\lambda_{\\text{max}}},\n",
    "$$\n",
    "donde $\\lambda_{\\text{max}}$ es valor propio más grande de $R_{uu}$\n",
    "\n",
    "Esto último viene de formar una ecuación de diferencia del estilo $\\hat w_{k, t+1} = (1-\\mu \\lambda_k)^t \\hat w_{k, t=0}$\n",
    "\n",
    "Ref: Haykin, \"Adaptive filter theory\", 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradiente descendente estocástico (SGD)\n",
    "\n",
    "El filtro de Wiener es óptimo pero no adaptivo\n",
    "- Requiere de $N$ muestras de $u$ y $d$ para estimar $R_{ud}$ y $R_{uu}$\n",
    "- Asume estacionaridad: $J(h) = \\mathbb{E}\\left[e_n^2\\right]$\n",
    "- El gradiente descendente (GD) es un método deterministico\n",
    "- Los pesos se adaptan luego de haber presentado las $N$ muestras (batch)\n",
    "\n",
    "Consideremos el caso en que los datos no son estacionarios\n",
    "- Significa que debemos adaptar el filtro en cada paso a medida que nuevas muestras son observadas\n",
    "- Para esto usamos la versión estocástica del GD: SGD\n",
    "- Los pesos se adaptan luego de haber presentado una muestra o un conjunto pequeño (mini-batch)\n",
    "- No hay garantía de llegar al óptimo en un problema convexo, pero es más eficiente computacionalmente que GD\n",
    "\n",
    "<img src=\"img/adaptive-sgd.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[&larr; Volver al índice](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "<a id=\"section3\"></a>\n",
    "# Algoritmo Least Mean Square (LMS)\n",
    "***\n",
    "\n",
    "\n",
    "Podemos extender el filtro de Wiener al caso no-estacionario usando SGD\n",
    "- El resultado es un algoritmo es simple (filtro FIR) que además es robusto\n",
    "- A diferencia del filtro de Wiener no se requiere conocimiento estadístico del proceso\n",
    "- Tampoco se requiere calcular e invertir la matriz de correlación\n",
    "- Se entrena de manera recursiva y online\n",
    "\n",
    "Consideremos la función de costo estocástica para la arquitectura FIR\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J^s_n(\\textbf{w}) &= e_n^2 \\nonumber \\\\\n",
    "&= (d_n - y_n)^2 \\nonumber \\\\\n",
    "&= (d_n - \\textbf{w}^T \\textbf{u}_n )^2 \\nonumber \\\\\n",
    "&= (d_n - \\sum_{k=0}^{L} w_{n, k} u_{n-k} )^2 \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "donde definimos $\\textbf{u}_n = [u_n, u_{n-1}, \\ldots, u_{n-L}]$ \n",
    "\n",
    "Notemos que usamos el error cuadrático instantaneo en lugar del MSE (filtro de Wiener)\n",
    "\n",
    "El gradiente en función del peso $w_{n, k}$ es \n",
    "$$\n",
    "\\frac{d J^s_n (\\textbf{w})}{d w_{n, k}} = - 2 e_n u_{n-k}\n",
    "$$\n",
    "Usando la regla SGD llegamos a \n",
    "$$\n",
    "w_{n+1, k} = w_{n, k} + 2 \\mu e_n u_{n-k}, k=0, 1, \\ldots, L\n",
    "$$\n",
    "o en forma matricial\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}_{n+1} &= \\textbf{w}_{n} + 2 \\mu e_n \\textbf{u}_{n}\\nonumber \\\\\n",
    "&= \\textbf{w}_{n} + 2 \\mu (d_n -  \\textbf{w}_{n}^T \\textbf{u}_{n}) \\textbf{u}_{n}, \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Estimamos la matriz de correlación instantanea y actualizamos los pesos recursivamente\n",
    "- La complejidad de este algoritmo es $L+1$, es decir la complejidad del filtro\n",
    "- Esto se conoce como algoritmo LMS o regla Widrow-Hoff\n",
    "- Inventado en 1960 por [Bernard Widrow](https://en.wikipedia.org/wiki/Bernard_Widrow) y Ted Hoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Interpretación geométrica del algoritmo LMS\n",
    "\n",
    "Tenemos la siguiente regla iterativa\n",
    "$$\n",
    "\\textbf{w}_{n+1} = \\textbf{w}_{n} + 2 \\mu e_n \\textbf{u}_{n} = \\textbf{w}_{n} + \\Delta \\textbf{w}_n\n",
    "$$\n",
    "que se puede interpretar graficamente como\n",
    "<a href=\"https://www.commsp.ee.ic.ac.uk/~mandic/SE_ASP_LN/ASP_MI_Lecture_5_Adaptive_Filters_2017.pdf\"><img src=\"img/adaptive-lms-geometry.png\" width=\"400px\"></a>\n",
    "\n",
    "Notemos que\n",
    "\n",
    "- Los cambios en el vector de peso $\\Delta \\textbf{w}_n$ son paralelos a $\\textbf{u}_{n}$\n",
    "- Estos cambios podrían estar dominados por $\\max_k \\textbf{u}_{n} = [u_n, u_{n-1}, \\ldots, u_{n-L}]$\n",
    "- El algoritmo Normalized LMS (NLMS) corrige esto ponderando por la varianza de $\\textbf{u}_{n}$ \n",
    "$$\n",
    "\\textbf{w}_{n+1} = \\textbf{w}_{n} + 2 \\mu e_n \\frac{\\textbf{u}_{n}}{\\left(\\|\\textbf{u}_{n}\\|^2 + \\delta\\right)}\n",
    "$$\n",
    "donde la constante $\\delta$ es un valor pequeño que se usa para evitar divisiones por cero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LMS: Adaptive line enhancement (ALE)\n",
    "\n",
    "- Sistema adaptivo para eliminar ruido aditivo de un canal\n",
    "- El sistema aprende un filtro pasabanda en torno a la frecuencia de interés\n",
    "- Notece como es posible filtrar incluso ante cambios bruscos en la señal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "fig, ax = plt.subplots(3, figsize=(9, 5))\n",
    "t, dt = np.linspace(0, 5, num=500, retstep=True)\n",
    "u = np.sin(2.0*np.pi*t*5)\n",
    "#u[250:] += 5  # Cambio abrupto en la media\n",
    "#u += 2*t  #  Tendencia lineal\n",
    "#u += u*(0.5 + 0.5*np.cos(2.0*np.pi*t/2))  # Tremolo (AM)\n",
    "def update(mu, L, rseed):\n",
    "    np.random.seed(rseed)\n",
    "    u_noise = u + 0.5*np.random.randn(len(t)) \n",
    "    w = np.zeros(shape=(L+1, ))\n",
    "    ax[0].cla(); ax[1].cla(); ax[2].cla(); \n",
    "    #LMS\n",
    "    u_pred = np.zeros(shape=(len(u), ))\n",
    "    for k in range(L+1, len(u)-1):\n",
    "        norm = np.sum(u_noise[k-L-1:k]**2) + 1e-6\n",
    "        u_pred[k] = np.dot(w, u_noise[k-L-1:k])\n",
    "        w += 2*mu*(u_noise[k] - u_pred[k])*u_noise[k-L-1:k]/norm\n",
    "    u_pred[k+1] = np.dot(w, u_noise[k-L-1:k])\n",
    "    ax[0].plot(t, u_noise, 'k.', alpha=0.5); \n",
    "    ax[0].plot(t, u, 'g-', alpha=0.5);  ax[0].plot(t, u_pred); \n",
    "    \n",
    "    ax[1].plot((u - u_pred)**2, label='LMS')\n",
    "    k, Hk = scipy.signal.freqz(b=w, a=1)\n",
    "    ax[2].plot(k/(2*dt*np.pi), np.abs(Hk))\n",
    "    \n",
    "interact(update, mu=SelectionSlider_nice(options=[1e-4, 1e-3, 0.01, 0.1, 0.2, 1.]),\n",
    "         L=SelectionSlider_nice(options=[1, 5, 10, 20, 50], value=10), rseed=IntSlider_nice());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- El algoritmo LMS es un sistema de control con retroalimentación\n",
    "- En el ejemplo anterior notamos la desestabilidad que ocurre con ciertos valores de $\\mu$\n",
    "- La convergencia del algoritmo depende de $\\mu$\n",
    "    - Muy pequeño: Convergencia lenta\n",
    "    - Muy grande: Desestabilidad\n",
    "\n",
    "### Comparación entre Filtro de Wiener/GD y algoritmo LMS/SGD\n",
    "- Wiener: Ambiente estacionario lo cual nos permite calcular $R_{uu}$ y $R_{ud}$. El aprendizaje es determinista.\n",
    "- LMS: El aprendizaje viene promediando a nivel de los estimadores de $w$. Esta sujeto al ruido de los estimadores de gradiente. El aprendizaje es estadístico.\n",
    "- Wiener es óptimo en cambio LMS es sub-óptimo (localmente óptimo). LMS tiende a la solución de Wiener\n",
    "- LMS se actualiza online y tiene costo $L$. Wiener se entrena offline y tiene costo $L^2$\n",
    "\n",
    "<img src=\"img/adaptive-lms.png\">\n",
    "\n",
    "\n",
    "Convergencia del algoritmo LMS (Haykin 6.5)\n",
    "- El algoritmo LMS tiende en la media $\\mathbb{E}[\\textbf{w}_n] \\to \\textbf{w}^*$ para $n\\to \\infty$\n",
    "- Convergencia en la media cuadrada: La varianza de $\\textbf{w}_n - \\textbf{w}^*$ tiene al valor mínimo de $J$ para $n\\to \\infty$\n",
    "- Esto se cumple si \n",
    "$$\n",
    "0 < \\mu < \\frac{1}{\\lambda_{\\text{max}}}\n",
    "$$\n",
    "donde $\\lambda_{\\text{max}}$ es el valor propio más grande de $R_{uu}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LMS: Cancelación de eco\n",
    "\n",
    "- Supongamos que enviamos una señal de voz a un amig@ \n",
    "- Nuestro amig@ escucha lo que enviamos en un parlante y responde\n",
    "- Nosotros escuchamos la respuesta de nuestro amig@ y adicionalmente nuestro mensaje original\n",
    "\n",
    "<img src=\"img/adaptive-echo-canceller.png\" width=\"500\">\n",
    "\n",
    "- Podemos usar un filtro adaptivo para cancelar el eco\n",
    "- Usamos como entrada la señal enviada y como salida deseada la señal recibida (con eco)\n",
    "- El filtro aprende el sistema reverberante\n",
    "- El error es la nueva señal recibida limpia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# la señal enviada original\n",
    "r, fs = sf.read(\"data/hola1.ogg\")\n",
    "Audio(r, rate=int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# El sistema que introduce ecos, por ejemplo una sala\n",
    "h = np.concatenate(([1.0], np.zeros(10), [0.7], np.zeros(10), [0.5], \n",
    "                    np.zeros(10), [0.3], np.zeros(10), [0.1], np.zeros(10), [0.05]))\n",
    "# la señal enviada con eco\n",
    "rh = np.convolve(r, h)[:len(r)]\n",
    "# la señal recibida limpia \n",
    "s, fs = sf.read(\"data/hola2.ogg\")\n",
    "s = np.concatenate((s, np.zeros(shape=(len(r)-len(s)))))\n",
    "# la señal recibida + señal enviada con eco + ruido blanco\n",
    "srh = s + 0.3*rh + np.random.randn(len(s))*0.005\n",
    "Audio(srh, rate=int(fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L, mu = 100, 0.02\n",
    "fig, ax = plt.subplots(2, figsize=(9, 4))\n",
    "w = np.zeros(shape=(L+1, ))\n",
    "rhhat = np.zeros(shape=(len(srh), ))\n",
    "for k in range(L+1, len(srh)-1):\n",
    "    norm = np.sum(r[k-L-1:k]**2) + 1e-10\n",
    "    rhhat[k] = np.dot(w, r[k-L-1:k])\n",
    "    w += 2*mu*(srh[k] - rhhat[k])*r[k-L-1:k]/(norm)\n",
    "rhhat[k+1] = np.dot(w, r[k-L-1:k])\n",
    "shat = srh - rhhat\n",
    "ax[0].plot(srh, alpha=0.5, label='hola2+hola1');\n",
    "ax[0].plot(shat, alpha=0.75, label='error');\n",
    "ax[0].plot(s, alpha=0.75, label='hola2 puro');\n",
    "ax[0].legend()\n",
    "ax[1].plot((s - shat)**2)\n",
    "Audio(shat, rate=int(fs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[&larr; Volver al índice](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"section4\"></a>\n",
    "***\n",
    "# Algoritmo Recursive Least Squares (RLS)\n",
    "***\n",
    "\n",
    "El algoritmo LMS\n",
    "- minimiza el error instantaneo\n",
    "- es simple y eficiente \n",
    "- en algunos casos su convergencia es demasiado lenta\n",
    "\n",
    "Podemos obtener un filtro adaptivo que converge más rápido si reemplazamos el error instantaneo por el error histórico\n",
    "\n",
    "Sigamos considerando un filtro tipo FIR con $L+1$ pesos que se actualizan de en cada época\n",
    "\n",
    "$$\n",
    "y_i = \\sum_{k=0}^L w_{i, k} u_{n-k}\n",
    "$$\n",
    "\n",
    "El algoritmo RLS (recursive least squares) es un método online que minimiza el error histórico, es decir la suma de errores entre la muestra actual y la inicial\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J^H_n(\\textbf{w}) &= \\sum_{i=L}^n   \\beta^{n-i} |e_i|^2 \\nonumber \\\\\n",
    "&= \\sum_{i=L+1}^n \\beta^{n-i} (d_i - \\sum_{k=0}^{L} w_{i, k} u_{i-k} )^2, \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $n$ es el índice del instante actual y $\\beta \\in [0, 1]$ es el \"factor de olvido\" y que usualmente es un valor cercano a $1$ \n",
    "\n",
    "Adicionalmente se agrega un regularizador a los pesos\n",
    "$$\n",
    "J^w_n = \\delta  \\| \\textbf{w}_{n} \\|^2\n",
    "$$\n",
    "\n",
    "La solución cerrada sería\n",
    "\n",
    "$$\n",
    "\\textbf{w}_n = (U_n^T \\pmb{\\beta} U_n + \\delta I)^{-1}  U_n^T \\pmb{\\beta} \\textbf{d}_n\n",
    "$$\n",
    "donde \n",
    "$$\n",
    "\\textbf{d}_n = \\begin{pmatrix}  d_n \\\\ d_{n-1} \\\\ \\vdots \\\\ d_{L+1} \\end{pmatrix} \\quad\n",
    "\\textbf{u}_n = \\begin{pmatrix}  u_n \\\\ u_{n-1} \\\\ \\vdots \\\\ u_{n-(L+1)} \\end{pmatrix} \\quad\n",
    "\\pmb{\\beta} = I \\begin{pmatrix} \\beta \\\\ \\beta^{1} \\\\ \\beta^{2}  \\vdots \\\\ \\beta^{n-L-1} \\end{pmatrix}\n",
    "\\quad \n",
    "U_n = \\begin{pmatrix}\n",
    "\\textbf{u}_n^T \\\\ \\textbf{u}_{n-1}^T \\\\ \\vdots \\\\ \\textbf{u}_{L+1}^T \\\\\n",
    "\\end{pmatrix} \\in \\mathbb{R}^{n - (L+1) \\times L+1}\n",
    "$$\n",
    "\n",
    "e $I$ es la matriz identidad. \n",
    "\n",
    "- Notemos la similitud con el filtro de Wiener\n",
    "    - Matriz de correlación ponderada y regularizada: $\\Phi_n = U_n^T \\pmb{\\beta} U_n + \\delta I$\n",
    "    - Vector de correalación cruzada ponderada:  $\\theta_n = U_n^T \\pmb{\\beta} \\textbf{d}_n$\n",
    "- Queremos recomputar esta solución cuando llegan nuevas observaciones\n",
    "- En particular queremos evitar invertir $\\Phi_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El algoritmo **RLS** propone una solución que actualiza los pesos de forma recursiva\n",
    "\n",
    "Las condiciones iniciales son \n",
    "- $\\Phi_0 = \\delta I$\n",
    "- $\\theta_0 = 0$\n",
    "\n",
    "y luego la actualización viene dada por \n",
    "\n",
    "- $\\Phi_{n} = \\beta \\Phi_{n-1} + \\textbf{u}_n \\textbf{u}_n^T$ \n",
    "- $\\theta_{n} = \\beta \\theta_{n-1} + \\textbf{u}_n d_n $ \n",
    "- $\\textbf{w}_n = \\Phi_n^{-1} \\theta_n$\n",
    "\n",
    "Que es más eficiente si actualizamos $\\Phi_{n}^{-1}$ en lugar de $\\Phi_{n}$ \n",
    "\n",
    "Usando el lema de inversión de matrices \n",
    "$$\n",
    "(A + UCV)^{-1} = A^{-1} - A^{-1} U (C^{-1} + VA^{-1} U)^{-1} V A^{-1}\n",
    "$$\n",
    "\n",
    "con $A = \\Phi_{n-1}^{-1}$, $C=1$, $U= \\textbf{u}_n$ y $V = \\textbf{u}_n^T$ entonces\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Phi_{n}^{-1} &= \\left(\\beta \\Phi_{n-1} + \\textbf{u}_n \\textbf{u}_n^T \\right)^{-1} \\nonumber \\\\\n",
    "&= \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-2} \\frac{\\Phi_{n-1}^{-1} \\textbf{u}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1} }{1 + \\beta^{-1} \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\textbf{u}_n} \\nonumber \\\\\n",
    "&= \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-1} \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1}, \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde llamamos **ganancia** a $\\textbf{k}_n$\n",
    "\n",
    "Podemos continuar para encontrar una regla de actualización recursiva para los pesos\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}_n &= \\Phi_n^{-1} \\theta_n \\nonumber \\\\\n",
    "&=  \\Phi_n^{-1} \\beta \\theta_{n-1} + \\Phi_n^{-1} \\textbf{u}_n d_n\\nonumber \\\\\n",
    "&=  \\Phi_{n-1}^{-1} \\theta_{n-1} - \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\theta_{n-1} + \\Phi_n^{-1} \\textbf{u}_n d_n \\nonumber \\\\\n",
    "&=  \\textbf{w}_{n-1} - \\textbf{k}_n \\textbf{u}_n^T  \\textbf{w}_{n-1} + \\Phi_n^{-1} \\textbf{u}_n d_n \\nonumber \\\\\n",
    "&=  \\textbf{w}_{n-1} + \\textbf{k}_n ( d_n - \\textbf{u}_n^T  \\textbf{w}_{n-1} ) \\nonumber \\\\\n",
    "&=  \\textbf{w}_{n-1} + \\textbf{k}_n e_n \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "donde reemplazamos $\\textbf{w}_{n-1} = \\Phi_{n-1}^{-1} \\theta_{n-1}$ y usamos que \n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{k}_n &= \\left(\\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-1} \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\right)  \\textbf{u}_n \\nonumber \\\\ &= \\Phi_n^{-1} u_n \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "### Notas\n",
    "- Con esto tenemos un algoritmo de complejidad $L^2$ en vez de $L^3$\n",
    "- Esto sigue siendo mayor que LMS (complejidad $L$) pero con la ventaja de converger más rapidamente \n",
    "- En la literatura suele usarse el nombre $P_n$ para $\\Phi_n^{-1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***\n",
    "## Resumen algoritmo RLS\n",
    "\n",
    "- Inicializar $\\Phi_0 = \\delta I$ y $\\textbf{w}_0 = 0$\n",
    "- Para $n \\in [1, \\infty]$\n",
    "    1. Calcular la ganancia\n",
    "    $$\n",
    "    \\textbf{k}_n =  \\frac{\\beta^{-1} \\Phi_{n-1}^{-1} \\textbf{u}_n }{1 + \\beta^{-1} \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\textbf{u}_n}\n",
    "    $$\n",
    "    1. Calcular el error\n",
    "    $$\n",
    "    e_n = d_n - \\textbf{u}_n^T  \\textbf{w}_{n-1} \n",
    "    $$\n",
    "    1. Actualizar el error de pesos\n",
    "    $$\n",
    "    \\textbf{w}_n = \\textbf{w}_{n-1} + \\textbf{k}_n e_n \n",
    "    $$\n",
    "    1. Actualizar el inverso de la matriz de correlación\n",
    "    $$\n",
    "    \\Phi_{n}^{-1} = \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-1} \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1}\n",
    "    $$\n",
    "    \n",
    "### Recomendaciones\n",
    "- A menor $\\delta$ mayor regularización. Usar $\\delta$ pequeño para SNR bajo y $\\delta$ grande para SNR alto\n",
    "- Considerar un valor de $\\beta \\approx 0.9$ inicialmente\n",
    "- Calibre $\\delta$ y $\\beta$ usando validación cruzada\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### RLS versus LMS: Tracking\n",
    "\n",
    "- Notemos la diferencia en tiempo de convergencia entre los algoritmos LMS y RLS\n",
    "- RLS es capaz de adaptarse a cambios bruscos más rápido que LMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(9, 6))\n",
    "t, dt = np.linspace(0, 5, num=500, retstep=True)\n",
    "np.random.seed(0)\n",
    "u = np.sin(2.0*np.pi*t*5)  \n",
    "# u[250:] += 5\n",
    "u += np.array([5*np.exp(-np.absolute(tt-1)/0.2) if tt>1 else 0 for tt in t])\n",
    "u += np.array([5*np.exp(-np.absolute(tt-3)/0.2) if tt>3 else 0 for tt in t])\n",
    "u_noisy = u + 0.5*np.random.randn(len(t))\n",
    "\n",
    "def update(mu, beta, L):\n",
    "    ax[0].cla(); ax[1].cla(); \n",
    "    u_pred = np.zeros(shape=(len(u_noisy), 2))\n",
    "    #LMS\n",
    "    w = np.zeros(shape=(L+1, ))\n",
    "    for k in range(L+1, len(u_noisy)):\n",
    "        u_window = u_noisy[k-L-1:k]\n",
    "        norm = np.sum(u_window**2) + 1e-6\n",
    "        u_pred[k, 0] = np.dot(w, u_window)\n",
    "        if k < len(u):\n",
    "            w += 2*mu*(u_noisy[k] - u_pred[k, 0])*u_window/norm\n",
    "    #RLS\n",
    "    w = np.zeros(shape=(L+1, ))\n",
    "    delta = 1.\n",
    "    Phi_inv = delta*np.eye(L+1); \n",
    "    for k in range(L+1, len(u_noisy)):\n",
    "        u_window = u_noisy[k-L-1:k]\n",
    "        # Calcular ganancia\n",
    "        gain = np.dot(Phi_inv, u_window)/(beta + np.dot(np.dot(u_window.T, Phi_inv), u_window))        \n",
    "        # Calcular error\n",
    "        u_pred[k, 1] = np.dot(w, u_window)\n",
    "        err = u_noisy[k] - u_pred[k, 1]\n",
    "        # Actualizar pesos\n",
    "        w += np.dot(gain, err)\n",
    "        # Actualizar el inverso de la matriz de correlación\n",
    "        Phi_inv = (1./beta)*(1. - np.sum(gain*u_window))*Phi_inv\n",
    "    \n",
    "    ax[0].plot(t, u_noisy, 'k.', alpha=0.5); \n",
    "    ax[0].plot(t, u, 'g-', alpha=0.5, label='Real');  \n",
    "    ax[0].plot(t, u_pred[:, 0], label='LMS'); \n",
    "    ax[0].plot(t, u_pred[:, 1], label='RLS'); ax[0].legend(loc=1)\n",
    "    ax[1].plot((u - u_pred[:, 0])**2, label='LMS')\n",
    "    ax[1].plot((u - u_pred[:, 1])**2, label='RLS'); ax[1].legend()\n",
    "\n",
    "    \n",
    "interact(update, \n",
    "         mu=FloatSlider_nice(step=0.01, max=0.1, min=0.01),\n",
    "         beta=FloatSlider_nice(step=0.01, max=1., min=0.5, value=0.9),\n",
    "         L=SelectionSlider_nice(options=[1, 5, 10, 20, 50], value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[&larr; Volver al índice](#index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"section5\"></a>\n",
    "***\n",
    "# Algoritmo Perceptrón (Rosemblatt 1962)\n",
    "***\n",
    "\n",
    "- Podemos entrenar un filtro adaptivo para hacer **clasificación binaria de patrones**\n",
    "- En este caso la respuesta deseada tiene dos categorías: $d_n \\in \\{-1, +1\\}$ \n",
    "- La entrada se considera continua y de $M$ dimensiones: $u_n \\in \\mathbb{R}^M$\n",
    "- Asumimos que se tienen $N$ tuplas $(u_n, d_n)$\n",
    "- El filtro tiene arquitectura FIR con $M+1$ coeficientes pero se agrega una no linealidad $\\phi(\\cdot)$ en la salida\n",
    "$$\n",
    "\\begin{align}\n",
    "y_n &=  \\phi \\left(w_0 + \\sum_{k=1}^{M} w_k u_{nk} \\right) \\nonumber \\\\\n",
    "&= \\phi \\left(\\langle \\textbf{w}, \\text{concat}(1, u_n) \\rangle \\right), \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "donde podemos usar $\\phi(z) = \\text{sign}(z) = \\begin{cases} +1 & z > 0 \\\\0 & z=0\\\\-1 & z<0 \\end{cases}$\n",
    "- Esto se conoce como el modelo matemático de una neurona de [McCulloch y Pitts](https://link.springer.com/article/10.1007/BF02478259)\n",
    "    - Las coeficientes del filtro son los pesos sinápticos de las dendritas\n",
    "    - La función no lineal corresponde al axón\n",
    "\n",
    "<img src=\"img/adaptive-neuron.png\" width=\"400\"><img src=\"img/adaptive-neuron2.jpeg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- El algoritmo para entrenar la neurona artificial se conoce como **algoritmo percetrón**\n",
    "- Asumimos un vector de pesos inicial nulo $\\textbf{w}^{(t=0)} = [0, 0, ..., 0]$\n",
    "- La función de costo en el instante $t$ al presentar el ejemplo $(d_n, u_n)$ \n",
    "$$\n",
    "\\mathcal{L}( \\textbf{w}^{(t)} ) = \\text{max} \\Big(0 ~, - d_n \\langle \\textbf{w}^{(t)}, \\text{concat}(1, u_n) \\rangle \\Big)\n",
    "$$\n",
    "- y su derivada es \n",
    "$$\n",
    "\\frac{d \\mathcal{L}(\\textbf{w}^{(t)} )}{d \\textbf{w}}  = \\begin{cases} 0 & d_n \\langle \\textbf{w}, \\text{concat}(1, u_n) \\rangle \\geq 0 \\\\ - d_n \\text{concat}(1, u_n)  & d_n \\langle \\textbf{w}, \\text{concat}(1, u_n) \\rangle < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "es decir que la derivada es cero si el ejemplo está bien clasificado\n",
    "- Finalmente la regla perceptron usando SGD con tasa de aprendizaje $\\mu$ es \n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}^{(t+1)} &= \\textbf{w}^{(t)} - \\mu \\frac{d \\mathcal{L}(\\textbf{w}^{(t)} )}{d \\textbf{w}} \\nonumber \\\\\n",
    "& = \\textbf{w}^{(t)} + \\begin{cases} \\mu d_n \\text{concat}(1, u_n) & \\\\ 0 & \\text{en otro caso} \\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "es decir que si el ejemplo está bien clasificado los pesos no se actualizan\n",
    "\n",
    "### Detalles del algoritmo perceptrón\n",
    "- En cada iteración se presenta un ejemplo \n",
    "- Se dice que se completa una época de entrenamiento cuando se han presentado los $N$ ejemplos\n",
    "- Presentar los ejemplos en distinto orden en cada época ayuda a evitar sesgos y acelera la convergencia\n",
    "- Detenemos el entrenamiento cuando todos los ejemplos están bien clasificados o al cumplir un cierto número de épocas sin cambio\n",
    "- El algoritmo perceptrón está garantizado a converger en tiempo finito si el problema es **linealmente separable**\n",
    "- Si el problema no es **linealmente separable** la convergencia se puede forzar disminuyendo gradualmente $\\mu$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "N = 50\n",
    "u = np.concatenate((np.random.randn(N, 2), 2 + np.random.randn(N, 2)))\n",
    "d = np.ones(shape=(2*N,)); d[:N] = -1.\n",
    "w = np.zeros(shape=(3, ))\n",
    "ax.scatter(u[:N, 0], u[:N, 1]); ax.scatter(u[N:, 0], u[N:, 1])\n",
    "x_plot = np.linspace(np.amin(u), np.amax(u))\n",
    "plane = ax.plot(x_plot, -w[0]/(w[2]+1e-10) - x_plot*w[1]/(w[2]+1e-10), 'k-', lw=4, alpha=0.75) \n",
    "P = np.random.permutation(2*N)\n",
    "dot = ax.plot([], [], 'ko', markersize=10)\n",
    "mu = 1e-5\n",
    "\n",
    "def update(n):\n",
    "    global w\n",
    "    idx = P[n - 2*N*int(n / (2*N))]\n",
    "    if d[idx]*np.dot(w, np.concatenate((np.array([1]), u[idx]))) <= 0.:\n",
    "        w = w + mu*d[idx]*np.concatenate((np.array([1]), u[idx]))\n",
    "    dot[0].set_data(u[idx, 0], u[idx, 1])\n",
    "    plane[0].set_ydata(-w[0]/(w[2]+1e-10) - x_plot*w[1]/(w[2]+1e-10))\n",
    "    ax.set_title(\"Iteration %d\" %(n))\n",
    "        \n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, frames=300, interval=100, repeat=False, blit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Más allá del perceptron \n",
    "\n",
    "- El modelo de neurona con salida sigmoide se conoce como **regresión logística**\n",
    "- Tanto el perceptrón como el regresor logístico se pueden extender a más de dos clases: **regresor softmax**\n",
    "- Conectando varias neuronas en cadena se forma lo que se conoce como una perceptrón multicapa\n",
    "- El perceptrón multicapa es un ejemplo de **red neuronal artificial**\n",
    "- Las redes neuronales artificiales se estudiarán en detalle en el curso de **inteligencia artificial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tópicos extra\n",
    "\n",
    "- [On the Intrinsic Relationship Between the Least Mean Square and Kalman Filters](https://www.commsp.ee.ic.ac.uk/~mandic/LMS_Kalman_IEEE_SPM_2015.pdf)\n",
    "- [Adaptive notch filter](http://homes.esat.kuleuven.be/~tvanwate/courses/dsp2/1415/DSP2_slides_04_adaptievefiltering.pdf)\n",
    "- [Reconstruction using Wiener filter](https://wwwmpa.mpa-garching.mpg.de/~ensslin/lectures/Files/Wiener_Filter_Demo_NIFTy3.html)\n",
    "- [Kalman filter](https://scipy-cookbook.readthedocs.io/items/KalmanFiltering.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
