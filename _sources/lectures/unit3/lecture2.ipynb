{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "hv.opts.defaults(hv.opts.Curve(width=500), \n",
    "                 hv.opts.Points(width=500), \n",
    "                 hv.opts.Image(width=500, colorbar=True, cmap='Viridis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimadores adaptivos parte I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hasta ahora hemos estudiando sistemas lineales donde: \n",
    "\n",
    "- sus coeficientes quedan fijos luego del diseño y son constantes en el tiempo\n",
    "- hacen supuestos sobre los estadísticos de la señal/ruido\n",
    "\n",
    "¿Qué podemos hacer si\n",
    "\n",
    "- no podemos hacer supuestos sobre los estadísticos?\n",
    "- los estadísticos de la señal/ruido cambian en el tiempo?\n",
    "- estamos en un escenario donde los datos llegan continuamente (data streaming)?\n",
    "\n",
    "Cuando los estadísticos cambian en el tiempo decimos que la señal es **no estacionaria**. \n",
    "\n",
    "En estos casos necesitamos un estimador de tipo **adaptivo**, es decir sistemas y filtros cuyos coeficientes se pueden **adaptar** a medida que llegan nuevos datos. Estos estimadores se diseñan de acuerdo a un método de optimización que es *online*\n",
    "\n",
    "La siguiente figura muestra algunos ejemplos de aplicaciones de sistemas adaptivos\n",
    "\n",
    "<img src=\"../images/adaptive-systems1.png\" width=\"700\">\n",
    "\n",
    "El método de optimización online que utilizaremos principalmente en este curso es el gradiente descendente estocástico. Revisemos a continuación los fundamentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradiente descendente\n",
    "\n",
    "Sea un vector de pesos $w$ de largo $L+1$ que guarda los coeficientes de un estimador\n",
    "\n",
    "Sea ahora una función de costo que mapea el vector de pesos a un número real\n",
    "\n",
    "$$\n",
    "J(w): \\mathbb{R}^{L+1} \\to \\mathbb{R}\n",
    "$$ \n",
    "\n",
    "La función de costo debe ser tal que a menor $J$ menor sea el error del estimador \n",
    "\n",
    "Para entrenar un estimador o filtro adaptivo se tienen los siguientes pasos conceptuales\n",
    "\n",
    "1. Partimos de una solución inicial $w_0$\n",
    "1. Modificamos iterativamente $w$ tal que $J(w_{t+1}) < J(w_t)$\n",
    "1. Nos detenemos al cumplir un cierto criterio \n",
    "\n",
    "\n",
    "Para modificar iterativamete y eficientemente los pesos utilizaremos la regla del **gradiente descendente** (GD)\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\mu \\frac{dJ(w)}{dw},\n",
    "$$\n",
    "\n",
    "donde $\\mu$ se conoce como tasa de aprendizaje o \"paso\"\n",
    "\n",
    "- Imaginemos $J$ como una superficie de $L+1$ dimensiones\n",
    "- En cada punto el gradiente negativo de $J$ nos indica hacia donde está el descenso más abrupto\n",
    "- La tasa $\\mu$ nos da el largo del salto entre $w_t$ y $w_{t+1}$\n",
    "\n",
    "Observando la **expansión de Taylor de primer orden** de $J$ en $w_{t}$ \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J(w_{t+1}) &= J(w_t) + \\frac{dJ(w_t)}{dw} (w_{t+1} - w_{t})  \\nonumber \\\\\n",
    "&= J(w_t) -\\mu \\left \\| \\frac{dJ(w_t)}{dw} \\right \\|^2 \\leq J(w_t) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "es decir que usando la regla GD con $\\mu>0$ y asumiendo que $J$ es convexo entonces se cumple que $J$ siempre decrece monotónicamente. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente gráficas interactivas muestran una superficie de costo no convexa para un parámetro unidimensional. Cada punto representa una solución que parte desde una posición inicial distinta. Las flechas corresponden a la derivada multiplicada por la tasa de aprendizaje. \n",
    "\n",
    "Estudie la evolución de las tres soluciones en cada caso. En primer lugar se utiliza $\\mu=0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = lambda w : (w-1)**2 + 0.2*np.sin(2*np.pi*w) #  Función de costo\n",
    "gradJ = lambda w : 2*(w-1) + 0.2*2*np.pi*np.cos(2*np.pi*w) # Gradiente\n",
    "mu = 0.05 # Tasa de aprendizaje\n",
    "iteraciones = 15\n",
    "wt = np.zeros(shape=(iteraciones, 3))\n",
    "wt[0, :] = np.array([0.05, 0.4, 1.9]) # Solución inicial\n",
    "w_plot = np.linspace(0, 2, num=100)\n",
    "\n",
    "for k in range(1, iteraciones):\n",
    "    wt[k, :] = wt[k-1, :] - mu*gradJ(wt[k-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "loss_surface = hv.Curve((w_plot, J(w_plot)), 'w', 'J')\n",
    "hMap = hv.HoloMap(kdims='Iteración')\n",
    "for k in range(iteraciones):\n",
    "    dots = hv.Points((wt[k, :], J(wt[k, :]))).opts(size=10, color='k')\n",
    "    mag = mu*gradJ(wt[k, :])\n",
    "    angle = np.pi/2 - np.sign(-mag)*np.pi/2\n",
    "    mag = np.abs(mag)\n",
    "    arrows = hv.VectorField((wt[k, :], J(wt[k, :]), angle, mag)).opts(pivot='tail', \n",
    "                                                                      magnitude=hv.dim('Magnitude'), \n",
    "                                                                      rescale_lengths=False)\n",
    "    hMap[k] =  dots * arrows \n",
    "    \n",
    "loss_surface * hMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "    \n",
    "Dependiendo de donde partimos la solución final es distinta. El gradiente descedente puede quedarse \"atorado\" en un mínimo local o en un punto silla\n",
    "    \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora observe como evolucionan las tres soluciones con $\\mu=0.5$, es decir 10 veces más grande que el caso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = lambda w : (w-1)**2 + 0.2*np.sin(2*np.pi*w) #  Función de costo\n",
    "gradJ = lambda w : 2*(w-1) + 0.2*2*np.pi*np.cos(2*np.pi*w) # Gradiente\n",
    "mu = 0.5 # Tasa de aprendizaje\n",
    "iteraciones = 15\n",
    "wt = np.zeros(shape=(iteraciones, 3))\n",
    "wt[0, :] = np.array([0.05, 0.4, 1.9]) # Solución inicial\n",
    "w_plot = np.linspace(0, 2, num=100)\n",
    "\n",
    "for k in range(1, iteraciones):\n",
    "    wt[k, :] = wt[k-1, :] - mu*gradJ(wt[k-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "loss_surface = hv.Curve((w_plot, J(w_plot)), 'w', 'J')\n",
    "hMap = hv.HoloMap(kdims='Iteración')\n",
    "for k in range(iteraciones):\n",
    "    dots = hv.Points((wt[k, :], J(wt[k, :]))).opts(size=10, color='k')\n",
    "    mag = mu*gradJ(wt[k, :])\n",
    "    angle = np.pi/2 - np.sign(-mag)*np.pi/2\n",
    "    mag = np.abs(mag)\n",
    "    arrows = hv.VectorField((wt[k, :], J(wt[k, :]), angle, mag)).opts(pivot='tail', \n",
    "                                                                      magnitude=hv.dim('Magnitude'), \n",
    "                                                                      rescale_lengths=False)\n",
    "    hMap[k] =  dots * arrows \n",
    "    \n",
    "loss_surface * hMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "    \n",
    "Si la tasa de aprendizaje es muy alta, los pasos son muy largos y podríamos no converger a un punto estacionario\n",
    "\n",
    ":::\n",
    "\n",
    "Los ejemplos anteriores nos han mostrado algunas de las limitaciones del algoritmo de gradiente descendente. Es importante tenerlas en cuenta cuando lo utilicemos en nuestras aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradiente descendente en el filtro de Wiener\n",
    "\n",
    "Para el filtro de Wiener teníamos que\n",
    "\n",
    "$$\n",
    "J(h) = \\sigma_d^2 - 2 \\textbf{h}^T R_{ud} + \\textbf{h}^T R_{uu} \\textbf{h},\n",
    "$$\n",
    "\n",
    "por ende\n",
    "\n",
    "$$\n",
    "\\frac{dJ(h)}{dh} = -2 R_{ud} + 2 R_{uu} \\textbf{h}\n",
    "$$\n",
    "\n",
    "y finalmente\n",
    "\n",
    "$$\n",
    "\\textbf{h}_{t+1} = \\textbf{h}_{t} (I - 2 \\mu R_{uu}) + 2\\mu R_{ud}\n",
    "$$\n",
    "\n",
    "En este caso la condición para una convergencia estable es \n",
    "\n",
    "$$\n",
    "0 < \\mu < \\frac{1}{\\lambda_{\\text{max}}},\n",
    "$$\n",
    "\n",
    "donde $\\lambda_{\\text{max}}$ es valor propio más grande de $R_{uu}$ \n",
    "\n",
    "(La prueba de esto puede encontrarse en *Haykin, \"Adaptive filter theory\", Sección 4.3*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradiente descendente estocástico (SGD)\n",
    "\n",
    "El filtro de Wiener es óptimo pero no adaptivo:\n",
    "\n",
    "- Requiere de $N$ muestras de $u$ y $d$ para estimar $R_{ud}$ y $R_{uu}$\n",
    "- Los pesos se adaptan luego de haber presentado las $N$ muestras: Es una estrategia de tipo **batch**\n",
    "- Asume que la señal es estacionaria\n",
    "\n",
    "\n",
    "Si nuestros son no estacionarios significa que debemos adaptar el filtro a medida que nuevas muestras son observadas\n",
    ". Para lograr esto podemos usar la versión estocástica del GD: SGD\n",
    "\n",
    "En SGD: \n",
    "- los pesos se adaptan luego de haber presentado una sola muestra o un conjunto pequeño de muestras (mini-batch)\n",
    "- no hay garantía de llegar al óptimo en un problema convexo, pero es más eficiente computacionalmente que GD\n",
    "\n",
    "El siguiente esquema muestra una comparación entre la trayectoria de $w$ cuando se usa GD (negro) y SGD (rojo). En general la trayectoria de SGD será más ruidosa y también podría requerir más pasos, pero cada paso es mucho más económico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/adaptive-sgd.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo Least Mean Square (LMS)\n",
    "\n",
    "\n",
    "Podemos extender el filtro de Wiener al caso no-estacionario usando SGD, el resultado es un algoritmo simple que además es robusto: **El algoritmo LMS**\n",
    "\n",
    "- Fue fue inventado en 1960 por [Bernard Widrow](https://en.wikipedia.org/wiki/Bernard_Widrow) y Ted Hoff\n",
    "- A diferencia del filtro de Wiener no se requiere conocimiento estadístico del proceso. Tampoco se requiere calcular e invertir la matriz de correlación\n",
    "- El algoritmo LMS se ajusta o entrena de manera recursiva y online\n",
    "\n",
    "\n",
    "Consideremos la función de costo **estocástica**  para la arquitectura FIR que utilizamos para el filtro de Wiener\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J^s_n(\\textbf{w}) &= e_n^2 \\nonumber \\\\\n",
    "&= (d_n - y_n)^2 \\nonumber \\\\\n",
    "&= (d_n - \\textbf{w}^T \\textbf{u}_n )^2 \\nonumber \\\\\n",
    "&= (d_n - \\sum_{k=0}^{L} w_{n, k} u_{n-k} )^2 \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde definimos $\\textbf{u}_n = [u_n, u_{n-1}, \\ldots, u_{n-L}]$. \n",
    "\n",
    ":::{note}\n",
    "\n",
    "A diferencia del filtro de Wiener no aplicamos el valor esperado al error cuadrático. Se usa el error cuadrático instantaneo\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar calculamos el gradiente en función del peso $w_{n, k}$ \n",
    "\n",
    "$$\n",
    "\\frac{d J^s_n (\\textbf{w})}{d w_{n, k}} = - 2 e_n u_{n-k}\n",
    "$$\n",
    "\n",
    "Luego, usando la regla SGD llegamos a \n",
    "\n",
    "$$\n",
    "w_{n+1, k} = w_{n, k} + 2 \\mu e_n u_{n-k}, k=0, 1, \\ldots, L\n",
    "$$\n",
    "\n",
    "y que en forma matricial es\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}_{n+1} &= \\textbf{w}_{n} + 2 \\mu e_n \\textbf{u}_{n}\\nonumber \\\\\n",
    "&= \\textbf{w}_{n} + 2 \\mu (d_n -  \\textbf{w}_{n}^T \\textbf{u}_{n}) \\textbf{u}_{n}, \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "que se conoce como la regla de **Widrow-Hoff**\n",
    "\n",
    ":::{important}\n",
    "    \n",
    "El algoritmo LMS estima el error instantaneo y actualiza los pesos recursivamente\n",
    "    \n",
    ":::\n",
    "\n",
    "La complejidad de este algoritmo es $L+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergencia del algoritmo LMS (Haykin 6.5)\n",
    "\n",
    "El algoritmo LMS tiende en la media al valor óptimo\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\textbf{w}_n] \\to \\textbf{w}^*\n",
    "$$ \n",
    "\n",
    "para $n\\to \\infty$\n",
    "\n",
    "Además convergence en la media cuadrada: La varianza de $\\textbf{w}_n - \\textbf{w}^*$ tiene al valor mínimo de $J$ para $n\\to \\infty$\n",
    "\n",
    "Esto se cumple si \n",
    "\n",
    "$$\n",
    "0 < \\mu < \\frac{2}{\\text{Tr}[R_{uu}]}\n",
    "$$\n",
    "\n",
    "donde $R_{uu} = \\mathbb{E}[\\textbf{u}_n \\textbf{u}_n^T ]$ es la matriz de autocorrelación y $\\text{Tr}[]$ el operador que calcula la traza de una matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algoritmo Normalized LMS (NLMS)\n",
    "\n",
    "Tenemos la siguiente regla iterativa\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}_{n+1} &= \\textbf{w}_{n} + 2 \\mu (d_n -  \\textbf{w}_{n}^T \\textbf{u}_{n}) \\textbf{u}_{n} \\nonumber \\\\\n",
    "& = \\textbf{w}_{n} + \\Delta \\textbf{w}_n \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "que se puede interpretar graficamente como\n",
    "\n",
    "<img src=\"../images/adaptive-lms-geometry.png\" width=\"400\">\n",
    "\n",
    "(donde $\\textbf{x}(k)$ y $\\textbf{w}(k)$ corresponden a $\\textbf{u}_n$ y $\\textbf{w}_n$ en nuestra notación, respectivamente)\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Los cambios en el vector de peso $\\Delta \\textbf{w}_n$ son paralelos a $\\textbf{u}_{n}$. Además estos cambios podrían estar dominados por \n",
    "\n",
    "$$\n",
    "\\max \\textbf{u}_{n} = [u_n, u_{n-1}, \\ldots, u_{n-L}]\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n",
    "El algoritmo **Normalized LMS** (NLMS) corrige este problema ponderando por la varianza de $\\textbf{u}_{n}$ \n",
    "\n",
    "$$\n",
    "\\textbf{w}_{n+1} = \\textbf{w}_{n} + 2 \\mu (d_n -  \\textbf{w}_{n}^T \\textbf{u}_{n}) \\frac{\\textbf{u}_{n}}{\\left(\\|\\textbf{u}_{n}\\|^2 + \\delta\\right)}\n",
    "$$\n",
    "\n",
    "donde la constante $\\delta$ es un valor pequeño que se usa para evitar divisiones por cero. En lo que sigue usaremos NLMS para revisar algunas aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementación del filtro NLMS en Python \n",
    "\n",
    "Podemos implementar las ecuaciones del filtro NLMS como se muestra a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filtro_NLMS:\n",
    "    \n",
    "    def __init__(self, L, mu, delta=1e-6, winit=None):\n",
    "        self.L = L\n",
    "        self.w = np.zeros(shape=(L+1, ))\n",
    "        self.mu = mu\n",
    "        self.delta = delta\n",
    "        \n",
    "    def update(self, un, dn):\n",
    "        # Asumiendo que un = [u[n], u[n-1], ..., u[n-L]]\n",
    "        unorm = np.dot(un, un) + self.delta\n",
    "        yn = np.dot(self.w, un)\n",
    "        self.w += 2*self.mu*(dn - yn)*(un/unorm)\n",
    "        return yn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- El filtro recibe como entrada el orden $L$ y la tasa de aprendizaje $\\mu$\n",
    "- Se asume un vector cero para los pesos iniciales, pero también en la práctica podemos partir de una solución anterior si esta existiera \n",
    "- Para actualizar el vector de pesos es necesario entregar el vector $\\textbf{u}_n \\in \\mathbb{R}^{L+1}$ y la salida deseada $d_n \\in \\mathbb{R}$. La función `update` retorna la salida predicha por el filtro $y_n = w_n^T \\textbf{u}_n\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación probaremos este filtro con una aplicación conocida como **Adaptive line enhancement** (ALE). ALE se refiere a un sistema adaptivo para eliminar ruido blanco aditivo de una señal. El sistema aprende un filtro pasabanda en torno a la frecuencia de interés\n",
    "\n",
    "En ALE usamos como señal deseada \n",
    "\n",
    "$$\n",
    "d_n = u_n = \\textbf{u}_n[0]\n",
    "$$\n",
    "\n",
    "El valor predicho por el filtro será la señal $u$ pero libre de ruido blanco. Esto se debe a que el ruido blanco no tiene correlación y por ende el filtro adaptivo no lo puede predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digamos que u = s + n\n",
    "# El objetivo es limpiar u para obtener s\n",
    "# s es una señal determínista y n es ruido blanco\n",
    "\n",
    "Fs, f0 =  100, 5\n",
    "t = np.arange(0, 4, 1/Fs)\n",
    "s = np.sin(2.0*np.pi*t*f0)\n",
    "n = 0.5*np.random.randn(len(t)) \n",
    "s[t>2.0] += 5  # Simulemos un cambio abrupto en la media de la señal\n",
    "#s += s*(0.5 + 0.5*np.cos(2.0*np.pi*t/2))  # Tremolo (AM)\n",
    "u = s + n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de un filtro estático (como el filtro de Wiener) es posible filtrar incluso ante cambios bruscos en la señal. \n",
    "\n",
    "Estudie como cambia el resultado del filtro con distintos valores de $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 20\n",
    "u_preds = {}\n",
    "\n",
    "for mu in np.logspace(-2, 0, num=10):\n",
    "    myfilter = Filtro_NLMS(L=L, mu=mu)\n",
    "    u_preds[mu] = np.zeros(shape=(len(u),))\n",
    "    for k in range(L+1, len(u)):\n",
    "        u_preds[mu][k] = myfilter.update(u[k-L-1:k][::-1], u[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "hMap = hv.HoloMap(kdims='mu')\n",
    "for mu, u_pred in u_preds.items():\n",
    "    s1 = hv.Curve((t, s), 'Tiempo', 'Señal', label='Limpia')\n",
    "    s2 = hv.Scatter((t, u), 'Tiempo', 'Señal', label='Contaminada')\n",
    "    s3 = hv.Curve((t, u_pred), 'Tiempo', 'Señal', label='Filtrada')\n",
    "    hMap[mu] = hv.Overlay([s1, s2, s3]).opts(hv.opts.Overlay(legend_position='top'), \n",
    "                                             hv.opts.Curve(ylim=(-5, 10), height=350))\n",
    "hMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{important}\n",
    "    \n",
    "La tasa de aprendizaje $\\mu$ controla la velocidad de adaptación. Pero una tasa demasiado grande provoca que el filtro sea inestable. En general el valor óptimo de $\\mu$ depende del problema y del valor de $L$\n",
    "    \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente figura muestra la respuesta en frecuencia del filtro en función del tiempo para $\\mu=0.02$\n",
    "\n",
    "Observe como a medida que se adapta el filtro se concentra en la frecuencia fundamental de la señal, que en este caso es 5 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 20\n",
    "u_preds = {}\n",
    "myfilter = Filtro_NLMS(L=L, mu=0.02)\n",
    "H_history = np.zeros(shape=(512, len(u))) \n",
    "for k in range(L+1, len(u)):\n",
    "    myfilter.update(u[k-L-1:k][::-1], u[k])\n",
    "    fk, Hk = scipy.signal.freqz(b=myfilter.w, a=1, fs=Fs)\n",
    "    H_history[:, k] = np.abs(Hk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "hv.Image((t, fk, H_history), kdims=['Tiempo [s]', 'Frecuencia [Hz]']).opts(cmap='Blues') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación entre Filtro de Wiener/GD y algoritmo LMS/SGD\n",
    "\n",
    "- **Supuestos**:  Wiener requiere un ambiente estacionario lo cual nos permite calcular $R_{uu}$ y $R_{ud}$. En LMS la señal puede ser no estacionaria.\n",
    "- **Aprendizaje:** En el filtro de Wiener el aprendizaje es determinista. En LMS el aprendizaje viene **promediando** a nivel de los estimadores de $w$. En LMS el aprendizaje es estadístico. \n",
    "- **Optimalidad:** Wiener es óptimo en cambio LMS es sub-óptimo (localmente óptimo). LMS tiende a la solución de Wiener\n",
    "- **Costo:** LMS se actualiza online y tiene costo $L$. Wiener se entrena offline y tiene costo $L^2$\n",
    "\n",
    "A continuación se muestra un diagrama que compara el filtro de Wiener y el algoritmo LMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../images/adaptive-lms.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
