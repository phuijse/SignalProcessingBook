
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Universidad Austral de Chile &#8212; INFO183 Análisis de sistemas lineales</title>
    
  <link rel="stylesheet" href="../../_static/css/index.d431a4ee1c1efae0e38bdfebc22debff.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.bfb7730f9caf2ec0b46a44615585038c.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/ui_handle.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.30270b6e4c972e43c488.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">INFO183 Análisis de sistemas lineales</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar este libro ..." aria-label="Buscar este libro ..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <p class="caption">
 <span class="caption-text">
  Unidad 1
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad1/01_introducci%C3%B3n.html">
   1. Introducción al procesamiento digital de señales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad1/02_espectro.html">
   2. Espectro y Transformada de Fourier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad1/03_muestreo.html">
   3. Efectos del muestreo y fenómeno de aliasing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad1/04_enventanado.html">
   4. Fuga espectral y técnica de enventanado
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Unidad 2
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad2/01_espectrograma.html">
   1. Espectrograma
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad2/02_sistemas.html">
   2. Sistemas para el procesamiento de señales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad2/03_filtros_FIR.html">
   3. Diseño de sistemas y filtros FIR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../unidad2/04_filtros_IIR.html">
   4. Diseño de sistemas y filtros IIR
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Unidad 3
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01_wiener.html">
   1. Estimador lineal óptimo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_LMS.html">
   2. Estimadores adaptivos parte I
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Navegación de palanca" aria-controls="site-navigation"
            title="Navegación de palanca" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Descarga esta pagina"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/clases/unidad3/04_kalman.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Descargar archivo fuente" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Imprimir en PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Modo de pantalla completa"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phuijse/UACH-INFO183/master?urlpath=tree/clases/unidad3/04_kalman.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Lanzamiento Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/phuijse/UACH-INFO183/blob/master/clases/unidad3/04_kalman.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Lanzamiento Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contenido
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Universidad Austral de Chile
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#info183-analisis-de-sistemas-lineales">
   INFO183: Análisis de sistemas lineales
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unidad-4-sistemas-y-filtros-adaptivos">
   Unidad 4: Sistemas y filtros adaptivos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dr-pablo-huijse-phuijse-at-inf-dot-uach-dot-cl">
     Dr. Pablo Huijse, phuijse at inf dot uach dot cl
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-href-https-github-com-phuijse-uach-info183-github-com-phuijse-uach-info183-a">
     <a href="https://github.com/phuijse/UACH-INFO183">
      github.com/phuijse/UACH-INFO183
     </a>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contenidos-de-la-unidad">
   Contenidos de la unidad
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bibliografia">
     Bibliografía
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducción
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#proceso-aleatorio-estocastico">
     Proceso aleatorio/estocástico
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#densidad-espectral-de-potencia">
       Densidad espectral de potencia
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimadores-optimos">
   Estimadores óptimos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filtro-de-wiener">
     Filtro de Wiener
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ajuste-del-filtro-de-wiener">
     Ajuste del filtro de Wiener
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#error-minimo-del-filtro-de-wiener">
     Error mínimo del filtro de Wiener
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filtro-de-wiener-regresion-identificacion-de-sistema">
     Filtro de wiener: Regresión (identificación de sistema)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#entrenamiento-del-predictor">
       Entrenamiento del predictor
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#filtro-de-wiener-prediccion">
     Filtro de wiener: Predicción
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Entrenamiento del predictor
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filtro-de-wiener-eliminar-ruido-blanco-aditivo">
   Filtro de Wiener: Eliminar ruido blanco aditivo
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sistemas-adaptivos">
   Sistemas adaptivos
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradiente-descendente">
   Gradiente descendente
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradiente-descendente-en-el-filtro-de-wiener">
     Gradiente descendente en el filtro de Wiener
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradiente-descendente-estocastico-sgd">
   Gradiente descendente estocástico (SGD)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algoritmo-least-mean-square-lms">
   Algoritmo Least Mean Square (LMS)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretacion-geometrica-del-algoritmo-lms">
   Interpretación geométrica del algoritmo LMS
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lms-adaptive-line-enhancement-ale">
     LMS: Adaptive line enhancement (ALE)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comparacion-entre-filtro-de-wiener-gd-y-algoritmo-lms-sgd">
     Comparación entre Filtro de Wiener/GD y algoritmo LMS/SGD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lms-cancelacion-de-eco">
     LMS: Cancelación de eco
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algoritmo-recursive-least-squares-rls">
   Algoritmo Recursive Least Squares (RLS)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notas">
     Notas
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resumen-algoritmo-rls">
     Resumen algoritmo RLS
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recomendaciones">
       Recomendaciones
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rls-versus-lms-tracking">
       RLS versus LMS: Tracking
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algoritmo-perceptron-rosemblatt-1962">
   Algoritmo Perceptrón (Rosemblatt 1962)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detalles-del-algoritmo-perceptron">
     Detalles del algoritmo perceptrón
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mas-alla-del-perceptron">
     Más allá del perceptron
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#topicos-extra">
     Tópicos extra
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%HTML</span>
<span class="c">&lt;!-- Mejorar visualización en proyector --&gt;</span>
<span class="p">&lt;</span><span class="nt">style</span><span class="p">&gt;</span>
<span class="p">.</span><span class="nc">rendered_html</span> <span class="p">{</span><span class="k">font-size</span><span class="p">:</span> <span class="mf">1.2</span><span class="kt">em</span><span class="p">;</span> <span class="k">line-height</span><span class="p">:</span> <span class="mi">150</span><span class="kt">%</span><span class="p">;}</span>
<span class="nt">div</span><span class="p">.</span><span class="nc">prompt</span> <span class="p">{</span><span class="k">min-width</span><span class="p">:</span> <span class="mi">0</span><span class="kt">ex</span><span class="p">;</span> <span class="k">padding</span><span class="p">:</span> <span class="mi">0</span><span class="kt">px</span><span class="p">;}</span>
<span class="p">.</span><span class="nc">container</span> <span class="p">{</span><span class="k">width</span><span class="p">:</span><span class="mi">90</span><span class="kt">%</span> <span class="cp">!important</span><span class="p">;}</span>
<span class="p">&lt;/</span><span class="nt">style</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><!-- Mejorar visualización en proyector -->
<style>
.rendered_html {font-size: 1.2em; line-height: 150%;}
div.prompt {min-width: 0ex; padding: 0px;}
.container {width:90% !important;}
</style>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span>
<span class="o">%</span><span class="k">matplotlib</span> notebook
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span><span class="p">,</span> <span class="n">patches</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Audio</span><span class="p">,</span> <span class="n">HTML</span>
<span class="kn">import</span> <span class="nn">soundfile</span> <span class="k">as</span> <span class="nn">sf</span>
<span class="kn">from</span> <span class="nn">style</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="mi">8803</span><span class="n">d11cb4cf</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Audio</span><span class="p">,</span> <span class="n">HTML</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">import</span> <span class="nn">soundfile</span> <span class="k">as</span> <span class="nn">sf</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="kn">from</span> <span class="nn">style</span> <span class="kn">import</span> <span class="o">*</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;style&#39;
</pre></div>
</div>
</div>
</div>
<div class="section" id="universidad-austral-de-chile">
<h1>Universidad Austral de Chile<a class="headerlink" href="#universidad-austral-de-chile" title="Enlazar permanentemente con este título">¶</a></h1>
</div>
<div class="section" id="info183-analisis-de-sistemas-lineales">
<h1>INFO183: Análisis de sistemas lineales<a class="headerlink" href="#info183-analisis-de-sistemas-lineales" title="Enlazar permanentemente con este título">¶</a></h1>
</div>
<div class="section" id="unidad-4-sistemas-y-filtros-adaptivos">
<h1>Unidad 4: Sistemas y filtros adaptivos<a class="headerlink" href="#unidad-4-sistemas-y-filtros-adaptivos" title="Enlazar permanentemente con este título">¶</a></h1>
<div class="section" id="dr-pablo-huijse-phuijse-at-inf-dot-uach-dot-cl">
<h2>Dr. Pablo Huijse, phuijse at inf dot uach dot cl<a class="headerlink" href="#dr-pablo-huijse-phuijse-at-inf-dot-uach-dot-cl" title="Enlazar permanentemente con este título">¶</a></h2>
</div>
<div class="section" id="a-href-https-github-com-phuijse-uach-info183-github-com-phuijse-uach-info183-a">
<h2><a href="https://github.com/phuijse/UACH-INFO183"> github.com/phuijse/UACH-INFO183 </a><a class="headerlink" href="#a-href-https-github-com-phuijse-uach-info183-github-com-phuijse-uach-info183-a" title="Enlazar permanentemente con este título">¶</a></h2>
<hr class="docutils" />
<p><a id="index"></a></p>
</div>
</div>
<div class="section" id="contenidos-de-la-unidad">
<h1>Contenidos de la unidad<a class="headerlink" href="#contenidos-de-la-unidad" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<ol class="simple">
<li><p><a class="reference external" href="#section1">Estimador lineal óptimo</a></p></li>
<li><p><a class="reference external" href="#section2">Gradiente descendente</a></p></li>
<li><p><a class="reference external" href="#section3">Algoritmo de mínimos cuadrados (LMS)</a></p></li>
<li><p><a class="reference external" href="#section4">Algoritmo de mínimos cuadrados recursivo (RLS)</a></p></li>
<li><p><a class="reference external" href="#section5">Algoritmo perceptrón</a></p></li>
</ol>
<div class="section" id="bibliografia">
<h2>Bibliografía<a class="headerlink" href="#bibliografia" title="Enlazar permanentemente con este título">¶</a></h2>
<ol class="simple">
<li><p>Simon Haykin, «Adaptive filter theory» 5ed, Pearson</p></li>
</ol>
</div>
</div>
<div class="section" id="introduccion">
<h1>Introducción<a class="headerlink" href="#introduccion" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<ul class="simple">
<li><p><strong>Estimador:</strong> Sistema diseñado para <strong>extraer información</strong> a partir de una <strong>señal</strong></p></li>
<li><p>La señal contiene <strong>información y ruido</strong></p></li>
<li><p>La señal es representada como una secuencia de <strong>datos</strong></p></li>
</ul>
<p>Tipos de estimador</p>
<ul class="simple">
<li><p><strong>Filtro:</strong> Estimo el valor actual de mi señal acentuando o eliminando una o más características</p></li>
<li><p><strong>Predictor:</strong> Estimo el valor futuro de mi señal</p></li>
</ul>
<p>Estimador lineal óptimo</p>
<ul class="simple">
<li><p>Lineal: La cantidad estimada es una función lineal de la entrada</p></li>
<li><p>Óptimo: El estimador es la mejor solución posible de acuerdo a un criterio (<em>e.g.</em> Error cuadrático medio)</p></li>
</ul>
<p>Estimador lineal adaptivo</p>
<ul class="simple">
<li><p>Es lineal pero no LTI</p></li>
<li><p>Sus parámetros cambian en función del tiempo</p></li>
<li><p>Diseñamos una regla para actualizar sus parámetros</p></li>
<li><p>Usualmente las reglas están basadas en criterios de optimización</p></li>
</ul>
<img alt="clases/unidad3/img/adaptive-systems1.png" src="clases/unidad3/img/adaptive-systems1.png" />
<div class="section" id="proceso-aleatorio-estocastico">
<h2>Proceso aleatorio/estocástico<a class="headerlink" href="#proceso-aleatorio-estocastico" title="Enlazar permanentemente con este título">¶</a></h2>
<hr class="docutils" />
<ul class="simple">
<li><p>Colección de variables aleatorias indexadas en el tiempo</p></li>
<li><p>Evolución de un fenomeno estadístico en el tiempo</p></li>
<li><p>El fenomeno se rige por leyes probabilísticas</p></li>
</ul>
<p>Un proceso aleatorio <span class="math notranslate nohighlight">\(U_n = (u_n, u_{n-1}, u_{n-2}, \ldots, u_{n-L})\)</span> se describe a través de sus momentos</p>
<p>Si consideramos una caracterízación de segundo orden necesitamos definir</p>
<ul class="simple">
<li><p>Momento central o media
$<span class="math notranslate nohighlight">\(
\mu(n) = \mathbb{E}[U_n]
\)</span>$</p></li>
<li><p>Segundo momento o correlación
$<span class="math notranslate nohighlight">\(
r_{uu}(n, n-k) = \mathbb{E}[U_n U_{n-k}]
\)</span>$</p></li>
<li><p>Segundo momento centrado o covarianza
$$</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-22bec59a-883d-48f1-8c7d-3749824d2287">
<span class="eqno">()<a class="headerlink" href="#equation-22bec59a-883d-48f1-8c7d-3749824d2287" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
c_{uu}(n, n-k) &amp;= \mathbb{E}[(U_n-\mu_n) (U_{n-k}- \mu_{n-k})] \nonumber \\
&amp;= r(n,n-k) - \mu_n \mu_{n-k} \nonumber
\end{align}\]</div>
<div class="math notranslate nohighlight">
\[
- correlación cruzada entre dos procesos 
\]</div>
<p>r_{ud}(n, n-k) = \mathbb{E}[U_n D_{n-k}]
$$</p>
<hr class="docutils" />
<p>En general consideraremos el caso simplificado donde el proceso es estacionario</p>
<div class="math notranslate nohighlight">
\[
\mu(n)  = \mu, \forall n
\]</div>
<p>y
$<span class="math notranslate nohighlight">\(
r_{uu}(n, n-k)  = r_{uu}(k), \forall n
\)</span><span class="math notranslate nohighlight">\(
es decir los estadísticos se mantienen constantes en el tiempo (no depende de \)</span>n$)</p>
<p>Otra simplificación es que el proceso sea ergódico</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[U_n] = \frac{1}{N} \sum_{n=1}^N u_n
\]</div>
<p>es decir podemos reemplazar el valor esperado por la media en el tiempo</p>
<hr class="docutils" />
<div class="section" id="densidad-espectral-de-potencia">
<h3>Densidad espectral de potencia<a class="headerlink" href="#densidad-espectral-de-potencia" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Otra cantidad de interés es la PSD (<em>power spectral density</em>) que mide la distribución de la potencia en frecuencia</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
S_{uu}(f) &amp;= \sum_{k=-\infty}^{\infty} r_{uu}(k) e^{-j 2\pi f k} \nonumber \\
&amp;= \lim_{N\to\infty} \frac{1}{2N+1} \mathbb{E} \left [\left|\sum_{n=-N}^{N} u_n e^{-j 2\pi f n} \right|^2 \right]
\end{align}
\end{split}\]</div>
<p>que corresponde a la transformada de Fourier de la correlación (caso estacionario)</p>
<p>La PSD y la correlación forman un par de Fourier</p>
<p><a class="reference external" href="#index">← Volver al índice</a></p>
<hr class="docutils" />
<p><a id="section1"></a></p>
</div>
</div>
</div>
<div class="section" id="estimadores-optimos">
<h1>Estimadores óptimos<a class="headerlink" href="#estimadores-optimos" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<p><a class="reference external" href="http://dle.rae.es/?id=R7bbor7">Óptimo</a>: adj. Sumamente bueno, que no puede ser mejor.</p>
<p>Para diseñar un estimador óptimo necesitamos un <strong>criterio</strong></p>
<p>Luego el estimador será <strong>óptimo según dicho criterio</strong></p>
<p>Usualmente también consideramos supuestos. Podríamos asumir que</p>
<ul class="simple">
<li><p>el ruido es aditivo y blanco o que tiene una cierta covarianza conocida</p></li>
<li><p>conocemos la media y covarianza de la señal</p></li>
<li><p>el proceso es estacionario</p></li>
</ul>
<div class="section" id="filtro-de-wiener">
<h2>Filtro de Wiener<a class="headerlink" href="#filtro-de-wiener" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Filtro LTI de tiempo discreto</p></li>
<li><p>Estructura FIR con <span class="math notranslate nohighlight">\(L+1\)</span> coeficientes: <span class="math notranslate nohighlight">\(h_0, h_1, h_2, \ldots, h_{L}\)</span></p></li>
<li><p>La entrada es una señal <span class="math notranslate nohighlight">\(u_0, u_1, u_2, \ldots\)</span></p></li>
<li><p>Para cada tiempo el filtro produce una salida <span class="math notranslate nohighlight">\(y_0, y_1, y_2, \ldots\)</span></p></li>
</ul>
<p>Adaptamos los coeficientes del filtro con dos ingredientes</p>
<ul class="simple">
<li><p>Una respuesta «deseada» <span class="math notranslate nohighlight">\(d_0, d_1, d_2, \ldots\)</span></p></li>
<li><p>Un criterio de optimalidad que opera sobre el error entre la respuesta deseada y la salida
$<span class="math notranslate nohighlight">\(
e_n = d_n - y_n = d_n - \sum_{k=0}^{L} h_k u_{n-k} 
\)</span>$</p></li>
</ul>
<p>Diagrama del filtro de Wiener</p>
<p><img alt="wiener.png" src="clases/unidad3/attachment:wiener.png" /></p>
<p>(Este filtro fue publicado por Norbert Wiener en 1949)</p>
</div>
<div class="section" id="ajuste-del-filtro-de-wiener">
<h2>Ajuste del filtro de Wiener<a class="headerlink" href="#ajuste-del-filtro-de-wiener" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El criterio más común para adaptar el filtro de Wiener es <strong>el error medio cuadrático</strong> entre la respuesta deseada y la salida del filtro. Asumiendo que la <span class="math notranslate nohighlight">\(u\)</span> e <span class="math notranslate nohighlight">\(d\)</span> son secuencias reales</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{MSE} &amp;= \mathbb{E}\left [e_n^2 \right] \nonumber \\
&amp;= \mathbb{E}\left [(d_n - y_n)^2 \right] \nonumber \\
&amp;= \mathbb{E}\left [d_n^2 \right]  - 2\mathbb{E}\left [ d_n y_n \right] + \mathbb{E}\left [ y_n^2 \right] \nonumber 
\end{align}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\sigma_d^2 = \mathbb{E}\left [d_n^2 \right]\)</span> es la varianza de la señal deseada y <span class="math notranslate nohighlight">\(\sigma_y^2 = \mathbb{E}\left [ y_n^2 \right]\)</span> es la varianza de nuestro estimador</p>
<hr class="docutils" />
<p>Minimizar el MSE implica acercar la salida del filtro a la respuesta deseada</p>
<hr class="docutils" />
<p>En este caso igualando la derivada del MSE a cero tenemos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\frac{d}{d h_j} \text{MSE} &amp;= -2\mathbb{E}\left[ d_n \frac{d y_n}{d h_j}  \right]  + 2 \mathbb{E}\left[ y_n \frac{d y_n}{d h_j}    \right]  \nonumber \\
&amp;= -2\mathbb{E}\left[ d_n u_{n-j} \right]  + 2 \mathbb{E}\left[ y_n u_{n-j}    \right]  \nonumber \\
&amp;= -2\mathbb{E}\left[ d_n u_{n-j} \right]  + 2 \mathbb{E}\left[ \sum_{k=0}^{L} h_k u_{n-k}  u_{n-j} \right] \nonumber \\
&amp;= -2\mathbb{E}\left[ d_n u_{n-j} \right]  + 2 \sum_{k=0}^{L} h_k \mathbb{E}\left[ u_{n-k}  u_{n-j} \right] = 0 \nonumber \end{align}
\end{split}\]</div>
<p>Si despejamos y repetimos para <span class="math notranslate nohighlight">\(j=0, \ldots, L\)</span> obtenemos el siguiente sistema de ecuaciones</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\begin{pmatrix}
r_{uu}(0) &amp; r_{uu}(1) &amp; r_{uu}(2) &amp; \ldots &amp; r_{uu}(L) \\
r_{uu}(1) &amp; r_{uu}(0) &amp; r_{uu}(1) &amp; \ldots &amp; r_{uu}(L-1) \\
r_{uu}(2) &amp; r_{uu}(1) &amp; r_{uu}(0) &amp; \ldots &amp; r_{uu}(L-2) \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp;\vdots \\
r_{uu}(L) &amp; r_{uu}(L-1) &amp; r_{uu}(L-2) &amp; \ldots &amp; r_{uu}(0) \\
\end{pmatrix}
\begin{pmatrix}
h_0  \\
h_1  \\
h_2  \\
\vdots  \\
h_L \\
\end{pmatrix} &amp;= 
\begin{pmatrix}
r_{ud}(0)  \\
r_{ud}(1)  \\
r_{ud}(2) \\
\vdots  \\
r_{ud}(L) \\
\end{pmatrix} \nonumber \\
R_{uu} \textbf{h} &amp;= R_{ud},
\end{align}
\end{split}\]</div>
<p>que se conoce como las ecuaciones de Wiener-Hopf.</p>
<p>Además <span class="math notranslate nohighlight">\(R_{uu}\)</span> se conoce como matriz de auto-correlación. Asumiendo que <span class="math notranslate nohighlight">\(R_{uu}\)</span> es no-singular, la <strong>solución óptima en el sentido de mínimo MSE</strong> es</p>
<div class="math notranslate nohighlight">
\[
\textbf{h}^{*} = R_{uu} ^{-1} R_{ud}
\]</div>
<p>En general <span class="math notranslate nohighlight">\(R_{uu}\)</span> es una matriz definida-positiva (su inversa existe) y el sistema puede resolverse en <span class="math notranslate nohighlight">\(\mathcal{O}(L^2)\)</span> usando la <a class="reference external" href="https://en.wikipedia.org/wiki/Levinson_recursion">recursión de Levison-Durbin</a></p>
<p>Requisitos/supuestos de este filtro</p>
<ul class="simple">
<li><p>la salida deseada y la entrada tienen media cero, <em>i.e.</em> <span class="math notranslate nohighlight">\(\mathbb{E}[d_n] = \mathbb{E}[u_n] = 0\)</span> (si existe podemos restarla)</p></li>
<li><p>la salida deseada y la entrada son estacionarias en el sentido amplio, <em>i.e.</em> la correlación solo depende de <span class="math notranslate nohighlight">\(m\)</span></p></li>
</ul>
</div>
<div class="section" id="error-minimo-del-filtro-de-wiener">
<h2>Error mínimo del filtro de Wiener<a class="headerlink" href="#error-minimo-del-filtro-de-wiener" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Dado que <span class="math notranslate nohighlight">\(y_n = \textbf{h}^T U_n = U_n^T \textbf{h} \)</span>, podemos expresar el MSE como
$$</p>
<div class="amsmath math notranslate nohighlight" id="equation-aa9e21bb-9d0e-4c87-be7e-5176afc0d1eb">
<span class="eqno">()<a class="headerlink" href="#equation-aa9e21bb-9d0e-4c87-be7e-5176afc0d1eb" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
\text{MSE} &amp;= \mathbb{E}\left [d_n^2 \right]  - 2\mathbb{E}\left [ d_n y_n \right] + \mathbb{E}\left [ y_n^2 \right] \nonumber \\
&amp;= \mathbb{E}\left [d_n^2 \right] - 2 \textbf{h}^T \mathbb{E}\left [ d_n U_n \right]  + \textbf{h}^T \mathbb{E}\left [U_n U_n^T \right]  \textbf{h}  \nonumber \\
&amp;= \sigma_d^2 - 2 \textbf{h}^T R_{ud} + \textbf{h}^T R_{uu} \textbf{h} \nonumber 
\end{align}\]</div>
<div class="math notranslate nohighlight">
\[Luego el mínimo error que se puede obtener es\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-30932d7b-6397-4bea-98d5-62c41bbe2f00">
<span class="eqno">()<a class="headerlink" href="#equation-30932d7b-6397-4bea-98d5-62c41bbe2f00" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
\text{MSE}_{\text{min}} &amp;= \sigma_d^2 - (R_{uu}^{-1} R_{ud})^T R_{ud} \nonumber \\
&amp;= \sigma_d^2 - R_{ud}^T R_{uu}^{-1} R_{ud} &lt; \sigma_d^2
\end{align}\]</div>
<p>$$</p>
</div>
<div class="section" id="filtro-de-wiener-regresion-identificacion-de-sistema">
<h2>Filtro de wiener: Regresión (identificación de sistema)<a class="headerlink" href="#filtro-de-wiener-regresion-identificacion-de-sistema" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En regresión buscamos encontrar los coeficientes <span class="math notranslate nohighlight">\(h\)</span> a partir de <span class="math notranslate nohighlight">\((X, Y)\)</span> tal que
$<span class="math notranslate nohighlight">\(
Y = h^T X + \epsilon,
\)</span><span class="math notranslate nohighlight">\(
donde \)</span>X \in \mathbb{R}^{N\times D}<span class="math notranslate nohighlight">\( son las variables dependientes (entrada), \)</span>Y \in \mathbb{R}^N<span class="math notranslate nohighlight">\( es la  variable dependiente (salida) y \)</span>\epsilon$ es ruido.</p>
<div class="section" id="entrenamiento-del-predictor">
<h3>Entrenamiento del predictor<a class="headerlink" href="#entrenamiento-del-predictor" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p>Asumimos que hemos observado N muestras de <span class="math notranslate nohighlight">\(X\)</span> e <span class="math notranslate nohighlight">\(Y\)</span></p></li>
<li><p>A partir de <span class="math notranslate nohighlight">\(u=X\)</span> construimos <span class="math notranslate nohighlight">\(R_{uu}\)</span></p></li>
<li><p>A partir de <span class="math notranslate nohighlight">\(d=Y\)</span> construimos <span class="math notranslate nohighlight">\(R_{ud}\)</span></p></li>
<li><p>Finalmente recuperamos <span class="math notranslate nohighlight">\(\textbf{h}\)</span> usando <span class="math notranslate nohighlight">\(R_{uu} ^{-1} R_{ud}\)</span></p></li>
<li><p>Con esto podemos interpolar <span class="math notranslate nohighlight">\(Y\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
    <span class="n">U</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span><span class="o">**</span><span class="n">i</span>
<span class="n">h_real</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.001</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">rseed</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">rseed</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">h_real</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">Ruu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">Rud</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Ruu</span><span class="p">,</span> <span class="n">Rud</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">h_real</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;true&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;observed&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;estimated&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
<span class="n">interact</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">rseed</span><span class="o">=</span><span class="n">IntSlider_nice</span><span class="p">(),</span> <span class="n">order</span><span class="o">=</span><span class="n">SelectionSlider_nice</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]));</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="filtro-de-wiener-prediccion">
<h2>Filtro de wiener: Predicción<a class="headerlink" href="#filtro-de-wiener-prediccion" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En este caso asumimos que la señal deseada es la entrada en el futuro
$<span class="math notranslate nohighlight">\(
d_n = \{u_{n+1}, u_{n+2}, \ldots, u_{n+m}\}
\)</span>$</p>
<ul class="simple">
<li><p>Donde <span class="math notranslate nohighlight">\(m\)</span> es el horizonte de predicción</p></li>
<li><p>Llamamos <em>predicción a un paso</em> al caso <span class="math notranslate nohighlight">\(m=1\)</span></p></li>
<li><p>El largo del filtro <span class="math notranslate nohighlight">\(L\)</span> define la cantidad de muestras pasadas que usamos para predecir</p></li>
<li><p>Por ejemplo un sistema de predicción a un paso con <span class="math notranslate nohighlight">\(L+1 = 3\)</span> coeficientes:
$<span class="math notranslate nohighlight">\(
h_0 u_n +  h_1 u_{n-1} + h_2 u_{n-2}= y_n = \hat u_{n+1} \approx u_{n+1}
\)</span>$</p></li>
</ul>
<div class="section" id="id1">
<h3>Entrenamiento del predictor<a class="headerlink" href="#id1" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p>Asumimos que la señal ha sido observada y que se cuenta con <span class="math notranslate nohighlight">\(N\)</span> muestras</p></li>
<li><p>Podemos formar una matriz cuyas filas son <span class="math notranslate nohighlight">\([u_n, u_{n-1}, \ldots, u_{n-L}]\)</span> para <span class="math notranslate nohighlight">\(n=L,L+1,\ldots, N-1\)</span></p></li>
<li><p>Podemos formar un vector <span class="math notranslate nohighlight">\([u_N, u_{N-1}, \ldots, u_{L+1}]^T\)</span> (caso <span class="math notranslate nohighlight">\(m=1\)</span>)</p></li>
<li><p>Con esto podemos formar las matrices de correlación y obtener <span class="math notranslate nohighlight">\(\textbf{h}\)</span></p></li>
<li><p>Finalmente usamos <span class="math notranslate nohighlight">\(\textbf{h}\)</span> para predecir el futuro no observado de <span class="math notranslate nohighlight">\(u\)</span></p></li>
</ul>
<p>¿Cómo afectan <span class="math notranslate nohighlight">\(L\)</span> y <span class="math notranslate nohighlight">\(N\)</span> en la calidad del predictor lineal?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.lib.stride_tricks</span> <span class="kn">import</span> <span class="n">as_strided</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.25</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="c1">#u += 0.5*t</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">N_train</span><span class="p">):</span>    
    <span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">as_strided</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">-</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span> <span class="p">,</span> <span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="n">u</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="o">.</span><span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="n">Ruu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">[:</span><span class="n">N_train</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">U</span><span class="p">[:</span><span class="n">N_train</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">])</span>
    <span class="n">Rud</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">[:</span><span class="n">N_train</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">U</span><span class="p">[:</span><span class="n">N_train</span><span class="p">,</span> <span class="n">L</span><span class="p">][:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Ruu</span><span class="p">,</span> <span class="n">Rud</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="n">N_train</span><span class="p">],</span> <span class="n">u</span><span class="p">[:</span><span class="n">N_train</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">);</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">N_train</span><span class="p">:],</span> <span class="n">u</span><span class="p">[</span><span class="n">N_train</span><span class="p">:],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">);</span> 
    <span class="n">u_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="p">))</span>
    <span class="n">u_pred</span><span class="p">[:</span><span class="n">N_train</span><span class="p">]</span> <span class="o">=</span> <span class="n">u</span><span class="p">[:</span><span class="n">N_train</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_train</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)):</span>
        <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">N_train</span><span class="p">:],</span> <span class="n">u_pred</span><span class="p">[</span><span class="n">N_train</span><span class="p">:],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>

<span class="n">interact</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="n">SelectionSlider_nice</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> 
         <span class="n">N_train</span><span class="o">=</span><span class="n">SelectionSlider_nice</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">//</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="o">//</span><span class="mi">3</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">));</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="filtro-de-wiener-eliminar-ruido-blanco-aditivo">
<h1>Filtro de Wiener: Eliminar ruido blanco aditivo<a class="headerlink" href="#filtro-de-wiener-eliminar-ruido-blanco-aditivo" title="Enlazar permanentemente con este título">¶</a></h1>
<p>En este caso asumimos que la señal de entrada corresponde a una señal deseada (información) que ha sido contaminada con ruido aditivo</p>
<div class="math notranslate nohighlight">
\[
u_n = d_n + \nu_n,
\]</div>
<p>adicionalmente asumimos que</p>
<ul class="simple">
<li><p>el ruido es estacionario en el sentido amplio y de media cero <span class="math notranslate nohighlight">\(\mathbb{E}[\nu_n] = 0\)</span></p></li>
<li><p>el ruido es blanco, es decir no tiene correlación consigo mismo o con la señal deseada
$<span class="math notranslate nohighlight">\(
r_{\nu d}(k) = 0, \forall k
\)</span>$</p></li>
<li><p>el ruido tiene una cierta varianza <span class="math notranslate nohighlight">\(\mathbb{E}[\nu_n^2] = \sigma_\nu^2, \forall n\)</span></p></li>
</ul>
<p>Notemos que en este caso <span class="math notranslate nohighlight">\(R_{uu} = R_{dd} + R_{\nu\nu}\)</span> y <span class="math notranslate nohighlight">\(R_{ud} = R_{dd}\)</span>, luego</p>
<p>la señal recuperada es <span class="math notranslate nohighlight">\(\hat d_n = h^{*} u_n\)</span> y el filtro es</p>
<div class="math notranslate nohighlight">
\[
\vec h^{*} = \frac{R_{dd}}{R_{dd} + R_{\nu\nu}}
\]</div>
<p>y su respuesta en frecuencia</p>
<div class="math notranslate nohighlight">
\[
H(f) = \frac{S_{dd}(f)}{S_{dd}(f) + S_{\nu\nu}(f)}
\]</div>
<p>es decir que</p>
<ul class="simple">
<li><p>en frecuencias donde la <span class="math notranslate nohighlight">\(S_{dd}(f) &gt; S_{\nu\nu}(f)\)</span>, entonces <span class="math notranslate nohighlight">\(H(f) = 1\)</span></p></li>
<li><p>en frecuencias donde la <span class="math notranslate nohighlight">\(S_{dd}(f) &lt; S_{\nu\nu}(f)\)</span>, entonces <span class="math notranslate nohighlight">\(H(f) = 0\)</span></p></li>
</ul>
</div>
<div class="section" id="sistemas-adaptivos">
<h1>Sistemas adaptivos<a class="headerlink" href="#sistemas-adaptivos" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Hasta ahora hemos estudiando sistemas LTI:</p>
<ul class="simple">
<li><p>sus coeficientes quedan fijos luego del diseño y son constantes en el tiempo</p></li>
<li><p>hacen supuestos sobre los estadísticos de la señal/ruido</p></li>
</ul>
<p>Qué hacer si</p>
<ul class="simple">
<li><p>no podemos hacer supuestos sobre los estadísticos</p></li>
<li><p>los estadísticos de la señal/ruido cambian en el tiempo (no estacionaridad)</p></li>
<li><p>estamos en un escenario donde los datos llegan continuamente (streaming)</p></li>
</ul>
<p>Estimador <strong>adaptivo</strong>:</p>
<ul class="simple">
<li><p>Sistemas cuyos coeficientes se pueden adaptar a medida que llegan nuevos datos</p></li>
<li><p>Se diseñan de acuerdo a un método de optimización <em>online</em></p></li>
</ul>
<p><a class="reference external" href="#index">← Volver al índice</a></p>
<hr class="docutils" />
<p><a id="section2"></a></p>
</div>
<div class="section" id="gradiente-descendente">
<h1>Gradiente descendente<a class="headerlink" href="#gradiente-descendente" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<ul class="simple">
<li><p>Sea un vector de pesos <span class="math notranslate nohighlight">\(w\)</span> de largo <span class="math notranslate nohighlight">\(L+1\)</span> que guarda los coeficientes de un filtro</p></li>
<li><p>Sea ahora una función de costo que mapea el vector de pesos a un número real: <span class="math notranslate nohighlight">\(J(w): \mathbb{R}^{L+1} \to \mathbb{R}\)</span></p>
<ul>
<li><p>A menor <span class="math notranslate nohighlight">\(J\)</span> mejor es nuestro filtro (menor error)</p></li>
</ul>
</li>
</ul>
<p>Para entrenar un filtro adaptivo</p>
<ol class="simple">
<li><p>Partimos de una solución inicial <span class="math notranslate nohighlight">\(w_0\)</span></p></li>
<li><p>Modificamos iterativamente <span class="math notranslate nohighlight">\(w\)</span> tal que <span class="math notranslate nohighlight">\(J(w_{t+1}) &lt; J(w_t)\)</span></p></li>
<li><p>Nos detenemos al cumplir un cierto criterio</p></li>
</ol>
<hr class="docutils" />
<p>Una alternativa de bajo costo para lograr esto es la regla del <strong>gradiente descendente</strong> (GD)</p>
<div class="math notranslate nohighlight">
\[
w_{t+1} = w_t - \mu \frac{dJ(w)}{dw},
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\mu\)</span> se conoce como tasa de aprendizaje o «paso»</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="s1">&#39;all&#39;</span><span class="p">);</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">-</span> <span class="mf">4.</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">L</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">L</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">get_offsets</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="n">mu</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">mu</span><span class="o">*</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">p</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">set_offsets</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">p</span><span class="p">,</span> <span class="n">L</span><span class="p">(</span><span class="n">p</span><span class="p">)])</span>
    
<span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#plt.close(); HTML(anim.to_html5_video())</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p>Imaginemos <span class="math notranslate nohighlight">\(J\)</span> como una superficie de <span class="math notranslate nohighlight">\(L+1\)</span> dimensiones</p></li>
<li><p>En cada punto el gradiente negativo de <span class="math notranslate nohighlight">\(J\)</span> nos indica hacia donde está el descenso más abrupto</p></li>
<li><p>La tasa <span class="math notranslate nohighlight">\(\mu\)</span> nos da el largo del salto entre <span class="math notranslate nohighlight">\(w_t\)</span> y <span class="math notranslate nohighlight">\(w_{t+1}\)</span></p></li>
</ul>
<p>Notemos de la <strong>expansión de Taylor de primer orden</strong> de <span class="math notranslate nohighlight">\(J\)</span> en <span class="math notranslate nohighlight">\(w_{t}\)</span> que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
J(w_{t+1}) &amp;= J(w_t) + \frac{dJ(w_t)}{dw} (w_{t+1} - w_{t})  \nonumber \\
&amp;= J(w_t) -\mu \left \| \frac{dJ(w_t)}{dw} \right \|^2 \leq J(w_t) \nonumber 
\end{align}
\end{split}\]</div>
<p>es decir que dado usando la regla GD con <span class="math notranslate nohighlight">\(\mu&gt;0\)</span> se cumple que <span class="math notranslate nohighlight">\(J\)</span> decrece monotonicamente</p>
<ul class="simple">
<li><p>Relación con método de Newton!</p></li>
</ul>
<div class="section" id="gradiente-descendente-en-el-filtro-de-wiener">
<h2>Gradiente descendente en el filtro de Wiener<a class="headerlink" href="#gradiente-descendente-en-el-filtro-de-wiener" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Para el filtro de Wiener teniamos
$<span class="math notranslate nohighlight">\(
J(h) = \sigma_d^2 - 2 \textbf{h}^T R_{ud} + \textbf{h}^T R_{uu} \textbf{h},
\)</span><span class="math notranslate nohighlight">\(
por ende
\)</span><span class="math notranslate nohighlight">\(
\frac{dJ(h)}{dh} = -2 R_{ud} + 2 R_{uu} \textbf{h}
\)</span><span class="math notranslate nohighlight">\(
y finalmente
\)</span><span class="math notranslate nohighlight">\(
\textbf{h}_{t+1} = \textbf{h}_{t} (I - 2 \mu R_{uu}) + 2\mu R_{ud}
\)</span><span class="math notranslate nohighlight">\(
En este caso la condición de convergencia estable es 
\)</span><span class="math notranslate nohighlight">\(
0 &lt; \mu &lt; \frac{1}{\lambda_{\text{max}}},
\)</span><span class="math notranslate nohighlight">\(
donde \)</span>\lambda_{\text{max}}<span class="math notranslate nohighlight">\( es valor propio más grande de \)</span>R_{uu}$</p>
<p>Esto último viene de formar una ecuación de diferencia del estilo <span class="math notranslate nohighlight">\(\hat w_{k, t+1} = (1-\mu \lambda_k)^t \hat w_{k, t=0}\)</span></p>
<p>Ref: Haykin, «Adaptive filter theory», 4.3</p>
</div>
</div>
<div class="section" id="gradiente-descendente-estocastico-sgd">
<h1>Gradiente descendente estocástico (SGD)<a class="headerlink" href="#gradiente-descendente-estocastico-sgd" title="Enlazar permanentemente con este título">¶</a></h1>
<p>El filtro de Wiener es óptimo pero no adaptivo</p>
<ul class="simple">
<li><p>Requiere de <span class="math notranslate nohighlight">\(N\)</span> muestras de <span class="math notranslate nohighlight">\(u\)</span> y <span class="math notranslate nohighlight">\(d\)</span> para estimar <span class="math notranslate nohighlight">\(R_{ud}\)</span> y <span class="math notranslate nohighlight">\(R_{uu}\)</span></p></li>
<li><p>Asume estacionaridad: <span class="math notranslate nohighlight">\(J(h) = \mathbb{E}\left[e_n^2\right]\)</span></p></li>
<li><p>El gradiente descendente (GD) es un método deterministico</p></li>
<li><p>Los pesos se adaptan luego de haber presentado las <span class="math notranslate nohighlight">\(N\)</span> muestras (batch)</p></li>
</ul>
<p>Consideremos el caso en que los datos no son estacionarios</p>
<ul class="simple">
<li><p>Significa que debemos adaptar el filtro en cada paso a medida que nuevas muestras son observadas</p></li>
<li><p>Para esto usamos la versión estocástica del GD: SGD</p></li>
<li><p>Los pesos se adaptan luego de haber presentado una muestra o un conjunto pequeño (mini-batch)</p></li>
<li><p>No hay garantía de llegar al óptimo en un problema convexo, pero es más eficiente computacionalmente que GD</p></li>
</ul>
<a class="reference internal image-reference" href="clases/unidad3/img/adaptive-sgd.png"><img alt="clases/unidad3/img/adaptive-sgd.png" src="clases/unidad3/img/adaptive-sgd.png" style="width: 600px;" /></a>
<p><a class="reference external" href="#index">← Volver al índice</a></p>
<hr class="docutils" />
<p><a id="section3"></a></p>
</div>
<div class="section" id="algoritmo-least-mean-square-lms">
<h1>Algoritmo Least Mean Square (LMS)<a class="headerlink" href="#algoritmo-least-mean-square-lms" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<p>Podemos extender el filtro de Wiener al caso no-estacionario usando SGD</p>
<ul class="simple">
<li><p>El resultado es un algoritmo es simple (filtro FIR) que además es robusto</p></li>
<li><p>A diferencia del filtro de Wiener no se requiere conocimiento estadístico del proceso</p></li>
<li><p>Tampoco se requiere calcular e invertir la matriz de correlación</p></li>
<li><p>Se entrena de manera recursiva y online</p></li>
</ul>
<p>Consideremos la función de costo estocástica para la arquitectura FIR</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
J^s_n(\textbf{w}) &amp;= e_n^2 \nonumber \\
&amp;= (d_n - y_n)^2 \nonumber \\
&amp;= (d_n - \textbf{w}^T \textbf{u}_n )^2 \nonumber \\
&amp;= (d_n - \sum_{k=0}^{L} w_{n, k} u_{n-k} )^2 \nonumber 
\end{align}
\end{split}\]</div>
<p>donde definimos <span class="math notranslate nohighlight">\(\textbf{u}_n = [u_n, u_{n-1}, \ldots, u_{n-L}]\)</span></p>
<p>Notemos que usamos el error cuadrático instantaneo en lugar del MSE (filtro de Wiener)</p>
<p>El gradiente en función del peso <span class="math notranslate nohighlight">\(w_{n, k}\)</span> es
$<span class="math notranslate nohighlight">\(
\frac{d J^s_n (\textbf{w})}{d w_{n, k}} = - 2 e_n u_{n-k}
\)</span><span class="math notranslate nohighlight">\(
Usando la regla SGD llegamos a 
\)</span><span class="math notranslate nohighlight">\(
w_{n+1, k} = w_{n, k} + 2 \mu e_n u_{n-k}, k=0, 1, \ldots, L
\)</span><span class="math notranslate nohighlight">\(
o en forma matricial
\)</span>$</p>
<div class="amsmath math notranslate nohighlight" id="equation-ecb652d1-89cc-43f6-84f8-1209e206cbae">
<span class="eqno">()<a class="headerlink" href="#equation-ecb652d1-89cc-43f6-84f8-1209e206cbae" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
\textbf{w}_{n+1} &amp;= \textbf{w}_{n} + 2 \mu e_n \textbf{u}_{n}\nonumber \\
&amp;= \textbf{w}_{n} + 2 \mu (d_n -  \textbf{w}_{n}^T \textbf{u}_{n}) \textbf{u}_{n}, \nonumber 
\end{align}\]</div>
<p>$$</p>
<ul class="simple">
<li><p>Estimamos la matriz de correlación instantanea y actualizamos los pesos recursivamente</p></li>
<li><p>La complejidad de este algoritmo es <span class="math notranslate nohighlight">\(L+1\)</span>, es decir la complejidad del filtro</p></li>
<li><p>Esto se conoce como algoritmo LMS o regla Widrow-Hoff</p></li>
<li><p>Inventado en 1960 por <a class="reference external" href="https://en.wikipedia.org/wiki/Bernard_Widrow">Bernard Widrow</a> y Ted Hoff</p></li>
</ul>
</div>
<div class="section" id="interpretacion-geometrica-del-algoritmo-lms">
<h1>Interpretación geométrica del algoritmo LMS<a class="headerlink" href="#interpretacion-geometrica-del-algoritmo-lms" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Tenemos la siguiente regla iterativa
$<span class="math notranslate nohighlight">\(
\textbf{w}_{n+1} = \textbf{w}_{n} + 2 \mu e_n \textbf{u}_{n} = \textbf{w}_{n} + \Delta \textbf{w}_n
\)</span>$
que se puede interpretar graficamente como
<a href="https://www.commsp.ee.ic.ac.uk/~mandic/SE_ASP_LN/ASP_MI_Lecture_5_Adaptive_Filters_2017.pdf"><img src="img/adaptive-lms-geometry.png" width="400px"></a></p>
<p>Notemos que</p>
<ul class="simple">
<li><p>Los cambios en el vector de peso <span class="math notranslate nohighlight">\(\Delta \textbf{w}_n\)</span> son paralelos a <span class="math notranslate nohighlight">\(\textbf{u}_{n}\)</span></p></li>
<li><p>Estos cambios podrían estar dominados por <span class="math notranslate nohighlight">\(\max_k \textbf{u}_{n} = [u_n, u_{n-1}, \ldots, u_{n-L}]\)</span></p></li>
<li><p>El algoritmo Normalized LMS (NLMS) corrige esto ponderando por la varianza de <span class="math notranslate nohighlight">\(\textbf{u}_{n}\)</span>
$<span class="math notranslate nohighlight">\(
\textbf{w}_{n+1} = \textbf{w}_{n} + 2 \mu e_n \frac{\textbf{u}_{n}}{\left(\|\textbf{u}_{n}\|^2 + \delta\right)}
\)</span><span class="math notranslate nohighlight">\(
donde la constante \)</span>\delta$ es un valor pequeño que se usa para evitar divisiones por cero</p></li>
</ul>
<div class="section" id="lms-adaptive-line-enhancement-ale">
<h2>LMS: Adaptive line enhancement (ALE)<a class="headerlink" href="#lms-adaptive-line-enhancement-ale" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Sistema adaptivo para eliminar ruido aditivo de un canal</p></li>
<li><p>El sistema aprende un filtro pasabanda en torno a la frecuencia de interés</p></li>
<li><p>Notece como es posible filtrar incluso ante cambios bruscos en la señal</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.lib.stride_tricks</span> <span class="kn">import</span> <span class="n">as_strided</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">t</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">t</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span>
<span class="c1">#u[250:] += 5  # Cambio abrupto en la media</span>
<span class="c1">#u += 2*t  #  Tendencia lineal</span>
<span class="c1">#u += u*(0.5 + 0.5*np.cos(2.0*np.pi*t/2))  # Tremolo (AM)</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">rseed</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">rseed</span><span class="p">)</span>
    <span class="n">u_noise</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> 
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span> <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span> 
    <span class="c1">#LMS</span>
    <span class="n">u_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u_noise</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span>
        <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u_noise</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>
        <span class="n">w</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">mu</span><span class="o">*</span><span class="p">(</span><span class="n">u_noise</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">*</span><span class="n">u_noise</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span><span class="o">/</span><span class="n">norm</span>
    <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u_noise</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u_noise</span><span class="p">,</span> <span class="s1">&#39;k.&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span> 
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span>  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u_pred</span><span class="p">);</span> 
    
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;LMS&#39;</span><span class="p">)</span>
    <span class="n">k</span><span class="p">,</span> <span class="n">Hk</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">freqz</span><span class="p">(</span><span class="n">b</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">dt</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Hk</span><span class="p">))</span>
    
<span class="n">interact</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">SelectionSlider_nice</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span>
         <span class="n">L</span><span class="o">=</span><span class="n">SelectionSlider_nice</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">rseed</span><span class="o">=</span><span class="n">IntSlider_nice</span><span class="p">());</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El algoritmo LMS es un sistema de control con retroalimentación</p></li>
<li><p>En el ejemplo anterior notamos la desestabilidad que ocurre con ciertos valores de <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>La convergencia del algoritmo depende de <span class="math notranslate nohighlight">\(\mu\)</span></p>
<ul>
<li><p>Muy pequeño: Convergencia lenta</p></li>
<li><p>Muy grande: Desestabilidad</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="comparacion-entre-filtro-de-wiener-gd-y-algoritmo-lms-sgd">
<h2>Comparación entre Filtro de Wiener/GD y algoritmo LMS/SGD<a class="headerlink" href="#comparacion-entre-filtro-de-wiener-gd-y-algoritmo-lms-sgd" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Wiener: Ambiente estacionario lo cual nos permite calcular <span class="math notranslate nohighlight">\(R_{uu}\)</span> y <span class="math notranslate nohighlight">\(R_{ud}\)</span>. El aprendizaje es determinista.</p></li>
<li><p>LMS: El aprendizaje viene promediando a nivel de los estimadores de <span class="math notranslate nohighlight">\(w\)</span>. Esta sujeto al ruido de los estimadores de gradiente. El aprendizaje es estadístico.</p></li>
<li><p>Wiener es óptimo en cambio LMS es sub-óptimo (localmente óptimo). LMS tiende a la solución de Wiener</p></li>
<li><p>LMS se actualiza online y tiene costo <span class="math notranslate nohighlight">\(L\)</span>. Wiener se entrena offline y tiene costo <span class="math notranslate nohighlight">\(L^2\)</span></p></li>
</ul>
<img alt="clases/unidad3/img/adaptive-lms.png" src="clases/unidad3/img/adaptive-lms.png" />
<p>Convergencia del algoritmo LMS (Haykin 6.5)</p>
<ul class="simple">
<li><p>El algoritmo LMS tiende en la media <span class="math notranslate nohighlight">\(\mathbb{E}[\textbf{w}_n] \to \textbf{w}^*\)</span> para <span class="math notranslate nohighlight">\(n\to \infty\)</span></p></li>
<li><p>Convergencia en la media cuadrada: La varianza de <span class="math notranslate nohighlight">\(\textbf{w}_n - \textbf{w}^*\)</span> tiene al valor mínimo de <span class="math notranslate nohighlight">\(J\)</span> para <span class="math notranslate nohighlight">\(n\to \infty\)</span></p></li>
<li><p>Esto se cumple si
$<span class="math notranslate nohighlight">\(
0 &lt; \mu &lt; \frac{1}{\lambda_{\text{max}}}
\)</span><span class="math notranslate nohighlight">\(
donde \)</span>\lambda_{\text{max}}<span class="math notranslate nohighlight">\( es el valor propio más grande de \)</span>R_{uu}$</p></li>
</ul>
</div>
<div class="section" id="lms-cancelacion-de-eco">
<h2>LMS: Cancelación de eco<a class="headerlink" href="#lms-cancelacion-de-eco" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Supongamos que enviamos una señal de voz a un amig&#64;</p></li>
<li><p>Nuestro amig&#64; escucha lo que enviamos en un parlante y responde</p></li>
<li><p>Nosotros escuchamos la respuesta de nuestro amig&#64; y adicionalmente nuestro mensaje original</p></li>
</ul>
<a class="reference internal image-reference" href="clases/unidad3/img/adaptive-echo-canceller.png"><img alt="clases/unidad3/img/adaptive-echo-canceller.png" src="clases/unidad3/img/adaptive-echo-canceller.png" style="width: 500px;" /></a>
<ul class="simple">
<li><p>Podemos usar un filtro adaptivo para cancelar el eco</p></li>
<li><p>Usamos como entrada la señal enviada y como salida deseada la señal recibida (con eco)</p></li>
<li><p>El filtro aprende el sistema reverberante</p></li>
<li><p>El error es la nueva señal recibida limpia</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># la señal enviada original</span>
<span class="n">r</span><span class="p">,</span> <span class="n">fs</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;data/hola1.ogg&quot;</span><span class="p">)</span>
<span class="n">Audio</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># El sistema que introduce ecos, por ejemplo una sala</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> 
                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">]))</span>
<span class="c1"># la señal enviada con eco</span>
<span class="n">rh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">h</span><span class="p">)[:</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">)]</span>
<span class="c1"># la señal recibida limpia </span>
<span class="n">s</span><span class="p">,</span> <span class="n">fs</span> <span class="o">=</span> <span class="n">sf</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;data/hola2.ogg&quot;</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)))))</span>
<span class="c1"># la señal recibida + señal enviada con eco + ruido blanco</span>
<span class="n">srh</span> <span class="o">=</span> <span class="n">s</span> <span class="o">+</span> <span class="mf">0.3</span><span class="o">*</span><span class="n">rh</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span><span class="o">*</span><span class="mf">0.005</span>
<span class="n">Audio</span><span class="p">(</span><span class="n">srh</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">L</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.02</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>
<span class="n">rhhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">srh</span><span class="p">),</span> <span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">srh</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-10</span>
    <span class="n">rhhat</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">mu</span><span class="o">*</span><span class="p">(</span><span class="n">srh</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">rhhat</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">*</span><span class="n">r</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">norm</span><span class="p">)</span>
<span class="n">rhhat</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>
<span class="n">shat</span> <span class="o">=</span> <span class="n">srh</span> <span class="o">-</span> <span class="n">rhhat</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">srh</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;hola2+hola1&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">shat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;hola2 puro&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">s</span> <span class="o">-</span> <span class="n">shat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">Audio</span><span class="p">(</span><span class="n">shat</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="#index">← Volver al índice</a></p>
<p><a id="section4"></a></p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="algoritmo-recursive-least-squares-rls">
<h1>Algoritmo Recursive Least Squares (RLS)<a class="headerlink" href="#algoritmo-recursive-least-squares-rls" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<p>El algoritmo LMS</p>
<ul class="simple">
<li><p>minimiza el error instantaneo</p></li>
<li><p>es simple y eficiente</p></li>
<li><p>en algunos casos su convergencia es demasiado lenta</p></li>
</ul>
<p>Podemos obtener un filtro adaptivo que converge más rápido si reemplazamos el error instantaneo por el error histórico</p>
<p>Sigamos considerando un filtro tipo FIR con <span class="math notranslate nohighlight">\(L+1\)</span> pesos que se actualizan de en cada época</p>
<div class="math notranslate nohighlight">
\[
y_i = \sum_{k=0}^L w_{i, k} u_{n-k}
\]</div>
<p>El algoritmo RLS (recursive least squares) es un método online que minimiza el error histórico, es decir la suma de errores entre la muestra actual y la inicial</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
J^H_n(\textbf{w}) &amp;= \sum_{i=L}^n   \beta^{n-i} |e_i|^2 \nonumber \\
&amp;= \sum_{i=L+1}^n \beta^{n-i} (d_i - \sum_{k=0}^{L} w_{i, k} u_{i-k} )^2, \nonumber
\end{align}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(n\)</span> es el índice del instante actual y <span class="math notranslate nohighlight">\(\beta \in [0, 1]\)</span> es el «factor de olvido» y que usualmente es un valor cercano a <span class="math notranslate nohighlight">\(1\)</span></p>
<p>Adicionalmente se agrega un regularizador a los pesos
$<span class="math notranslate nohighlight">\(
J^w_n = \delta  \| \textbf{w}_{n} \|^2
\)</span>$</p>
<p>La solución cerrada sería</p>
<div class="math notranslate nohighlight">
\[
\textbf{w}_n = (U_n^T \pmb{\beta} U_n + \delta I)^{-1}  U_n^T \pmb{\beta} \textbf{d}_n
\]</div>
<p>donde
$<span class="math notranslate nohighlight">\(
\textbf{d}_n = \begin{pmatrix}  d_n \\ d_{n-1} \\ \vdots \\ d_{L+1} \end{pmatrix} \quad
\textbf{u}_n = \begin{pmatrix}  u_n \\ u_{n-1} \\ \vdots \\ u_{n-(L+1)} \end{pmatrix} \quad
\pmb{\beta} = I \begin{pmatrix} \beta \\ \beta^{1} \\ \beta^{2}  \vdots \\ \beta^{n-L-1} \end{pmatrix}
\quad 
U_n = \begin{pmatrix}
\textbf{u}_n^T \\ \textbf{u}_{n-1}^T \\ \vdots \\ \textbf{u}_{L+1}^T \\
\end{pmatrix} \in \mathbb{R}^{n - (L+1) \times L+1}
\)</span>$</p>
<p>e <span class="math notranslate nohighlight">\(I\)</span> es la matriz identidad.</p>
<ul class="simple">
<li><p>Notemos la similitud con el filtro de Wiener</p>
<ul>
<li><p>Matriz de correlación ponderada y regularizada: <span class="math notranslate nohighlight">\(\Phi_n = U_n^T \pmb{\beta} U_n + \delta I\)</span></p></li>
<li><p>Vector de correalación cruzada ponderada:  <span class="math notranslate nohighlight">\(\theta_n = U_n^T \pmb{\beta} \textbf{d}_n\)</span></p></li>
</ul>
</li>
<li><p>Queremos recomputar esta solución cuando llegan nuevas observaciones</p></li>
<li><p>En particular queremos evitar invertir <span class="math notranslate nohighlight">\(\Phi_n\)</span></p></li>
</ul>
<p>El algoritmo <strong>RLS</strong> propone una solución que actualiza los pesos de forma recursiva</p>
<p>Las condiciones iniciales son</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Phi_0 = \delta I\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta_0 = 0\)</span></p></li>
</ul>
<p>y luego la actualización viene dada por</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Phi_{n} = \beta \Phi_{n-1} + \textbf{u}_n \textbf{u}_n^T\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta_{n} = \beta \theta_{n-1} + \textbf{u}_n d_n \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\textbf{w}_n = \Phi_n^{-1} \theta_n\)</span></p></li>
</ul>
<p>Que es más eficiente si actualizamos <span class="math notranslate nohighlight">\(\Phi_{n}^{-1}\)</span> en lugar de <span class="math notranslate nohighlight">\(\Phi_{n}\)</span></p>
<p>Usando el lema de inversión de matrices
$<span class="math notranslate nohighlight">\(
(A + UCV)^{-1} = A^{-1} - A^{-1} U (C^{-1} + VA^{-1} U)^{-1} V A^{-1}
\)</span>$</p>
<p>con <span class="math notranslate nohighlight">\(A = \Phi_{n-1}^{-1}\)</span>, <span class="math notranslate nohighlight">\(C=1\)</span>, <span class="math notranslate nohighlight">\(U= \textbf{u}_n\)</span> y <span class="math notranslate nohighlight">\(V = \textbf{u}_n^T\)</span> entonces</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\Phi_{n}^{-1} &amp;= \left(\beta \Phi_{n-1} + \textbf{u}_n \textbf{u}_n^T \right)^{-1} \nonumber \\
&amp;= \beta^{-1} \Phi_{n-1}^{-1} - \beta^{-2} \frac{\Phi_{n-1}^{-1} \textbf{u}_n \textbf{u}_n^T \Phi_{n-1}^{-1} }{1 + \beta^{-1} \textbf{u}_n^T \Phi_{n-1}^{-1} \textbf{u}_n} \nonumber \\
&amp;= \beta^{-1} \Phi_{n-1}^{-1} - \beta^{-1} \textbf{k}_n \textbf{u}_n^T \Phi_{n-1}^{-1}, \nonumber 
\end{align}
\end{split}\]</div>
<p>donde llamamos <strong>ganancia</strong> a <span class="math notranslate nohighlight">\(\textbf{k}_n\)</span></p>
<p>Podemos continuar para encontrar una regla de actualización recursiva para los pesos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\textbf{w}_n &amp;= \Phi_n^{-1} \theta_n \nonumber \\
&amp;=  \Phi_n^{-1} \beta \theta_{n-1} + \Phi_n^{-1} \textbf{u}_n d_n\nonumber \\
&amp;=  \Phi_{n-1}^{-1} \theta_{n-1} - \textbf{k}_n \textbf{u}_n^T \Phi_{n-1}^{-1} \theta_{n-1} + \Phi_n^{-1} \textbf{u}_n d_n \nonumber \\
&amp;=  \textbf{w}_{n-1} - \textbf{k}_n \textbf{u}_n^T  \textbf{w}_{n-1} + \Phi_n^{-1} \textbf{u}_n d_n \nonumber \\
&amp;=  \textbf{w}_{n-1} + \textbf{k}_n ( d_n - \textbf{u}_n^T  \textbf{w}_{n-1} ) \nonumber \\
&amp;=  \textbf{w}_{n-1} + \textbf{k}_n e_n \nonumber 
\end{align}
\end{split}\]</div>
<p>donde reemplazamos <span class="math notranslate nohighlight">\(\textbf{w}_{n-1} = \Phi_{n-1}^{-1} \theta_{n-1}\)</span> y usamos que
$$</p>
<div class="amsmath math notranslate nohighlight" id="equation-ae91c168-8857-4954-a5a6-181bafe45129">
<span class="eqno">()<a class="headerlink" href="#equation-ae91c168-8857-4954-a5a6-181bafe45129" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
\textbf{k}_n &amp;= \left(\beta^{-1} \Phi_{n-1}^{-1} - \beta^{-1} \textbf{k}_n \textbf{u}_n^T \Phi_{n-1}^{-1} \right)  \textbf{u}_n \nonumber \\ &amp;= \Phi_n^{-1} u_n \nonumber
\end{align}\]</div>
<p>$$</p>
<div class="section" id="notas">
<h2>Notas<a class="headerlink" href="#notas" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Con esto tenemos un algoritmo de complejidad <span class="math notranslate nohighlight">\(L^2\)</span> en vez de <span class="math notranslate nohighlight">\(L^3\)</span></p></li>
<li><p>Esto sigue siendo mayor que LMS (complejidad <span class="math notranslate nohighlight">\(L\)</span>) pero con la ventaja de converger más rapidamente</p></li>
<li><p>En la literatura suele usarse el nombre <span class="math notranslate nohighlight">\(P_n\)</span> para <span class="math notranslate nohighlight">\(\Phi_n^{-1}\)</span></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="resumen-algoritmo-rls">
<h2>Resumen algoritmo RLS<a class="headerlink" href="#resumen-algoritmo-rls" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>Inicializar <span class="math notranslate nohighlight">\(\Phi_0 = \delta I\)</span> y <span class="math notranslate nohighlight">\(\textbf{w}_0 = 0\)</span></p></li>
<li><p>Para <span class="math notranslate nohighlight">\(n \in [1, \infty]\)</span></p>
<ol class="simple">
<li><p>Calcular la ganancia
$<span class="math notranslate nohighlight">\(
\textbf{k}_n =  \frac{\beta^{-1} \Phi_{n-1}^{-1} \textbf{u}_n }{1 + \beta^{-1} \textbf{u}_n^T \Phi_{n-1}^{-1} \textbf{u}_n}
\)</span>$</p></li>
<li><p>Calcular el error
$<span class="math notranslate nohighlight">\(
e_n = d_n - \textbf{u}_n^T  \textbf{w}_{n-1} 
\)</span>$</p></li>
<li><p>Actualizar el error de pesos
$<span class="math notranslate nohighlight">\(
\textbf{w}_n = \textbf{w}_{n-1} + \textbf{k}_n e_n 
\)</span>$</p></li>
<li><p>Actualizar el inverso de la matriz de correlación
$<span class="math notranslate nohighlight">\(
\Phi_{n}^{-1} = \beta^{-1} \Phi_{n-1}^{-1} - \beta^{-1} \textbf{k}_n \textbf{u}_n^T \Phi_{n-1}^{-1}
\)</span>$</p></li>
</ol>
</li>
</ul>
<div class="section" id="recomendaciones">
<h3>Recomendaciones<a class="headerlink" href="#recomendaciones" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p>A menor <span class="math notranslate nohighlight">\(\delta\)</span> mayor regularización. Usar <span class="math notranslate nohighlight">\(\delta\)</span> pequeño para SNR bajo y <span class="math notranslate nohighlight">\(\delta\)</span> grande para SNR alto</p></li>
<li><p>Considerar un valor de <span class="math notranslate nohighlight">\(\beta \approx 0.9\)</span> inicialmente</p></li>
<li><p>Calibre <span class="math notranslate nohighlight">\(\delta\)</span> y <span class="math notranslate nohighlight">\(\beta\)</span> usando validación cruzada</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="rls-versus-lms-tracking">
<h3>RLS versus LMS: Tracking<a class="headerlink" href="#rls-versus-lms-tracking" title="Enlazar permanentemente con este título">¶</a></h3>
<ul class="simple">
<li><p>Notemos la diferencia en tiempo de convergencia entre los algoritmos LMS y RLS</p></li>
<li><p>RLS es capaz de adaptarse a cambios bruscos más rápido que LMS</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">t</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">retstep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">t</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span>  
<span class="c1"># u[250:] += 5</span>
<span class="n">u</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">tt</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mf">0.2</span><span class="p">)</span> <span class="k">if</span> <span class="n">tt</span><span class="o">&gt;</span><span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="n">t</span><span class="p">])</span>
<span class="n">u</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">tt</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mf">0.2</span><span class="p">)</span> <span class="k">if</span> <span class="n">tt</span><span class="o">&gt;</span><span class="mi">3</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">tt</span> <span class="ow">in</span> <span class="n">t</span><span class="p">])</span>
<span class="n">u_noisy</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">();</span> 
    <span class="n">u_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">u_noisy</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="c1">#LMS</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">u_noisy</span><span class="p">)):</span>
        <span class="n">u_window</span> <span class="o">=</span> <span class="n">u_noisy</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u_window</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span>
        <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u_window</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
            <span class="n">w</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">mu</span><span class="o">*</span><span class="p">(</span><span class="n">u_noisy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="n">u_window</span><span class="o">/</span><span class="n">norm</span>
    <span class="c1">#RLS</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="mf">1.</span>
    <span class="n">Phi_inv</span> <span class="o">=</span> <span class="n">delta</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span> 
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">u_noisy</span><span class="p">)):</span>
        <span class="n">u_window</span> <span class="o">=</span> <span class="n">u_noisy</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">k</span><span class="p">]</span>
        <span class="c1"># Calcular ganancia</span>
        <span class="n">gain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Phi_inv</span><span class="p">,</span> <span class="n">u_window</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">beta</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u_window</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Phi_inv</span><span class="p">),</span> <span class="n">u_window</span><span class="p">))</span>        
        <span class="c1"># Calcular error</span>
        <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">u_window</span><span class="p">)</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">u_noisy</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">u_pred</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Actualizar pesos</span>
        <span class="n">w</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gain</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
        <span class="c1"># Actualizar el inverso de la matriz de correlación</span>
        <span class="n">Phi_inv</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">gain</span><span class="o">*</span><span class="n">u_window</span><span class="p">))</span><span class="o">*</span><span class="n">Phi_inv</span>
    
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u_noisy</span><span class="p">,</span> <span class="s1">&#39;k.&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">);</span> 
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real&#39;</span><span class="p">);</span>  
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;LMS&#39;</span><span class="p">);</span> 
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">u_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;RLS&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;LMS&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">u</span> <span class="o">-</span> <span class="n">u_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;RLS&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    
<span class="n">interact</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> 
         <span class="n">mu</span><span class="o">=</span><span class="n">FloatSlider_nice</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span>
         <span class="n">beta</span><span class="o">=</span><span class="n">FloatSlider_nice</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.9</span><span class="p">),</span>
         <span class="n">L</span><span class="o">=</span><span class="n">SelectionSlider_nice</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="mi">10</span><span class="p">));</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="#index">← Volver al índice</a></p>
<p><a id="section5"></a></p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="algoritmo-perceptron-rosemblatt-1962">
<h1>Algoritmo Perceptrón (Rosemblatt 1962)<a class="headerlink" href="#algoritmo-perceptron-rosemblatt-1962" title="Enlazar permanentemente con este título">¶</a></h1>
<hr class="docutils" />
<ul class="simple">
<li><p>Podemos entrenar un filtro adaptivo para hacer <strong>clasificación binaria de patrones</strong></p></li>
<li><p>En este caso la respuesta deseada tiene dos categorías: <span class="math notranslate nohighlight">\(d_n \in \{-1, +1\}\)</span></p></li>
<li><p>La entrada se considera continua y de <span class="math notranslate nohighlight">\(M\)</span> dimensiones: <span class="math notranslate nohighlight">\(u_n \in \mathbb{R}^M\)</span></p></li>
<li><p>Asumimos que se tienen <span class="math notranslate nohighlight">\(N\)</span> tuplas <span class="math notranslate nohighlight">\((u_n, d_n)\)</span></p></li>
<li><p>El filtro tiene arquitectura FIR con <span class="math notranslate nohighlight">\(M+1\)</span> coeficientes pero se agrega una no linealidad <span class="math notranslate nohighlight">\(\phi(\cdot)\)</span> en la salida
$$</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-a976d2d8-5720-43d3-bbfc-d99894c8ba64">
<span class="eqno">()<a class="headerlink" href="#equation-a976d2d8-5720-43d3-bbfc-d99894c8ba64" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
y_n &amp;=  \phi \left(w_0 + \sum_{k=1}^{M} w_k u_{nk} \right) \nonumber \\
&amp;= \phi \left(\langle \textbf{w}, \text{concat}(1, u_n) \rangle \right), \nonumber 
\end{align}\]</div>
<p>$<span class="math notranslate nohighlight">\(
donde podemos usar \)</span>\phi(z) = \text{sign}(z) = \begin{cases} +1 &amp; z &gt; 0 \0 &amp; z=0-1 &amp; z&lt;0 \end{cases}$</p>
<ul class="simple">
<li><p>Esto se conoce como el modelo matemático de una neurona de <a class="reference external" href="https://link.springer.com/article/10.1007/BF02478259">McCulloch y Pitts</a></p>
<ul>
<li><p>Las coeficientes del filtro son los pesos sinápticos de las dendritas</p></li>
<li><p>La función no lineal corresponde al axón</p></li>
</ul>
</li>
</ul>
<p><img src="img/adaptive-neuron.png" width="400"><img src="img/adaptive-neuron2.jpeg" width="400"></p>
<ul class="simple">
<li><p>El algoritmo para entrenar la neurona artificial se conoce como <strong>algoritmo percetrón</strong></p></li>
<li><p>Asumimos un vector de pesos inicial nulo <span class="math notranslate nohighlight">\(\textbf{w}^{(t=0)} = [0, 0, ..., 0]\)</span></p></li>
<li><p>La función de costo en el instante <span class="math notranslate nohighlight">\(t\)</span> al presentar el ejemplo <span class="math notranslate nohighlight">\((d_n, u_n)\)</span>
$<span class="math notranslate nohighlight">\(
\mathcal{L}( \textbf{w}^{(t)} ) = \text{max} \Big(0 ~, - d_n \langle \textbf{w}^{(t)}, \text{concat}(1, u_n) \rangle \Big)
\)</span>$</p></li>
<li><p>y su derivada es
$<span class="math notranslate nohighlight">\(
\frac{d \mathcal{L}(\textbf{w}^{(t)} )}{d \textbf{w}}  = \begin{cases} 0 &amp; d_n \langle \textbf{w}, \text{concat}(1, u_n) \rangle \geq 0 \\ - d_n \text{concat}(1, u_n)  &amp; d_n \langle \textbf{w}, \text{concat}(1, u_n) \rangle &lt; 0
\end{cases}
\)</span>$
es decir que la derivada es cero si el ejemplo está bien clasificado</p></li>
<li><p>Finalmente la regla perceptron usando SGD con tasa de aprendizaje <span class="math notranslate nohighlight">\(\mu\)</span> es
$$</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-b6bdefc0-45c8-4d6c-a2c9-56436d58e548">
<span class="eqno">()<a class="headerlink" href="#equation-b6bdefc0-45c8-4d6c-a2c9-56436d58e548" title="Enlace permanente a esta ecuación">¶</a></span>\[\begin{align}
\textbf{w}^{(t+1)} &amp;= \textbf{w}^{(t)} - \mu \frac{d \mathcal{L}(\textbf{w}^{(t)} )}{d \textbf{w}} \nonumber \\
&amp; = \textbf{w}^{(t)} + \begin{cases} \mu d_n \text{concat}(1, u_n) &amp; \\ 0 &amp; \text{en otro caso} \end{cases}
\end{align}\]</div>
<p>$$
es decir que si el ejemplo está bien clasificado los pesos no se actualizan</p>
<div class="section" id="detalles-del-algoritmo-perceptron">
<h2>Detalles del algoritmo perceptrón<a class="headerlink" href="#detalles-del-algoritmo-perceptron" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>En cada iteración se presenta un ejemplo</p></li>
<li><p>Se dice que se completa una época de entrenamiento cuando se han presentado los <span class="math notranslate nohighlight">\(N\)</span> ejemplos</p></li>
<li><p>Presentar los ejemplos en distinto orden en cada época ayuda a evitar sesgos y acelera la convergencia</p></li>
<li><p>Detenemos el entrenamiento cuando todos los ejemplos están bien clasificados o al cumplir un cierto número de épocas sin cambio</p></li>
<li><p>El algoritmo perceptrón está garantizado a converger en tiempo finito si el problema es <strong>linealmente separable</strong></p></li>
<li><p>Si el problema no es <strong>linealmente separable</strong> la convergencia se puede forzar disminuyendo gradualmente <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="p">,));</span> <span class="n">d</span><span class="p">[:</span><span class="n">N</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">u</span><span class="p">[:</span><span class="n">N</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="p">[:</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">]);</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">N</span><span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">N</span><span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
<span class="n">plane</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">)</span> <span class="o">-</span> <span class="n">x_plot</span><span class="o">*</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span> 
<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
<span class="n">dot</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([],</span> <span class="p">[],</span> <span class="s1">&#39;ko&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">w</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">P</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">N</span><span class="p">))]</span>
    <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">u</span><span class="p">[</span><span class="n">idx</span><span class="p">])))</span> <span class="o">&lt;=</span> <span class="mf">0.</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">+</span> <span class="n">mu</span><span class="o">*</span><span class="n">d</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">u</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
    <span class="n">dot</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">plane</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ydata</span><span class="p">(</span><span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">)</span> <span class="o">-</span> <span class="n">x_plot</span><span class="o">*</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Iteration </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
        

<span class="n">anim</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mas-alla-del-perceptron">
<h2>Más allá del perceptron<a class="headerlink" href="#mas-alla-del-perceptron" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p>El modelo de neurona con salida sigmoide se conoce como <strong>regresión logística</strong></p></li>
<li><p>Tanto el perceptrón como el regresor logístico se pueden extender a más de dos clases: <strong>regresor softmax</strong></p></li>
<li><p>Conectando varias neuronas en cadena se forma lo que se conoce como una perceptrón multicapa</p></li>
<li><p>El perceptrón multicapa es un ejemplo de <strong>red neuronal artificial</strong></p></li>
<li><p>Las redes neuronales artificiales se estudiarán en detalle en el curso de <strong>inteligencia artificial</strong></p></li>
</ul>
</div>
<div class="section" id="topicos-extra">
<h2>Tópicos extra<a class="headerlink" href="#topicos-extra" title="Enlazar permanentemente con este título">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.commsp.ee.ic.ac.uk/~mandic/LMS_Kalman_IEEE_SPM_2015.pdf">On the Intrinsic Relationship Between the Least Mean Square and Kalman Filters</a></p></li>
<li><p><a class="reference external" href="http://homes.esat.kuleuven.be/~tvanwate/courses/dsp2/1415/DSP2_slides_04_adaptievefiltering.pdf">Adaptive notch filter</a></p></li>
<li><p><a class="reference external" href="https://wwwmpa.mpa-garching.mpg.de/~ensslin/lectures/Files/Wiener_Filter_Demo_NIFTy3.html">Reconstruction using Wiener filter</a></p></li>
<li><p><a class="reference external" href="https://scipy-cookbook.readthedocs.io/items/KalmanFiltering.html">Kalman filter</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./clases/unidad3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Pablo Huijse Heise<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.30270b6e4c972e43c488.js"></script>


    
  </body>
</html>