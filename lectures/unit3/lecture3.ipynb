{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "hv.opts.defaults(hv.opts.Curve(width=500), \n",
    "                 hv.opts.Points(width=500), \n",
    "                 hv.opts.Image(width=500, colorbar=True, cmap='Viridis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimadores adaptivos parte II\n",
    "\n",
    "En esta lección veremos algunos estimadores adaptivos que extienden el filtro LMS que revisamos en la lección anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo de Mínimos Cuadrados Recursivos \n",
    "\n",
    "\n",
    "El algoritmo LMS minimiza el error instantaneo y es simple y eficiente. Pero en algunos casos su convergencia es demasiado lenta\n",
    "\n",
    ":::{tip}\n",
    "\n",
    "Podemos obtener un filtro adaptivo que converge más rápido si utilizamos el error histórico en lugar del error instantaneo\n",
    "\n",
    ":::\n",
    "\n",
    "Sigamos considerando un filtro tipo FIR con $L+1$ pesos que se actualizan de en cada época $n$\n",
    "\n",
    "$$\n",
    "y_n = \\sum_{k=0}^L w_{n, k} u_{n-k}\n",
    "$$\n",
    "\n",
    "El algoritmo RLS (*Recursive Least Squares*) es un método online que minimiza el error histórico, es decir la suma de errores desde la muestra inicial hasta la actual\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J^H_n(\\textbf{w}) &= \\sum_{i=L}^n   \\beta^{n-i} |e_i|^2 \\nonumber \\\\\n",
    "&= \\sum_{i=L}^n \\beta^{n-i} (d_i - \\sum_{k=0}^{L} w_{i, k} u_{i-k} )^2, \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $n$ es el índice del instante actual y $\\beta \\in [0, 1]$ es el \"factor de olvido\", que usualmente es un valor cercano pero ligeramente menor que $1$.\n",
    "\n",
    "Adicionalmente se agrega un regularizador a los pesos\n",
    "\n",
    "$$\n",
    "J^w_n = \\lambda  \\| \\textbf{w}_{n} \\|^2 = \\lambda \\sum_{k=1} w_{n, k}^2\n",
    "$$\n",
    "\n",
    "Para evitar divergencias en el proceso de entrenamiento\n",
    "\n",
    ":::{important}\n",
    "\n",
    "La función de costo total del filtro RLS es la suma de error histórico y el regularizador\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución exacta del filtro RLS\n",
    "\n",
    "Si derivamos la función de costo e igualamos a cero obtenemos la siguiente regla\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}_n &= (U_n^T \\pmb{\\beta} U_n + \\lambda I)^{-1}  U_n^T \\pmb{\\beta} \\textbf{d}_n \\nonumber \\\\\n",
    "&= \\Phi_n^{-1} \\theta_n \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde reconocemos los siguientes términos\n",
    "\n",
    "- Matriz de correlación ponderada y regularizada: $\\Phi_n = U_n^T \\pmb{\\beta} U_n + \\lambda I$\n",
    "- Vector de correalación cruzada ponderada:  $\\theta_n = U_n^T \\pmb{\\beta} \\textbf{d}_n$\n",
    "\n",
    "que se definen en función\n",
    "\n",
    "$$\n",
    "\\textbf{d}_n = \\begin{pmatrix}  d_n \\\\ d_{n-1} \\\\ \\vdots \\\\ d_{L+1} \\end{pmatrix} \\quad\n",
    "\\textbf{u}_n = \\begin{pmatrix}  u_n \\\\ u_{n-1} \\\\ \\vdots \\\\ u_{n-(L+1)} \\end{pmatrix} \\quad\n",
    "\\pmb{\\beta} = I \\begin{pmatrix} \\beta \\\\ \\beta^{1} \\\\ \\beta^{2}  \\vdots \\\\ \\beta^{n-L-1} \\end{pmatrix}\n",
    "\\quad \n",
    "U_n = \\begin{pmatrix}\n",
    "\\textbf{u}_n^T \\\\ \\textbf{u}_{n-1}^T \\\\ \\vdots \\\\ \\textbf{u}_{L+1}^T \\\\\n",
    "\\end{pmatrix} \\in \\mathbb{R}^{n - (L+1) \\times L+1}\n",
    "$$\n",
    "\n",
    "donde $I$ es la matriz identidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "Esta solución es similar a la del filtro de Wiener. Es difícil actualizarla a medida que llegan nuevas observaciones y además es muy costosa debido al cálculo del inverso de la matriz de correlación\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución recursiva del filtro RLS\n",
    "\n",
    "En lugar de la solución cerrada, es más conveniente actualizar los pesos de forma recursiva. Las condiciones iniciales son \n",
    "\n",
    "- $\\Phi_0 = \\lambda^{-1} I$\n",
    "- $\\theta_0 = 0$\n",
    "\n",
    "y luego la actualización viene dada por \n",
    "\n",
    "- $\\Phi_{n} = \\beta \\Phi_{n-1} + \\textbf{u}_n \\textbf{u}_n^T$ \n",
    "- $\\theta_{n} = \\beta \\theta_{n-1} + \\textbf{u}_n d_n $ \n",
    "- $\\textbf{w}_n = \\Phi_n^{-1} \\theta_n$\n",
    "\n",
    "Podemos evitar invertir la matriz de correlación si usamos el lema de inversión de matrices \n",
    "\n",
    "$$\n",
    "(A + UCV)^{-1} = A^{-1} - A^{-1} U (C^{-1} + VA^{-1} U)^{-1} V A^{-1}\n",
    "$$\n",
    "\n",
    "con $A = \\Phi_{n-1}^{-1}$, $C=1$, $U= \\textbf{u}_n$ y $V = \\textbf{u}_n^T$. \n",
    "\n",
    "De esta forma podemos actualizar $\\Phi_{n}^{-1}$ directamente sin tener que invertirla, como se muestra a continuación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\Phi_{n}^{-1} &= \\left(\\beta \\Phi_{n-1} + \\textbf{u}_n \\textbf{u}_n^T \\right)^{-1} \\nonumber \\\\\n",
    "&= \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-2} \\frac{\\Phi_{n-1}^{-1} \\textbf{u}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1} }{1 + \\beta^{-1} \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\textbf{u}_n} \\nonumber \\\\\n",
    "&= \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-1} \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1}, \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde llamamos **ganancia** al factor\n",
    "\n",
    "$$\n",
    "\\textbf{k}_n =  \\frac{\\beta^{-1} \\Phi_{n-1}^{-1} \\textbf{u}_n }{1 + \\beta^{-1} \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\textbf{u}_n}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último paso es obtener al regla de actualización de pesos\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{w}_n &= \\Phi_n^{-1} \\theta_n \\nonumber \\\\\n",
    "&=  \\Phi_n^{-1} \\left ( \\beta \\theta_{n-1} + \\textbf{u}_n d_n \\right) \\nonumber \\\\\n",
    "&=  \\left ( \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-1} \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\right ) \\beta \\theta_{n-1} + \\Phi_n^{-1} \\textbf{u}_n d_n \\nonumber \\\\\n",
    "&=  \\textbf{w}_{n-1} - \\textbf{k}_n \\textbf{u}_n^T  \\textbf{w}_{n-1} + \\Phi_n^{-1} \\textbf{u}_n d_n \\nonumber \\\\\n",
    "&=  \\textbf{w}_{n-1} + \\textbf{k}_n ( d_n - \\textbf{u}_n^T  \\textbf{w}_{n-1} ) \\nonumber \\\\\n",
    "&=  \\textbf{w}_{n-1} + \\textbf{k}_n e_n \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde usamos que $\\textbf{w}_{n-1} = \\Phi_{n-1}^{-1} \\theta_{n-1}$ y $\\textbf{k}_n = \\Phi_n^{-1} \\textbf{u}_n$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} \n",
    "\n",
    "Con esto tenemos un algoritmo de orden cuadrático en lugar de orden cúbico. Esto sigue siendo mayor que LMS que era de orden lineal pero tiene la ventaja de converger más rapidamente.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen del algoritmo RLS\n",
    "\n",
    "```{prf:algorithm} Algoritmo RLS\n",
    ":nonumber:\n",
    "\n",
    "**Hyper-parámetros:** $L$, $\\lambda$, $\\beta$\n",
    "\n",
    "1. Inicializar $\\Phi_0^{-1} = \\lambda I$ y $\\textbf{w}_0 = 0$\n",
    "2. Para $n \\in [1, \\infty]$\n",
    "    1. Calcular la ganancia\n",
    "    \n",
    "    $$\n",
    "    \\textbf{k}_n =  \\frac{\\Phi_{n-1}^{-1} \\textbf{u}_n }{\\beta + \\textbf{u}_n^T \\Phi_{n-1}^{-1} \\textbf{u}_n}\n",
    "    $$\n",
    "    \n",
    "    2. Calcular el error\n",
    "    \n",
    "    $$\n",
    "    e_n = d_n - \\textbf{u}_n^T  \\textbf{w}_{n-1} \n",
    "    $$\n",
    "\n",
    "    3. Actualizar el error de pesos\n",
    "    \n",
    "    $$\n",
    "    \\textbf{w}_n = \\textbf{w}_{n-1} + \\textbf{k}_n e_n \n",
    "    $$\n",
    "    \n",
    "    4. Actualizar el inverso de la matriz de correlación\n",
    "    \n",
    "    $$\n",
    "    \\Phi_{n}^{-1} = \\beta^{-1} \\Phi_{n-1}^{-1} - \\beta^{-1} \\textbf{k}_n \\textbf{u}_n^T \\Phi_{n-1}^{-1}\n",
    "    $$\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- Hiperparámetro $\\beta$: Define la memoría efectiva del sistema y repercute en la convergencia y estabilidad del filtro. Como punto de partida se sugiere un valor de $\\beta \\approx 0.99$. En general $\\beta \\in [0.9, 1.0)$\n",
    "- Hiperparámetro $\\lambda$: Mientras más pequeño sea su valor mayor será la regularización. Se recomienda $\\lambda < 0.01/\\sigma_u^2$ donde $\\sigma_u$ es la desviación estándar de la señal de entrada. En la práctica se pueden calibrar con validación cruzada al igual que $L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación referencial en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filtro_RLS:\n",
    "    \n",
    "    def __init__(self, L, beta=0.99, lamb=1e-2):\n",
    "        self.L = L\n",
    "        self.w = np.zeros(shape=(L+1, ))\n",
    "        self.beta = beta\n",
    "        self.lamb = lamb\n",
    "        self.Phi_inv = lamb*np.eye(L+1)\n",
    "        \n",
    "    def update(self, un, dn):\n",
    "        # Cálculo de la ganancia\n",
    "        pi = np.dot(un.T, self.Phi_inv)\n",
    "        kn = pi.T/(self.beta + np.inner(pi, un))\n",
    "        # Actualizar el vector de pesos\n",
    "        error = dn - np.dot(self.w, un)\n",
    "        self.w += kn*error\n",
    "        # Actualizar el inverso de Phi\n",
    "        self.Phi_inv = (self.Phi_inv - np.outer(kn, pi))*self.beta**-1\n",
    "        return np.dot(self.w, un)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo: ALE con filtro RLS\n",
    "\n",
    "Veamos como reacciona el filtro RLS ante cambios bruscos usando el ejemplo de la lección pasada. Comparemos con el filtro NLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "Fs, f0 =  100, 5\n",
    "t = np.arange(0, 3, 1/Fs)\n",
    "s = np.sin(2.0*np.pi*t*f0)\n",
    "s[t>1] += 5\n",
    "u = s + 0.5*np.random.randn(len(t))\n",
    "\n",
    "class Filtro_NLMS:\n",
    "    \n",
    "    def __init__(self, L, mu, delta=1e-6):\n",
    "        self.L = L\n",
    "        self.w = np.zeros(shape=(L+1, ))\n",
    "        self.mu = mu\n",
    "        self.delta = delta\n",
    "        \n",
    "    def update(self, un, dn):\n",
    "        unorm = np.dot(un, un) + self.delta\n",
    "        error = dn - np.dot(self.w, un)\n",
    "        self.w += 2*self.mu*error*(un/unorm)\n",
    "        return np.dot(self.w, un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 20\n",
    "lms = Filtro_NLMS(L, 0.02)\n",
    "rls = Filtro_RLS(L, 0.99, 1e-2)\n",
    "\n",
    "u_pred = np.zeros(shape=(len(u), 2))\n",
    "for k in range(L+1, len(u)):\n",
    "    u_pred[k, 0] = lms.update(u[k-L-1:k][::-1], u[k])\n",
    "    u_pred[k, 1] = rls.update(u[k-L-1:k][::-1], u[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "s1 = hv.Curve((t, s), 'Tiempo', 'Señal', label='Limpia')\n",
    "s2 = hv.Scatter((t, u), 'Tiempo', 'Señal', label='Contaminada')\n",
    "s3 = hv.Curve((t, u_pred[:, 0]), 'Tiempo', 'Señal', label='Filtrada (LMS)')\n",
    "s4 = hv.Curve((t, u_pred[:, 1]), 'Tiempo', 'Señal', label='Filtrada (RMS)')\n",
    "hv.Overlay([s1, s2, s3, s4]).opts(hv.opts.Overlay(legend_position='top'), \n",
    "                                  hv.opts.Curve(ylim=(-5, 10), height=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} \n",
    "\n",
    "RLS es capaz de seguir los cambios de la señal en menos tiempo que el filtro LMS\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptrón \n",
    "\n",
    "El perceptrón es un filtro adaptivo desarrollado por [Frank Rosemblatt en 1962](https://en.wikipedia.org/wiki/Frank_Rosenblatt) con el objetivo de hacer **clasificación supervisada de patrones**\n",
    "\n",
    "Asumiremos que\n",
    "\n",
    "- La respuesta deseada tiene dos categorías: $d_n \\in \\{-1, +1\\}$. El perceptrón resuelve un problema de **clasificación binario**\n",
    "- La entrada es continua y de $L$ dimensiones: $u_n \\in \\mathbb{R}^L$\n",
    "- Se tienen $N$ tuplas $(u_n, d_n)$ para entrenar el filtro\n",
    "\n",
    "El filtro tiene arquitectura FIR con $L+1$ coeficientes pero se agrega una función no lineal $\\phi(\\cdot)$ en la salida del filtro\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_n &=  \\phi \\left(b + \\sum_{k=1}^{M} w_k u_{nk} \\right) \\nonumber \\\\\n",
    "&= \\phi \\left(b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle \\right), \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Los coeficientes del filtro son el escalar $b$ y el vector $\\textbf{w}$. \n",
    "\n",
    ":::{note}\n",
    "\n",
    "Este filtro corresponde al modelo matemático de una neurona de [McCulloch y Pitts](https://link.springer.com/article/10.1007/BF02478259), el antecesor de las actuales redes neuronales profundas\n",
    "\n",
    ":::\n",
    "\n",
    "En la implementación original se utilizó la siguiente función no lineal o función de activación\n",
    "\n",
    "$$\n",
    "\\phi(z) = \\text{sign}(z) = \\begin{cases} +1 & z > 0 \\\\0 & z=0\\\\-1 & z<0 \\end{cases}\n",
    "$$\n",
    "\n",
    "La siguiente figura esquematiza el modelo y su inspiración biológica\n",
    "\n",
    "<img src=\"../images/neurona.png\" width=\"700\">\n",
    "\n",
    "- Las coeficientes del filtro simulan la importancia o peso de las dendritas\n",
    "- La función no lineal simula el axón que dispara un estímulo eléctrico cuando el voltaje supera un umbral\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ajuste de la neurona artificial: Algoritmo perceptron\n",
    "\n",
    "La neurona ajusta sus parámetros con cada ejemplo que recibe. Asumiendo que tenemos un dataset con $N$ tuplas $(d_i, u_i)$ donde $d_i$ es la etiqueta y $u_i$ es el vector de entrada\n",
    "\n",
    "\n",
    "```{prf:algorithm} Algoritmo Perceptron\n",
    ":nonumber:\n",
    "\n",
    "**Hyper-parámetros:** $\\mu$, $M$\n",
    "\n",
    "1. Inicialización de los parámetros: $b=0$, $w_i=0, \\forall i = 1, \\ldots, L$\n",
    "1. Inicialización del contador: $m=0$\n",
    "2. Para $\\text{nepoch}=1,2,\\ldots, \\infty$\n",
    "    1. Hacer una permutación del dataset\n",
    "    1. $m = 0$\n",
    "    2. Para $n=1,2,\\ldots,N$\n",
    "        1. Si\n",
    "        \n",
    "        $$\n",
    "        \\text{sign} \\left(b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle \\right) \\neq d_i\n",
    "        $$\n",
    "    \n",
    "        entonces \n",
    "        \n",
    "        $$\n",
    "        \\textbf{w} =  \\textbf{w} + \\mu d_n \\textbf{u}_n\n",
    "        $$\n",
    "        \n",
    "        $$\n",
    "        b = b + \\mu d_n\n",
    "        $$\n",
    "        \n",
    "        de lo contrario\n",
    "        \n",
    "        $$\n",
    "        m = m + 1 \n",
    "        $$\n",
    "        \n",
    "        2. Si $m==M$\n",
    "        \n",
    "        entonces\n",
    "        \n",
    "        Detener el entrenamiento\n",
    "        \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- Se completa una época de entrenamiento cuando se han presentado los $N$ ejemplos del conjunto\n",
    "- El hiperparámetro $\\mu$ es la tasa de aprendizaje de la neurona\n",
    "- Detenemos el entrenamiento cuando todos los ejemplos están bien clasificados \n",
    "- También se puede detener el entrenamiento si se cumple un cierto número fijo de épocas o al cumplir un cierto número de épocas sin cambios en $b$ y $w$\n",
    "- La permutación de los ejemplos en cada época puede evitar sesgos y acelerar la convergencia\n",
    "- El algoritmo perceptrón está garantizado a converger en tiempo finito si el problema es **linealmente separable**. Si el problema no es **linealmente separable** la convergencia se puede forzar disminuyendo gradualmente $\\mu$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interpretación como una aplicación de gradiente descendente estocástico (SGD)\n",
    "\n",
    "El algoritmo de ajuste de la neurona puede considerarse como una minimización de la siguiente función de costo\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(b, \\textbf{w} ) = \\text{max} \\Big(0 ~, - d_n ( b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle) \\Big)\n",
    "$$\n",
    "\n",
    "cuya derivada es \n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{d \\textbf{w}}  = \\begin{cases} 0 & d_n ( b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle)  \\geq 0 \\\\ - d_n \\textbf{u}_n  & d_n ( b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle)  < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{d b}  = \\begin{cases} 0 & d_n ( b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle)  \\geq 0 \\\\ - d_n   & d_n ( b + \\langle \\textbf{w}, \\textbf{u}_n \\rangle)  < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "es decir que la derivada es cero si el ejemplo está bien clasificado\n",
    "\n",
    "Notemos que si aplicamos SGD sobre esta función de costo\n",
    "\n",
    "$$\n",
    "\\textbf{w} = \\textbf{w} - \\mu \\frac{d \\mathcal{L}}{d \\textbf{w}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = b - \\mu \\frac{d \\mathcal{L}}{db}\n",
    "$$\n",
    "\n",
    "se recuperan las reglas de ajuste vistas anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Clasificación binaria con perceptrón\n",
    "\n",
    "A continuación se muestra como ajustar un perceptrón a medida que se presentan los ejemplos en un problema de clasificación linealmente separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5 # Ejemplos por clase\n",
    "L = 2 # Dimensión de los datos\n",
    "np.random.seed(12345)\n",
    "u = np.concatenate((np.random.randn(N, L), \n",
    "                    4 + np.random.randn(N, L)))\n",
    "d = np.ones(shape=(2*N,)); \n",
    "d[:N] = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros e hiperparámetros\n",
    "b, w = 0, np.zeros(shape=(L, ))\n",
    "mu = 1e-5\n",
    "max_epoch = 5\n",
    "\n",
    "w_history = np.zeros(shape=(max_epoch*len(d), L))\n",
    "b_history = np.zeros(shape=(max_epoch*len(d),))\n",
    "u_history = np.zeros(shape=(max_epoch*len(d), 2))\n",
    "# Entrenamiento\n",
    "for nepoch in range(max_epoch):\n",
    "    idx = np.random.permutation(len(d))\n",
    "    for n, (un, dn) in enumerate(zip(u[idx], d[idx])):\n",
    "        if dn*(b+np.inner(w, un)) <= 0.:\n",
    "            w += mu*dn*un\n",
    "            b += mu*dn \n",
    "        u_history[nepoch*len(d)+n, :] = un\n",
    "        w_history[nepoch*len(d)+n, :] = w\n",
    "        b_history[nepoch*len(d)+n] = b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La neurona defina un hiperplano que separa el espacio en dos clases. En la siguiente animación se muestra el ajuste de la neurona y en consecuencia la modificación del hiperplano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "x_plot = np.linspace(-2, 7, num=10)\n",
    "hiperplano = lambda x, w, b, tol=1e-10 : -b/(w[1]+tol) - x*w[0]/(w[1]+tol)\n",
    "\n",
    "c1 = hv.Points((u[:N, 0], u[:N, 1]), label='Clase 1').opts(size=10, height=350, xlim=(-2, 7), ylim=(-2, 7))\n",
    "c2 = hv.Points((u[N:, 0], u[N:, 1]), label='Clase 2').opts(size=10)\n",
    "p = hv.HoloMap(kdims='Iteración')\n",
    "for i in range(len(b_history)):\n",
    "    plane = hv.Curve((x_plot, hiperplano(x_plot, w_history[i, :], b_history[i])), label='Hiperplano').opts(color='k')\n",
    "    selected = hv.Points((u_history[i, 0], u_history[i, 1])).opts(color='k', size=10)\n",
    "    p[i] = c1 * c2 * plane * selected\n",
    "\n",
    "hv.output(p.opts(legend_position='top'), holomap='gif', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ":::{note} \n",
    "\n",
    "El hiperplano se traslada y rota (transformación lineal) cada vez que el ejemplo seleccionado (marcado en negro) está mal clasificado\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Más allá del perceptron \n",
    "\n",
    "- El modelo de neurona con salida sigmoide se conoce como **regresión logística**\n",
    "- Tanto el perceptrón como el regresor logístico se pueden extender a más de dos clases: **regresor softmax**\n",
    "- Conectando varias neuronas en cadena se forma lo que se conoce como una perceptrón multicapa. Este es un ejemplo de **red neuronal artificial**\n",
    "- Las redes neuronales artificiales se estudian en mayor detalle en el curso de **inteligencia artificial** (INFO257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
