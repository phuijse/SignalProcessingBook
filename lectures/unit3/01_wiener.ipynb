{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.fft as sfft\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "from IPython.display import YouTubeVideo, HTML, Audio\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
    "from bokeh.plotting import Figure, show, output_notebook\n",
    "from bokeh.palettes import Dark2_5 as palette\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimador lineal óptimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definiciones y fundamentos\n",
    "\n",
    "- **Estimador:** Sistema diseñado para **extraer información** a partir de una **señal**\n",
    "- La señal contiene **información y ruido** \n",
    "- La señal es representada como una secuencia de **datos**\n",
    "\n",
    "Tipos de estimador\n",
    "\n",
    "- **Filtro:** Estimo el valor actual de mi señal acentuando o eliminando una o más características\n",
    "- **Predictor:** Estimo el valor futuro de mi señal\n",
    "\n",
    "Estimador lineal óptimo\n",
    "\n",
    "- Lineal: La cantidad estimada es una función lineal de la entrada\n",
    "- Óptimo: El estimador es la mejor solución posible de acuerdo a un criterio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Proceso aleatorio o proceso estocástico\n",
    "\n",
    "Un proceso estocástico es una **colección de variables aleatorias** indexadas tal que forman una secuencia \n",
    "\n",
    "Se denotan matematicamente como un conjunto $\\{U_k\\}$, con $k=0, 1, 2, \\ldots, N$. El índice $k$ puede representar tiempo, espacio u otra variable independiente\n",
    "\n",
    "\n",
    "La siguiente figura muestre tres realizaciones u observaciones de un proceso estocástico con cuatro elementos\n",
    "\n",
    "<img src=\"../images/stochastic_process.png\" width=\"600\">\n",
    "\n",
    "\n",
    "\n",
    "Se usan para modelar la evolución de un fenomeno estadístico en el tiempo donde el fenomeno se rige por leyes probabilísticas\n",
    "\n",
    "#### Momentos de un proceso estocástico\n",
    "\n",
    "Un proceso aleatorio $U_n = (u_n, u_{n-1}, u_{n-2}, \\ldots, u_{n-L})$ se describe a través de sus momentos estadísticos\n",
    "\n",
    "Si consideramos una caracterízación de segundo orden necesitamos definir\n",
    "\n",
    "- Momento central o media: Describe el valor central del proceso\n",
    "\n",
    "$$\n",
    "\\mu(n) = \\mathbb{E}[U_n]\n",
    "$$\n",
    "\n",
    "- Segundo momento o correlación: Describe la dispersión de un proceso \n",
    "\n",
    "$$\n",
    "r_{uu}(n, n-k) = \\mathbb{E}[U_n U_{n-k}]\n",
    "$$\n",
    "\n",
    "- Segundo momento centrado o covarianza\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "c_{uu}(n, n-k) &= \\mathbb{E}[(U_n-\\mu_n) (U_{n-k}- \\mu_{n-k})] \\nonumber \\\\\n",
    "&= r(n,n-k) - \\mu_n \\mu_{n-k} \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- Correlación cruzada entre dos procesos \n",
    "\n",
    "$$\n",
    "r_{ud}(n, n-k) = \\mathbb{E}[U_n D_{n-k}]\n",
    "$$\n",
    "\n",
    "#### Proceso estocástico estacionario\n",
    "\n",
    "En general consideraremos el caso simplificado donde el **proceso es estacionario**\n",
    "\n",
    "$$\n",
    "\\mu(n)  = \\mu, \\forall n\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "r_{uu}(n, n-k)  = r_{uu}(k), \\forall n\n",
    "$$\n",
    "\n",
    "es decir que los momentos estadísticos se mantienen constantes en el tiempo (no depende de $n$)\n",
    "\n",
    "Otra simplificación es que el proceso sea ergódico\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[U_n] = \\frac{1}{N} \\sum_{n=1}^N u_n\n",
    "$$\n",
    "\n",
    "es decir podemos reemplazar el valor esperado por la media muestral en el tiempo\n",
    "\n",
    "\n",
    "#### Densidad espectral de potencia\n",
    "\n",
    "Otra cantidad de interés es la PSD (*power spectral density*) que mide la distribución de la potencia en frecuencia\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S_{uu}(f) &= \\sum_{k=-\\infty}^{\\infty} r_{uu}(k) e^{-j 2\\pi f k} \\nonumber \\\\\n",
    "&= \\lim_{N\\to\\infty} \\frac{1}{2N+1} \\mathbb{E} \\left [\\left|\\sum_{n=-N}^{N} u_n e^{-j 2\\pi f n} \\right|^2 \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "que corresponde a la transformada de Fourier de la correlación (caso estacionario)\n",
    "\n",
    "La PSD y la correlación forman un par de Fourier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimadores óptimos\n",
    "\n",
    "Definición de [Óptimo](http://dle.rae.es/?id=R7bbor7): adjetivo. Sumamente bueno, que no puede ser mejor.\n",
    "\n",
    "Para diseñar un estimador óptimo necesitamos un **criterio**\n",
    "\n",
    "Luego el estimador será **óptimo según dicho criterio**\n",
    "\n",
    "Usualmente también consideramos supuestos\n",
    "\n",
    "Por ejemplo podríamos asumir que\n",
    "\n",
    "- el ruido es aditivo y blanco o que tiene una cierta covarianza conocida\n",
    "- conocemos la media y covarianza de la señal\n",
    "- el proceso es estacionario\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filtro de Wiener\n",
    "\n",
    "Este filtro fue publicado por Norbert Wiener en 1949. Es un filtro de tiempo discreto con estructura FIR y $L+1$ coeficientes: $h_0, h_1, h_2, \\ldots, h_{L}$\n",
    "\n",
    "- La entrada al filtro es una señal $u_0, u_1, u_2, \\ldots$\n",
    "- Para cada tiempo el filtro produce una salida $y_0, y_1, y_2, \\ldots$\n",
    "\n",
    "Los coeficientes del filtro se aprenden en base a dos ingredientes\n",
    "\n",
    "- Una respuesta \"deseada\" u objetivo $d_0, d_1, d_2, \\ldots$\n",
    "- Un criterio de optimalidad que opera sobre el error entre la respuesta deseada y la salida\n",
    "\n",
    "$$\n",
    "e_n = d_n - y_n = d_n - \\sum_{k=0}^{L} h_k u_{n-k} \n",
    "$$\n",
    "\n",
    "\n",
    "Diagrama del filtro de Wiener\n",
    "\n",
    "<img src=\"../images/wiener.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ajuste del filtro de Wiener\n",
    "\n",
    "El criterio más común para aprender o adaptar el filtro de Wiener es **el error medio cuadrático** entre la respuesta deseada y la salida del filtro\n",
    "\n",
    "Asumiendo que $u$ y $d$ son secuencias de valores reales podemos escribir el MSE como\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{MSE} &= \\mathbb{E}\\left [e_n^2 \\right] \\nonumber \\\\\n",
    "&= \\mathbb{E}\\left [(d_n - y_n)^2 \\right] \\nonumber \\\\\n",
    "&= \\mathbb{E}\\left [d_n^2 \\right]  - 2\\mathbb{E}\\left [ d_n y_n \\right] + \\mathbb{E}\\left [ y_n^2 \\right] \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "donde $\\sigma_d^2 = \\mathbb{E}\\left [d_n^2 \\right]$ es la varianza de la señal deseada y $\\sigma_y^2 = \\mathbb{E}\\left [ y_n^2 \\right]$ es la varianza de nuestro estimador\n",
    " \n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Minimizar el MSE implica acercar la salida del filtro a la respuesta deseada\n",
    "    \n",
    "</div>\n",
    "\n",
    "En este caso, igualando la derivada del MSE a cero, tenemos \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{d h_j} \\text{MSE} &= -2\\mathbb{E}\\left[ d_n \\frac{d y_n}{d h_j}  \\right]  + 2 \\mathbb{E}\\left[ y_n \\frac{d y_n}{d h_j}    \\right]  \\nonumber \\\\\n",
    "&= -2\\mathbb{E}\\left[ d_n u_{n-j} \\right]  + 2 \\mathbb{E}\\left[ y_n u_{n-j}    \\right]  \\nonumber \\\\\n",
    "&= -2\\mathbb{E}\\left[ d_n u_{n-j} \\right]  + 2 \\mathbb{E}\\left[ \\sum_{k=0}^{L} h_k u_{n-k}  u_{n-j} \\right] \\nonumber \\\\\n",
    "&= -2\\mathbb{E}\\left[ d_n u_{n-j} \\right]  + 2 \\sum_{k=0}^{L} h_k \\mathbb{E}\\left[ u_{n-k}  u_{n-j} \\right] = 0 \\nonumber \\end{align}\n",
    "$$\n",
    "\n",
    "Si despejamos y repetimos para $j=0, \\ldots, L$ obtenemos el siguiente sistema de ecuaciones\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{pmatrix}\n",
    "r_{uu}(0) & r_{uu}(1) & r_{uu}(2) & \\ldots & r_{uu}(L) \\\\\n",
    "r_{uu}(1) & r_{uu}(0) & r_{uu}(1) & \\ldots & r_{uu}(L-1) \\\\\n",
    "r_{uu}(2) & r_{uu}(1) & r_{uu}(0) & \\ldots & r_{uu}(L-2) \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots &\\vdots \\\\\n",
    "r_{uu}(L) & r_{uu}(L-1) & r_{uu}(L-2) & \\ldots & r_{uu}(0) \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "h_0  \\\\\n",
    "h_1  \\\\\n",
    "h_2  \\\\\n",
    "\\vdots  \\\\\n",
    "h_L \\\\\n",
    "\\end{pmatrix} &= \n",
    "\\begin{pmatrix}\n",
    "r_{ud}(0)  \\\\\n",
    "r_{ud}(1)  \\\\\n",
    "r_{ud}(2) \\\\\n",
    "\\vdots  \\\\\n",
    "r_{ud}(L) \\\\\n",
    "\\end{pmatrix} \\nonumber \\\\\n",
    "R_{uu} \\textbf{h} &= R_{ud},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "que se conoce como las **ecuaciones de Wiener-Hopf**. Además $R_{uu}$ se conoce como matriz de auto-correlación. \n",
    "\n",
    "Asumiendo que $R_{uu}$ es no-singular, es decir que su inversa existe, la **solución óptima en el sentido de mínimo MSE** es \n",
    "\n",
    "$$\n",
    "\\textbf{h}^{*} = R_{uu} ^{-1} R_{ud}\n",
    "$$\n",
    "\n",
    "En general $R_{uu}$ es una matriz definida-positiva (su inversa existe) y el sistema puede resolverse en $\\mathcal{O}(L^2)$ usando la [recursión de Levison-Durbin](https://en.wikipedia.org/wiki/Levinson_recursion)\n",
    "\n",
    "### Requisitos/supuestos de este filtro\n",
    "\n",
    "- La salida deseada y la entrada tienen media cero, *i.e.* $\\mathbb{E}[d_n] = \\mathbb{E}[u_n] = 0$, si esto no fuera así puede restarse antes de entrenar el filtro\n",
    "- La salida deseada y la entrada son estacionarias en el sentido amplio, es decir la correlación solo depende de $m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error mínimo del filtro de Wiener\n",
    "\n",
    "Sea $U_n = (u_n, u_{n-1}, u_{n-2}, \\ldots, u_{n-L})$ \n",
    "\n",
    "Dado que $y_n = \\textbf{h}^T U_n = U_n^T \\textbf{h} $, podemos expresar el MSE como\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{MSE} &= \\mathbb{E}\\left [d_n^2 \\right]  - 2\\mathbb{E}\\left [ d_n y_n \\right] + \\mathbb{E}\\left [ y_n^2 \\right] \\nonumber \\\\\n",
    "&= \\mathbb{E}\\left [d_n^2 \\right] - 2 \\textbf{h}^T \\mathbb{E}\\left [ d_n U_n \\right]  + \\textbf{h}^T \\mathbb{E}\\left [U_n U_n^T \\right]  \\textbf{h}  \\nonumber \\\\\n",
    "&= \\sigma_d^2 - 2 \\textbf{h}^T R_{ud} + \\textbf{h}^T R_{uu} \\textbf{h} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Luego el mínimo error que se puede obtener es\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{MSE}_{\\text{min}} &= \\sigma_d^2 - (R_{uu}^{-1} R_{ud})^T R_{ud} \\nonumber \\\\\n",
    "&= \\sigma_d^2 - R_{ud}^T R_{uu}^{-1} R_{ud} < \\sigma_d^2\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones del filtro de Wiener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regresión  o identificación de sistema\n",
    "\n",
    "En regresión buscamos encontrar los coeficientes $h$ a partir de $(X, Y)$ tal que\n",
    "\n",
    "$$\n",
    "Y = h^T X + \\epsilon,\n",
    "$$\n",
    "\n",
    "donde $X \\in \\mathbb{R}^{N\\times D}$ son las variables dependientes (entrada), $Y \\in \\mathbb{R}^N$ es la  variable dependiente (salida) y $\\epsilon$ es ruido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar el filtro\n",
    "\n",
    "1. Asumimos que hemos observado N muestras de $X$ e $Y$ \n",
    "1. A partir de $u=X$ construimos $R_{uu}$\n",
    "1. A partir de $d=Y$ construimos $R_{ud}$\n",
    "1. Finalmente recuperamos $\\textbf{h}$ usando $R_{uu} ^{-1} R_{ud}$\n",
    "1. Con esto podemos interpolar $Y$ \n",
    "\n",
    "Sea por ejemplo una regresión de tipo polinomial donde encontrar $h_k$ tal que\n",
    "\n",
    "$$\n",
    "d_i = f_i + \\epsilon = \\sum_{k=1}^L h_k u_i^k + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.linspace(-2, 2, num=30)\n",
    "f = 0.25*u**5 - 2*u**3 + 5*u # Los coeficientes reales son [0, 5, 0, -2, 0, 1/4, 0, 0, 0, ...]\n",
    "d = f + np.random.randn(len(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo cambia el resultado con L?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wiener_regression(u, d, L):\n",
    "    U = np.ones(shape=(len(u), L))\n",
    "    for i in range(1, L):\n",
    "        U[:, i] = u**i\n",
    "    Ruu = np.dot(U.T, U)\n",
    "    Rud = np.dot(U.T, d[:, np.newaxis])\n",
    "    return np.linalg.solve(Ruu, Rud)[:, 0]\n",
    "\n",
    "def interpolate_wiener(u, h):\n",
    "    L = len(h)\n",
    "    U = np.ones(shape=(len(u), L))\n",
    "    for i in range(1, L):\n",
    "        U[:, i] = u**i\n",
    "    return np.dot(U, h)\n",
    "\n",
    "uhat = np.linspace(np.amin(u), np.amax(u), num=100)\n",
    "L = [2, 5, 10]\n",
    "p = [Figure(plot_width=600, plot_height=250, toolbar_location=\"below\") for k in L]\n",
    "\n",
    "for p_, L_, color in zip(p, L, palette):\n",
    "    fhat = interpolate_wiener(uhat, train_wiener_regression(u, d, L_))\n",
    "    p_.line(u, f, line_width=3, legend_label=\"Señal intrísinca f\")\n",
    "    p_.scatter(u, d, color='black', line_width=3, legend_label=\"Señal contaminada y\")\n",
    "    p_.line(uhat, fhat, line_width=3, \n",
    "            color=color, legend_label=f\"Señal interpolada L={L_}\")\n",
    "    p_.legend.location = 'bottom_right'\n",
    "show(column(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Si $L$ es muy pequeño el filtro es demasiado simple. Si $L$ es muy grande el filtro se puede sobreajustar al ruido\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predicción \n",
    "\n",
    "En este caso asumimos que la señal deseada es la entrada en el futuro\n",
    "\n",
    "$$\n",
    "d_n = \\{u_{n+1}, u_{n+2}, \\ldots, u_{n+m}\\}\n",
    "$$ \n",
    "\n",
    "donde $m$ es el horizonte de predicción\n",
    "\n",
    "Se llama *predicción a un paso* al caso $m=1$\n",
    "\n",
    "El largo del filtro $L$ define la cantidad de muestras pasadas que usamos para predecir\n",
    "\n",
    "Por ejemplo un sistema de predicción a un paso con $L+1 = 3$ coeficientes:\n",
    "\n",
    "$$\n",
    "h_0 u_n +  h_1 u_{n-1} + h_2 u_{n-2}= y_n = \\hat u_{n+1} \\approx u_{n+1}\n",
    "$$\n",
    "\n",
    "Para entrenar el filtro\n",
    "\n",
    "1. Asumimos que la señal ha sido observada y que se cuenta con $N$ muestras para entrenar\n",
    "1. Podemos formar una matriz cuyas filas son $[u_n, u_{n-1}, \\ldots, u_{n-L}]$ para $n=L,L+1,\\ldots, N-1$\n",
    "1. Podemos formar un vector $[u_N, u_{N-1}, \\ldots, u_{L+1}]^T$ (caso $m=1$)\n",
    "1. Con esto podemos formar las matrices de correlación y obtener $\\textbf{h}$\n",
    "1. Finalmente usamos $\\textbf{h}$ para predecir el futuro no observado de $u$\n",
    "\n",
    "¿Cómo afecta $L$ a la calidad del predictor lineal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "np.random.seed(0)\n",
    "t = np.linspace(0, 10, num=200)\n",
    "u = np.sin(2.0*np.pi*0.5*t) + 0.25*np.random.randn(len(t))\n",
    "\n",
    "def train_wiener_predictor(u, L):\n",
    "    U = as_strided(u, [len(u)-L+1 , L+1], \n",
    "                   strides=[u.strides[0], u.strides[0]])\n",
    "    Ruu = np.dot(U[:, :L].T, U[:, :L])\n",
    "    Rud = np.dot(U[:, :L].T, U[:, L][:, np.newaxis])\n",
    "    return np.linalg.solve(Ruu, Rud)[:, 0]\n",
    "\n",
    "def predict_wiener(u_past, h, m):\n",
    "    L = len(h)\n",
    "    u_pred = np.zeros(shape=(m+L, ))\n",
    "    u_pred[:L] = u_past\n",
    "    for k in range(L, m+L):\n",
    "        u_pred[k] = np.sum(h*u_pred[k-L:k])\n",
    "    return u_pred[L:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "L = [5, 10, 20, 40]\n",
    "p = [Figure(plot_width=600, plot_height=250, \n",
    "            title=f\"Filtro de orden {L_}\", toolbar_location=\"below\") for L_ in L]\n",
    "\n",
    "for p_, L_ in zip(p, L):\n",
    "    h = train_wiener_predictor(u[:N], L_)\n",
    "    u_pred = predict_wiener(u[N-L_:N], h, m=100)\n",
    "    p_.scatter(t[:N], u[:N], color=palette[0], legend_label=\"Pasado\")\n",
    "    p_.scatter(t[N:], u[N:], color=palette[1], legend_label=\"Futuro real\")\n",
    "    p_.line(t[N:], u_pred, line_width=3, color=palette[2], legend_label=\"Futuro predicho\")\n",
    "    p_.legend.location = 'bottom_left'\n",
    "\n",
    "show(column(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">    \n",
    "\n",
    "El resultado es similar al caso anterior. Si $L$ es muy pequeño el filtro es demasiado simple. Si $L$ es muy grande el filtro se puede sobreajustar al ruido    \n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Eliminar ruido blanco aditivo\n",
    "\n",
    "En este caso asumimos que la señal de entrada corresponde a una señal deseada (información) que ha sido contaminada con ruido aditivo\n",
    "\n",
    "$$\n",
    "u_n = d_n + \\nu_n,\n",
    "$$\n",
    "\n",
    "adicionalmente asumimos que\n",
    "- el ruido es estacionario en el sentido amplio y de media cero $\\mathbb{E}[\\nu_n] = 0$\n",
    "- el ruido es blanco, es decir no tiene correlación consigo mismo o con la señal deseada\n",
    "\n",
    "$$\n",
    "r_{\\nu d}(k) = 0, \\forall k\n",
    "$$\n",
    "\n",
    "- el ruido tiene una cierta varianza $\\mathbb{E}[\\nu_n^2] = \\sigma_\\nu^2, \\forall n$\n",
    "\n",
    "Notemos que en este caso $R_{uu} = R_{dd} + R_{\\nu\\nu}$ y $R_{ud} = R_{dd}$, luego\n",
    "\n",
    "la señal recuperada es $\\hat d_n = h^{*} u_n$ y el filtro es\n",
    "\n",
    "$$\n",
    "\\vec h^{*} = \\frac{R_{dd}}{R_{dd} + R_{\\nu\\nu}}\n",
    "$$\n",
    "\n",
    "y su respuesta en frecuencia\n",
    "\n",
    "$$\n",
    "H(f) = \\frac{S_{dd}(f)}{S_{dd}(f) + S_{\\nu\\nu}(f)}\n",
    "$$\n",
    "\n",
    "es decir que \n",
    "- en frecuencias donde la $S_{dd}(f) > S_{\\nu\\nu}(f)$, entonces $H(f) = 1$\n",
    "- en frecuencias donde la $S_{dd}(f) < S_{\\nu\\nu}(f)$, entonces $H(f) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INFO183",
   "language": "python",
   "name": "info183"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
